{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.datasets import fetch_lfw_people \nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report, confusion_matrix \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-02-27T10:11:42.282271Z","iopub.execute_input":"2024-02-27T10:11:42.282608Z","iopub.status.idle":"2024-02-27T10:11:42.288173Z","shell.execute_reply.started":"2024-02-27T10:11:42.282579Z","shell.execute_reply":"2024-02-27T10:11:42.287322Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# DEFINE MODULAR PCA","metadata":{}},{"cell_type":"code","source":"def get_length(n):\n    start = int(np.sqrt(n))\n    while start > 1:\n        if n % start == 0:\n            break\n        else:\n            start -= 1\n    return start, n // start","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.289753Z","iopub.execute_input":"2024-02-27T10:11:42.290040Z","iopub.status.idle":"2024-02-27T10:11:42.305485Z","shell.execute_reply.started":"2024-02-27T10:11:42.290014Z","shell.execute_reply":"2024-02-27T10:11:42.304545Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def cut_image(X, num_image=4, shape=(62,47)):\n    height, width = shape\n    num_width, num_height = get_length(num_image)\n    part_width = width // num_width\n    part_height = height // num_height\n\n    X_cut = []\n\n    for i in range(X.shape[0]):\n        image = X[i].reshape(shape)\n        for k in range(num_width):\n            for j in range(num_height):\n                left = j * part_width\n                upper = k * part_height\n                right = left + part_width\n                lower = upper + part_height\n\n                # Crop the image to get the part\n                part = image[upper:lower, left:right]\n\n                pixels = np.reshape(part, [1, part_width * part_height])\n                pixels = np.asarray(pixels)\n\n                if k == 0 and j == 0:\n                    X_i = pixels\n                else:\n                    X_i = np.hstack([X_i, pixels])\n\n        if len(X_cut) == 0:\n            X_cut = X_i\n        else:\n            X_cut = np.vstack([X_cut, X_i])\n\n    return X_cut","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.306475Z","iopub.execute_input":"2024-02-27T10:11:42.306739Z","iopub.status.idle":"2024-02-27T10:11:42.314900Z","shell.execute_reply.started":"2024-02-27T10:11:42.306717Z","shell.execute_reply":"2024-02-27T10:11:42.314243Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class ModularPCA:\n    def __init__(self, n_components, num_image=4, shape_image=(62,47)):\n        self.n_components = n_components\n        self.shape = shape_image\n        self.num_image = num_image\n\n    def fit(self, X):\n        self.X = cut_image(X, self.num_image, self.shape)\n        self.pca = PCA(n_components=self.n_components, random_state=42)\n        self.pca.fit(self.X)\n\n    def transform(self, X):\n        X_cut = cut_image(X, self.num_image, self.shape)\n        return self.pca.transform(X_cut)\n\n    def fit_transform(self, X):\n        self.fit(X)\n        return self.pca.fit_transform(self.X)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.316414Z","iopub.execute_input":"2024-02-27T10:11:42.317124Z","iopub.status.idle":"2024-02-27T10:11:42.324890Z","shell.execute_reply.started":"2024-02-27T10:11:42.317102Z","shell.execute_reply":"2024-02-27T10:11:42.324243Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# LOAD DATASET","metadata":{}},{"cell_type":"code","source":"lfw_people = fetch_lfw_people(min_faces_per_person = 70, funneled=False) \n  \nn_samples, h, w = lfw_people.images.shape \n  \nX = lfw_people.data \nn_features = X.shape[1] \n  \ny = lfw_people.target \ntarget_names = lfw_people.target_names \nn_classes = target_names.shape[0] \n  \n# Print Details about dataset \nprint(\"Number of Data Samples: % d\" % n_samples) \nprint(\"Size of a data sample: % d\" % n_features) \nprint(\"Number of Class Labels: % d\" % n_classes)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.325877Z","iopub.execute_input":"2024-02-27T10:11:42.326710Z","iopub.status.idle":"2024-02-27T10:11:42.404441Z","shell.execute_reply.started":"2024-02-27T10:11:42.326680Z","shell.execute_reply":"2024-02-27T10:11:42.403526Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Number of Data Samples:  1288\nSize of a data sample:  2914\nNumber of Class Labels:  7\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify=y) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.405761Z","iopub.execute_input":"2024-02-27T10:11:42.406048Z","iopub.status.idle":"2024-02-27T10:11:42.414557Z","shell.execute_reply.started":"2024-02-27T10:11:42.406021Z","shell.execute_reply":"2024-02-27T10:11:42.413549Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"n_components = 150\n  \npca = PCA(n_components=n_components)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced = pca.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:42.415718Z","iopub.execute_input":"2024-02-27T10:11:42.416409Z","iopub.status.idle":"2024-02-27T10:11:43.164342Z","shell.execute_reply.started":"2024-02-27T10:11:42.416376Z","shell.execute_reply":"2024-02-27T10:11:43.163614Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Euclidean","metadata":{}},{"cell_type":"code","source":"y_predict = []\nfor i in range(len(X_test_reduced)):\n    min_ = np.argmin(np.sqrt(np.sum((X_train_reduced - X_test_reduced[i])**2,axis=1)))\n    y_predict.append(y_train[min_])","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:43.165812Z","iopub.execute_input":"2024-02-27T10:11:43.166848Z","iopub.status.idle":"2024-02-27T10:11:43.277194Z","shell.execute_reply.started":"2024-02-27T10:11:43.166822Z","shell.execute_reply":"2024-02-27T10:11:43.276485Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_predict, target_names = target_names)) ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:43.280621Z","iopub.execute_input":"2024-02-27T10:11:43.281075Z","iopub.status.idle":"2024-02-27T10:11:43.291272Z","shell.execute_reply.started":"2024-02-27T10:11:43.281048Z","shell.execute_reply":"2024-02-27T10:11:43.290568Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"**Set up dataframe for model results storage**","metadata":{}},{"cell_type":"code","source":"model_scores = {}\nprediction_results = {}","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:11:43.292469Z","iopub.execute_input":"2024-02-27T10:11:43.292762Z","iopub.status.idle":"2024-02-27T10:11:43.296422Z","shell.execute_reply.started":"2024-02-27T10:11:43.292737Z","shell.execute_reply":"2024-02-27T10:11:43.295484Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"*****","metadata":{}},{"cell_type":"markdown","source":"# Modular PCA - TUNNING PROCESS","metadata":{"execution":{"iopub.execute_input":"2024-02-26T11:14:34.583816Z","iopub.status.busy":"2024-02-26T11:14:34.583441Z","iopub.status.idle":"2024-02-26T11:14:34.588812Z","shell.execute_reply":"2024-02-26T11:14:34.587532Z","shell.execute_reply.started":"2024-02-26T11:14:34.583789Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nn_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:43.297734Z","iopub.execute_input":"2024-02-27T10:11:43.298280Z","iopub.status.idle":"2024-02-27T10:11:43.305362Z","shell.execute_reply.started":"2024-02-27T10:11:43.298254Z","shell.execute_reply":"2024-02-27T10:11:43.304703Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# num_image = 4","metadata":{}},{"cell_type":"code","source":"n_components_pca = 150\nnum_images = 4\n\npca = ModularPCA(n_components=n_components_pca, num_image= num_images)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced = pca.transform(X_test)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:11:43.306534Z","iopub.execute_input":"2024-02-27T10:11:43.307164Z","iopub.status.idle":"2024-02-27T10:11:44.116916Z","shell.execute_reply.started":"2024-02-27T10:11:43.307139Z","shell.execute_reply":"2024-02-27T10:11:44.116125Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine ","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:44.120498Z","iopub.execute_input":"2024-02-27T10:11:44.122947Z","iopub.status.idle":"2024-02-27T10:11:44.315489Z","shell.execute_reply.started":"2024-02-27T10:11:44.122918Z","shell.execute_reply":"2024-02-27T10:11:44.314351Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"accuracy: 0.7732919254658385\nrecall: 0.6860788303823859\nprecision: 0.7300406004088043\nf1-score: 0.6995254022707311\nroc_auc:  0.8215152210812063\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        # 'degree': trial.suggest_int('degree', 2, 5),  # for polynomial kernel\n        'tol': trial.suggest_loguniform('tol', 1e-4, 1e-2),\n        'shrinking': trial.suggest_categorical('shrinking', [True, False]),\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = SVC(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:44.318254Z","iopub.execute_input":"2024-02-27T10:11:44.318850Z","iopub.status.idle":"2024-02-27T10:11:44.324918Z","shell.execute_reply.started":"2024-02-27T10:11:44.318824Z","shell.execute_reply":"2024-02-27T10:11:44.324110Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = SVC(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['svc'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'SVM'\nmodel_scores[model_name +str(num_images)] = [accuracy,recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:11:44.325776Z","iopub.execute_input":"2024-02-27T10:11:44.326172Z","iopub.status.idle":"2024-02-27T10:12:18.999314Z","shell.execute_reply.started":"2024-02-27T10:11:44.326151Z","shell.execute_reply":"2024-02-27T10:12:18.998423Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:11:44,338] A new study created in memory with name: no-name-0a6ab767-95d5-4ae3-be01-52963ba58149\n[I 2024-02-27 10:11:45,078] Trial 0 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.008661687190428806, 'gamma': 1170.1936675359614, 'tol': 0.0010686108969680012, 'shrinking': False}. Best is trial 0 with value: 0.41097163613054855.\n[I 2024-02-27 10:11:45,281] Trial 1 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 5.174269004444433e-05, 'gamma': 0.0031705137506750514, 'tol': 0.005301320952420495, 'shrinking': True}. Best is trial 0 with value: 0.41097163613054855.\n[I 2024-02-27 10:11:45,619] Trial 2 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.8120260918650797, 'gamma': 0.00013339279991124477, 'tol': 0.0006386683054024209, 'shrinking': True}. Best is trial 0 with value: 0.41097163613054855.\n[I 2024-02-27 10:11:45,904] Trial 3 finished with value: 0.7608514502430426 and parameters: {'kernel': 'linear', 'C': 0.16391616090771216, 'gamma': 313.94645987697015, 'tol': 0.0030018876310815455, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:46,376] Trial 4 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 6.977230656479624, 'gamma': 493.7852820428063, 'tol': 0.0010829705288169119, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:46,637] Trial 5 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 33330.56672677512, 'gamma': 44902.44291201136, 'tol': 0.008582993426197904, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:47,418] Trial 6 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 27.963732611843515, 'gamma': 44994.13272134209, 'tol': 0.00020150356893105153, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:47,717] Trial 7 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.5268543766115811, 'gamma': 0.002473909180896884, 'tol': 0.0011125860785399684, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:48,281] Trial 8 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.739484402693296, 'gamma': 0.3845889499434259, 'tol': 0.0005334777905085697, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:48,740] Trial 9 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 5.097463798652525e-05, 'gamma': 2.8546444393462638, 'tol': 0.0001605627397357723, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:49,115] Trial 10 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 7828.793072506121, 'gamma': 7.82754184016594, 'tol': 0.002949087401804375, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:49,426] Trial 11 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 13980.391145572441, 'gamma': 61156.27487987145, 'tol': 0.009749932617824931, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:49,777] Trial 12 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 363.8767869169313, 'gamma': 627.7571509205357, 'tol': 0.0033859838103676033, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:50,008] Trial 13 finished with value: 0.5993536670049677 and parameters: {'kernel': 'linear', 'C': 0.007589027800208777, 'gamma': 75.17296881409345, 'tol': 0.007654633567623221, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:50,242] Trial 14 finished with value: 0.6128144864056407 and parameters: {'kernel': 'linear', 'C': 0.008196212590550285, 'gamma': 7575.1012721677625, 'tol': 0.0022946689615534303, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:50,574] Trial 15 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 77645.28971923272, 'gamma': 26.182170150712242, 'tol': 0.004673156566161334, 'shrinking': False}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:50,887] Trial 16 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 417.1144753665453, 'gamma': 0.30807347236462884, 'tol': 0.0018164297690079778, 'shrinking': True}. Best is trial 3 with value: 0.7608514502430426.\n[I 2024-02-27 10:11:51,133] Trial 17 finished with value: 0.7629293306981465 and parameters: {'kernel': 'linear', 'C': 0.06940781905091782, 'gamma': 4727.939116939268, 'tol': 0.004978972714129722, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:51,374] Trial 18 finished with value: 0.7380909139469045 and parameters: {'kernel': 'linear', 'C': 0.029844251945198404, 'gamma': 225.73514472448375, 'tol': 0.0019824173256718417, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:51,619] Trial 19 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.00027691077097870596, 'gamma': 4031.9702766766736, 'tol': 0.004965404350596846, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:51,925] Trial 20 finished with value: 0.759820522407991 and parameters: {'kernel': 'linear', 'C': 0.07051163832006134, 'gamma': 4772.822147936632, 'tol': 0.0003758007014901863, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:52,247] Trial 21 finished with value: 0.7598044976229902 and parameters: {'kernel': 'linear', 'C': 0.09184388324484284, 'gamma': 6799.588947921624, 'tol': 0.00037354026369060164, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:52,765] Trial 22 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 8.748837201739542, 'gamma': 42.11276032694701, 'tol': 0.00010939309070782396, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:53,017] Trial 23 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0009187801364873082, 'gamma': 3892.3724462502582, 'tol': 0.00034442010885995627, 'shrinking': False}. Best is trial 17 with value: 0.7629293306981465.\n[I 2024-02-27 10:11:53,307] Trial 24 finished with value: 0.7660274557983013 and parameters: {'kernel': 'linear', 'C': 0.10483500551999021, 'gamma': 191.18963974567595, 'tol': 0.0014939355934541457, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:53,556] Trial 25 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.000700755040999588, 'gamma': 0.056086088016584636, 'tol': 0.003070726243562901, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:53,837] Trial 26 finished with value: 0.7567117141178356 and parameters: {'kernel': 'linear', 'C': 0.0885203240901346, 'gamma': 6.824021655083341, 'tol': 0.0015757059874397783, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:54,165] Trial 27 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 4.7116495476641305, 'gamma': 149.4831227020606, 'tol': 0.006307389633524393, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:54,540] Trial 28 finished with value: 0.6045456973452272 and parameters: {'kernel': 'poly', 'C': 72.49323326830735, 'gamma': 28.558570526825648, 'tol': 0.0036828629781881206, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:55,187] Trial 29 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.0026232398101447667, 'gamma': 1263.0984656599846, 'tol': 0.0007425962903428519, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:55,943] Trial 30 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.24027552352176437, 'gamma': 1113.611650519868, 'tol': 0.001620590379631135, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:56,186] Trial 31 finished with value: 0.7411943806420597 and parameters: {'kernel': 'linear', 'C': 0.032460744894318834, 'gamma': 16735.511723795244, 'tol': 0.0013741893968058185, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:56,422] Trial 32 finished with value: 0.7411943806420597 and parameters: {'kernel': 'linear', 'C': 0.03234214278705845, 'gamma': 2006.244254345038, 'tol': 0.002484035274441219, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:56,802] Trial 33 finished with value: 0.7650072111532504 and parameters: {'kernel': 'linear', 'C': 0.20057799497403303, 'gamma': 1.9959729762973195e-05, 'tol': 0.000349827689765765, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:57,148] Trial 34 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 3.093520041000231, 'gamma': 0.0005884046184942388, 'tol': 0.004022634598619916, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:57,513] Trial 35 finished with value: 0.5610544308530526 and parameters: {'kernel': 'poly', 'C': 0.2965191866903001, 'gamma': 0.03767908704868607, 'tol': 0.000708960719391765, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:57,738] Trial 36 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 1.1638469805866281e-05, 'gamma': 0.06060618853759603, 'tol': 0.0009045546220975205, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:58,080] Trial 37 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 1.5821729736078474, 'gamma': 0.00011104515994016068, 'tol': 0.006824865362307711, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:58,326] Trial 38 finished with value: 0.4948186528497409 and parameters: {'kernel': 'linear', 'C': 0.003759902403945141, 'gamma': 1.4420042380736035e-05, 'tol': 0.0002485419443543467, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:58,781] Trial 39 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 0.20094296340798848, 'gamma': 231.29951541117873, 'tol': 0.0009977893609129291, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:59,110] Trial 40 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 24.30420135234848, 'gamma': 1.4928003397473464, 'tol': 0.0012196213900458651, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:59,405] Trial 41 finished with value: 0.7619037444580952 and parameters: {'kernel': 'linear', 'C': 0.06683480147519019, 'gamma': 15340.64448484236, 'tol': 0.00045468831435129236, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:11:59,842] Trial 42 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 0.7902857751897362, 'gamma': 16800.58169501542, 'tol': 0.0004722208011876229, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:00,096] Trial 43 finished with value: 0.7225522140911276 and parameters: {'kernel': 'linear', 'C': 0.019965143338814363, 'gamma': 70424.6824073579, 'tol': 0.0002981007437503487, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:00,425] Trial 44 finished with value: 0.7598151808129907 and parameters: {'kernel': 'linear', 'C': 0.12601418159677855, 'gamma': 472.3942455772566, 'tol': 0.0004574551552294543, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:01,185] Trial 45 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.8632369298390428, 'gamma': 24746.11577706169, 'tol': 0.0002166579971244239, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:01,424] Trial 46 finished with value: 0.6852945889642648 and parameters: {'kernel': 'linear', 'C': 0.01464760244724118, 'gamma': 0.0096328714725387, 'tol': 0.0005854072042897301, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:01,862] Trial 47 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 0.002998341306890823, 'gamma': 8.3087617398722, 'tol': 0.002862814650062465, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:02,170] Trial 48 finished with value: 0.7525773195876289 and parameters: {'kernel': 'linear', 'C': 0.3690812024487456, 'gamma': 91.2609651638583, 'tol': 0.005889551976730727, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:02,582] Trial 49 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 1.347017683803884, 'gamma': 483.3419098646408, 'tol': 0.0008289118353316885, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:02,893] Trial 50 finished with value: 0.762940013888147 and parameters: {'kernel': 'linear', 'C': 0.06524592657600319, 'gamma': 0.3299306878005061, 'tol': 0.00016395856780707178, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:03,247] Trial 51 finished with value: 0.7618877196730944 and parameters: {'kernel': 'linear', 'C': 0.07863663177429595, 'gamma': 1.5835712206387974e-05, 'tol': 0.00016795292995699284, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:03,558] Trial 52 finished with value: 0.7577693499278885 and parameters: {'kernel': 'linear', 'C': 0.06168226310451504, 'gamma': 9.900557267069158e-05, 'tol': 0.00014295283850663713, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:03,854] Trial 53 finished with value: 0.7505208055125261 and parameters: {'kernel': 'linear', 'C': 0.04985139803368504, 'gamma': 1.2592875799504225e-05, 'tol': 0.0001588833900976221, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:04,109] Trial 54 finished with value: 0.631440628171572 and parameters: {'kernel': 'linear', 'C': 0.009076786691959418, 'gamma': 3.6068131787784605e-05, 'tol': 0.00010682988902293879, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:04,559] Trial 55 finished with value: 0.742219966882111 and parameters: {'kernel': 'linear', 'C': 0.48333367958636303, 'gamma': 0.0003950783754324634, 'tol': 0.00019507402211950663, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:04,808] Trial 56 finished with value: 0.6697665722984883 and parameters: {'kernel': 'linear', 'C': 0.012566204253284743, 'gamma': 0.0006293291236157527, 'tol': 0.0002512261598476617, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:05,311] Trial 57 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 2.236952679100639, 'gamma': 0.001495625402052451, 'tol': 0.00013765622196721322, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:05,612] Trial 58 finished with value: 0.7618823780780941 and parameters: {'kernel': 'linear', 'C': 0.14554813233181615, 'gamma': 0.3170689720639478, 'tol': 0.0002911180571706347, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:05,864] Trial 59 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0014363635160660323, 'gamma': 3.458766286822996e-05, 'tol': 0.0001907700984620175, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:06,193] Trial 60 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.00034573542279715873, 'gamma': 0.011945366866695195, 'tol': 0.0004514052884559821, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:06,487] Trial 61 finished with value: 0.7608461086480423 and parameters: {'kernel': 'linear', 'C': 0.13107660568607693, 'gamma': 0.1305655732784567, 'tol': 0.00029294807693504483, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:06,741] Trial 62 finished with value: 0.5310346669515518 and parameters: {'kernel': 'linear', 'C': 0.005000483137782339, 'gamma': 0.5230952224226539, 'tol': 0.00032218968714977053, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:06,984] Trial 63 finished with value: 0.7443031889322151 and parameters: {'kernel': 'linear', 'C': 0.037891039203974936, 'gamma': 2.74495305002161, 'tol': 0.0002546943124565439, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:07,280] Trial 64 finished with value: 0.7618930612680946 and parameters: {'kernel': 'linear', 'C': 0.17642485055552756, 'gamma': 0.8763366826186247, 'tol': 0.0003943466710786942, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:07,612] Trial 65 finished with value: 0.7432562363121628 and parameters: {'kernel': 'linear', 'C': 0.4766242752321781, 'gamma': 12.054078254106816, 'tol': 0.0005592756687441092, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:08,003] Trial 66 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 7.515104420891421, 'gamma': 4.1675066721949366e-05, 'tol': 0.00012623881121908296, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:08,398] Trial 67 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 0.07023877939057731, 'gamma': 2135.768296774034, 'tol': 0.0003801863677541726, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:08,655] Trial 68 finished with value: 0.7318732973665936 and parameters: {'kernel': 'linear', 'C': 0.02456417372637772, 'gamma': 11801.18823805899, 'tol': 0.0001848794173620122, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:09,057] Trial 69 finished with value: 0.7608621334330431 and parameters: {'kernel': 'linear', 'C': 0.21505190643927538, 'gamma': 0.796628584400803, 'tol': 0.0004092532933428287, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:09,305] Trial 70 finished with value: 0.5765877891138295 and parameters: {'kernel': 'linear', 'C': 0.00660390659026696, 'gamma': 0.0002828632263018781, 'tol': 0.0006652235694306128, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:09,546] Trial 71 finished with value: 0.7618823780780941 and parameters: {'kernel': 'linear', 'C': 0.1436058763064786, 'gamma': 0.31756636510863767, 'tol': 0.009657418149370156, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:09,820] Trial 72 finished with value: 0.7608514502430426 and parameters: {'kernel': 'linear', 'C': 0.07907106010331762, 'gamma': 0.11996771843732662, 'tol': 0.00016269577281086332, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:10,171] Trial 73 finished with value: 0.751541050157577 and parameters: {'kernel': 'linear', 'C': 0.4166331791029572, 'gamma': 0.022126546799045476, 'tol': 0.0002361786165236793, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:10,415] Trial 74 finished with value: 0.7235831419261791 and parameters: {'kernel': 'linear', 'C': 0.020958703863244027, 'gamma': 3.754200272705548, 'tol': 0.0003126978944402202, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:10,722] Trial 75 finished with value: 0.7546445168527323 and parameters: {'kernel': 'linear', 'C': 0.23653116358028853, 'gamma': 0.16834889166082348, 'tol': 0.0005333367059349245, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:11,104] Trial 76 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 0.9031611491900418, 'gamma': 1.3021434133560874, 'tol': 0.00028182019489361764, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:11,847] Trial 77 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.03787772557064613, 'gamma': 23.64153627446781, 'tol': 0.00035347355149974397, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:12,220] Trial 78 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 2.690348103041672, 'gamma': 37325.28846420372, 'tol': 0.0020987166824605282, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:12,517] Trial 79 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.11008018939948325, 'gamma': 0.0025587050146392044, 'tol': 0.00017580902303778633, 'shrinking': False}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:12,788] Trial 80 finished with value: 0.7608674750280434 and parameters: {'kernel': 'linear', 'C': 0.057342417798721124, 'gamma': 6974.813911384228, 'tol': 0.00011926299610329365, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:13,033] Trial 81 finished with value: 0.7618770364830938 and parameters: {'kernel': 'linear', 'C': 0.13769587458822885, 'gamma': 0.24227774182825523, 'tol': 0.008860132327729737, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:13,290] Trial 82 finished with value: 0.7618823780780941 and parameters: {'kernel': 'linear', 'C': 0.1531548487526283, 'gamma': 0.43222137859282383, 'tol': 0.004376918805017113, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:13,518] Trial 83 finished with value: 0.6811548528390577 and parameters: {'kernel': 'linear', 'C': 0.013713392200800098, 'gamma': 0.8309857826774161, 'tol': 0.007399014711129868, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:13,896] Trial 84 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 3326.7988802043433, 'gamma': 1.8972463697388293, 'tol': 0.0002084364783978587, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:14,171] Trial 85 finished with value: 0.7422359916671117 and parameters: {'kernel': 'linear', 'C': 0.5414001787098716, 'gamma': 0.06511535269440391, 'tol': 0.005860455587771514, 'shrinking': True}. Best is trial 24 with value: 0.7660274557983013.\n[I 2024-02-27 10:12:14,534] Trial 86 finished with value: 0.7660434805833022 and parameters: {'kernel': 'linear', 'C': 0.20225772002176173, 'gamma': 0.2582112290136897, 'tol': 0.0004965247482921393, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:14,981] Trial 87 finished with value: 0.74119972223706 and parameters: {'kernel': 'linear', 'C': 1.4011460405751748, 'gamma': 2.3720320142804793e-05, 'tol': 0.0004036551593765691, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:15,376] Trial 88 finished with value: 0.7505047807275252 and parameters: {'kernel': 'linear', 'C': 0.2993749121035286, 'gamma': 6.512025365886748e-05, 'tol': 0.0005206221181080749, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:15,634] Trial 89 finished with value: 0.7318732973665936 and parameters: {'kernel': 'linear', 'C': 0.025465722687792215, 'gamma': 83875.08168865545, 'tol': 0.00022164490473578768, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:15,977] Trial 90 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.08785608345355538, 'gamma': 0.0001973000169664676, 'tol': 0.0007853974797390238, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:16,256] Trial 91 finished with value: 0.7650018695582501 and parameters: {'kernel': 'linear', 'C': 0.18974473644488618, 'gamma': 0.3054752435053834, 'tol': 0.009299787122467356, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:16,657] Trial 92 finished with value: 0.7525773195876289 and parameters: {'kernel': 'linear', 'C': 0.25970866122427533, 'gamma': 0.08371174197241438, 'tol': 0.0004431130649267421, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:16,990] Trial 93 finished with value: 0.7391271833769564 and parameters: {'kernel': 'linear', 'C': 0.7287801631282834, 'gamma': 0.03656438201955695, 'tol': 0.005152155831511993, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:17,243] Trial 94 finished with value: 0.7422306500721115 and parameters: {'kernel': 'linear', 'C': 0.035973562191820505, 'gamma': 0.6293034738129885, 'tol': 0.0006495759474314921, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:17,520] Trial 95 finished with value: 0.7577640083328883 and parameters: {'kernel': 'linear', 'C': 0.0545602411556955, 'gamma': 3.6229345572961122, 'tol': 0.000510261354327328, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:17,763] Trial 96 finished with value: 0.6935687196196785 and parameters: {'kernel': 'linear', 'C': 0.016158705783576276, 'gamma': 0.20047572189292423, 'tol': 0.00026182121993410736, 'shrinking': False}. Best is trial 86 with value: 0.7660434805833022.\n[I 2024-02-27 10:12:18,125] Trial 97 finished with value: 0.767079750013354 and parameters: {'kernel': 'linear', 'C': 0.2038742930094989, 'gamma': 2818.1414528745645, 'tol': 0.0006052187746297819, 'shrinking': False}. Best is trial 97 with value: 0.767079750013354.\n[I 2024-02-27 10:12:18,506] Trial 98 finished with value: 0.6055766251802788 and parameters: {'kernel': 'poly', 'C': 13.205740511065896, 'gamma': 2447.053741992252, 'tol': 0.0011630186930258594, 'shrinking': False}. Best is trial 97 with value: 0.767079750013354.\n[I 2024-02-27 10:12:18,864] Trial 99 finished with value: 0.7411943806420597 and parameters: {'kernel': 'linear', 'C': 0.6023568852148631, 'gamma': 1074.7980696302923, 'tol': 0.003510571344251347, 'shrinking': False}. Best is trial 97 with value: 0.767079750013354.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'kernel': 'linear', 'C': 0.2038742930094989, 'gamma': 2818.1414528745645, 'tol': 0.0006052187746297819, 'shrinking': False}\naccuracy: 0.8229813664596274\nrecall: 0.7413857484712588\nprecision: 0.809884955736749\nf1-score: 0.7660375372917103\nroc_auc:  0.8532325827328578\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:12:19.000256Z","iopub.execute_input":"2024-02-27T10:12:19.000875Z","iopub.status.idle":"2024-02-27T10:12:19.013828Z","shell.execute_reply.started":"2024-02-27T10:12:19.000853Z","shell.execute_reply":"2024-02-27T10:12:19.012816Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"SVM - Modular PCA 4\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train_reduced, y_train)\ny_pred = dt.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:12:19.015446Z","iopub.execute_input":"2024-02-27T10:12:19.015658Z","iopub.status.idle":"2024-02-27T10:12:19.327682Z","shell.execute_reply.started":"2024-02-27T10:12:19.015639Z","shell.execute_reply":"2024-02-27T10:12:19.326657Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"accuracy: 0.36024844720496896\nrecall: 0.25488617292491383\nprecision: 0.25183401303367164\nf1-score: 0.25114847316902505\nroc_auc:  0.5684869124716337\naccuracy: 0.7732919254658385\nrecall: 0.6860788303823859\nprecision: 0.7300406004088043\nf1-score: 0.6995254022707311\nroc_auc:  0.8215152210812063\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 10),\n        \"min_samples_split\" : trial.suggest_int(\"min_samples_split\", 2, 20),\n        \"min_samples_leaf\" : trial.suggest_int(\"min_samples_leaf\", 1, 10),\n        \"criterion\" : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n        'random_state': trial.suggest_categorical('random_state', [42])\n\n    }\n\n    # Create KNN model with tuned hyperparameters\n    model = DecisionTreeClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:12:19.330361Z","iopub.execute_input":"2024-02-27T10:12:19.330695Z","iopub.status.idle":"2024-02-27T10:12:19.336953Z","shell.execute_reply.started":"2024-02-27T10:12:19.330657Z","shell.execute_reply":"2024-02-27T10:12:19.336065Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = DecisionTreeClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['decison tree'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Decision Tree'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:12:19.338107Z","iopub.execute_input":"2024-02-27T10:12:19.338405Z","iopub.status.idle":"2024-02-27T10:13:02.929333Z","shell.execute_reply.started":"2024-02-27T10:12:19.338379Z","shell.execute_reply":"2024-02-27T10:13:02.928494Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:12:19,348] A new study created in memory with name: no-name-8c971552-30a2-4521-8c5e-32e0c804c25f\n[I 2024-02-27 10:12:19,751] Trial 0 finished with value: 0.36847924790342396 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 0 with value: 0.36847924790342396.\n[I 2024-02-27 10:12:20,070] Trial 1 finished with value: 0.3923027616046151 and parameters: {'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 1 with value: 0.3923027616046151.\n[I 2024-02-27 10:12:20,587] Trial 2 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:21,252] Trial 3 finished with value: 0.37164147214358206 and parameters: {'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:21,617] Trial 4 finished with value: 0.35604935633780244 and parameters: {'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:22,319] Trial 5 finished with value: 0.36335131670316756 and parameters: {'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:23,084] Trial 6 finished with value: 0.3519363281875968 and parameters: {'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 1, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:23,368] Trial 7 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:23,710] Trial 8 finished with value: 0.37158805619357943 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:23,843] Trial 9 finished with value: 0.39648523048982426 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:24,365] Trial 10 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:24,889] Trial 11 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:25,412] Trial 12 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:25,931] Trial 13 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:26,524] Trial 14 finished with value: 0.3726563751936328 and parameters: {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 2 with value: 0.4120079055606004.\n[I 2024-02-27 10:12:26,938] Trial 15 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:27,356] Trial 16 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:27,649] Trial 17 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:28,333] Trial 18 finished with value: 0.3799102612039955 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:28,754] Trial 19 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:29,176] Trial 20 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:29,589] Trial 21 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:30,006] Trial 22 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:30,597] Trial 23 finished with value: 0.37368730302868436 and parameters: {'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:31,011] Trial 24 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:31,606] Trial 25 finished with value: 0.37368730302868436 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:31,757] Trial 26 finished with value: 0.39648523048982426 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:32,440] Trial 27 finished with value: 0.35508786923775437 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:32,858] Trial 28 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:33,151] Trial 29 finished with value: 0.38505955878425296 and parameters: {'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:33,451] Trial 30 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:33,863] Trial 31 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:34,297] Trial 32 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:34,718] Trial 33 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:35,240] Trial 34 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:35,566] Trial 35 finished with value: 0.38509160835425454 and parameters: {'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:35,864] Trial 36 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:36,376] Trial 37 finished with value: 0.41303883339565195 and parameters: {'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:36,798] Trial 38 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:37,193] Trial 39 finished with value: 0.35915816462795785 and parameters: {'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:37,895] Trial 40 finished with value: 0.3540729661877037 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:38,315] Trial 41 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:38,612] Trial 42 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:39,139] Trial 43 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:39,557] Trial 44 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:39,858] Trial 45 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:40,371] Trial 46 finished with value: 0.41303883339565195 and parameters: {'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:40,570] Trial 47 finished with value: 0.4047273115752364 and parameters: {'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:41,094] Trial 48 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:41,698] Trial 49 finished with value: 0.36954756690347734 and parameters: {'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:41,995] Trial 50 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:42,416] Trial 51 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:42,835] Trial 52 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:43,371] Trial 53 finished with value: 0.41303883339565195 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:43,795] Trial 54 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:44,094] Trial 55 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:44,618] Trial 56 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:44,918] Trial 57 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:45,127] Trial 58 finished with value: 0.4047273115752364 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:45,764] Trial 59 finished with value: 0.3716147641685807 and parameters: {'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 1, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:46,187] Trial 60 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:46,606] Trial 61 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:47,035] Trial 62 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:47,335] Trial 63 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:47,865] Trial 64 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:48,285] Trial 65 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:48,989] Trial 66 finished with value: 0.35508786923775437 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:49,514] Trial 67 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:49,715] Trial 68 finished with value: 0.4047273115752364 and parameters: {'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:50,021] Trial 69 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:50,548] Trial 70 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:50,967] Trial 71 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:51,387] Trial 72 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:51,804] Trial 73 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:52,104] Trial 74 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:52,702] Trial 75 finished with value: 0.37368730302868436 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:53,123] Trial 76 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:53,646] Trial 77 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:54,298] Trial 78 finished with value: 0.36334063351316703 and parameters: {'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:54,448] Trial 79 finished with value: 0.39648523048982426 and parameters: {'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:54,872] Trial 80 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:55,285] Trial 81 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:55,702] Trial 82 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:56,222] Trial 83 finished with value: 0.41303883339565195 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:56,641] Trial 84 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:56,940] Trial 85 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:57,471] Trial 86 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:57,890] Trial 87 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:58,188] Trial 88 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:58,605] Trial 89 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:59,150] Trial 90 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:59,567] Trial 91 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:12:59,981] Trial 92 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:00,400] Trial 93 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:00,699] Trial 94 finished with value: 0.4006303082100315 and parameters: {'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:00,898] Trial 95 finished with value: 0.4047273115752364 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:01,313] Trial 96 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:01,852] Trial 97 finished with value: 0.4120079055606004 and parameters: {'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 4, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:02,273] Trial 98 finished with value: 0.4285775332514289 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n[I 2024-02-27 10:13:02,812] Trial 99 finished with value: 0.41097163613054855 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 15 with value: 0.4285775332514289.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}\naccuracy: 0.40372670807453415\nrecall: 0.18543938538841048\nprecision: 0.10945797673908274\nf1-score: 0.13760079641612744\nroc_auc:  0.5277072914514944\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:13:02.930326Z","iopub.execute_input":"2024-02-27T10:13:02.930575Z","iopub.status.idle":"2024-02-27T10:13:02.943783Z","shell.execute_reply.started":"2024-02-27T10:13:02.930553Z","shell.execute_reply":"2024-02-27T10:13:02.942930Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Decision Tree - Modular PCA 4\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# KNN Classifier","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_reduced, y_train)\ny_pred = knn.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:02.944957Z","iopub.execute_input":"2024-02-27T10:13:02.945370Z","iopub.status.idle":"2024-02-27T10:13:03.026741Z","shell.execute_reply.started":"2024-02-27T10:13:02.945347Z","shell.execute_reply":"2024-02-27T10:13:03.026096Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"accuracy: 0.5217391304347826\nrecall: 0.3579375530567069\nprecision: 0.4443203499464842\nf1-score: 0.3513750358759977\nroc_auc:  0.6313629846736768\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'n_neighbors': trial.suggest_int(\"n_neighbors\", 5, 100),\n        'weights' : trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n        'metric' : trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"]),\n        'algorithm':trial.suggest_categorical('algorithm',['auto', 'ball_tree', 'kd_tree', 'brute']),\n        'n_jobs': -1\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = KNeighborsClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:03.027904Z","iopub.execute_input":"2024-02-27T10:13:03.028338Z","iopub.status.idle":"2024-02-27T10:13:03.033583Z","shell.execute_reply.started":"2024-02-27T10:13:03.028314Z","shell.execute_reply":"2024-02-27T10:13:03.032983Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 200)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model =KNeighborsClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['KNN'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'K-Nearest Neighbors'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall, f1,precision, roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:03.034544Z","iopub.execute_input":"2024-02-27T10:13:03.035150Z","iopub.status.idle":"2024-02-27T10:13:30.975444Z","shell.execute_reply.started":"2024-02-27T10:13:03.035128Z","shell.execute_reply":"2024-02-27T10:13:30.974435Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:13:03,043] A new study created in memory with name: no-name-770479be-cc70-456b-a9cb-b5935596bb81\n[I 2024-02-27 10:13:03,219] Trial 0 finished with value: 0.4803108808290156 and parameters: {'n_neighbors': 35, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.4803108808290156.\n[I 2024-02-27 10:13:03,410] Trial 1 finished with value: 0.5021045884301052 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 1 with value: 0.5021045884301052.\n[I 2024-02-27 10:13:03,614] Trial 2 finished with value: 0.5082954970354148 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:03,743] Trial 3 finished with value: 0.44822391966241115 and parameters: {'n_neighbors': 84, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:03,928] Trial 4 finished with value: 0.44822391966241115 and parameters: {'n_neighbors': 84, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:03,963] Trial 5 finished with value: 0.47721809732386083 and parameters: {'n_neighbors': 39, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:04,167] Trial 6 finished with value: 0.4575503445328775 and parameters: {'n_neighbors': 74, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:04,362] Trial 7 finished with value: 0.46995352812349767 and parameters: {'n_neighbors': 58, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:04,472] Trial 8 finished with value: 0.5010362694300519 and parameters: {'n_neighbors': 32, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:04,685] Trial 9 finished with value: 0.48238341968911913 and parameters: {'n_neighbors': 51, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.5082954970354148.\n[I 2024-02-27 10:13:04,850] Trial 10 finished with value: 0.5155547246407777 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 10 with value: 0.5155547246407777.\n[I 2024-02-27 10:13:05,019] Trial 11 finished with value: 0.5269216388013461 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:05,187] Trial 12 finished with value: 0.5155547246407777 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:05,394] Trial 13 finished with value: 0.5113882805405694 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:05,943] Trial 14 finished with value: 0.5134768441856739 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,152] Trial 15 finished with value: 0.4471983334223599 and parameters: {'n_neighbors': 98, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,323] Trial 16 finished with value: 0.5155547246407777 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,492] Trial 17 finished with value: 0.47306233641365314 and parameters: {'n_neighbors': 49, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,534] Trial 18 finished with value: 0.4927354307996367 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,576] Trial 19 finished with value: 0.4606431280380322 and parameters: {'n_neighbors': 65, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,745] Trial 20 finished with value: 0.4710165055285508 and parameters: {'n_neighbors': 42, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:06,915] Trial 21 finished with value: 0.507259227605363 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,090] Trial 22 finished with value: 0.509342449655467 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,255] Trial 23 finished with value: 0.4927354307996367 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,421] Trial 24 finished with value: 0.5134875273756744 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,584] Trial 25 finished with value: 0.507259227605363 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,752] Trial 26 finished with value: 0.4927354307996367 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,788] Trial 27 finished with value: 0.5114149885155708 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:07,824] Trial 28 finished with value: 0.5113882805405694 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,010] Trial 29 finished with value: 0.48032156401901605 and parameters: {'n_neighbors': 33, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,179] Trial 30 finished with value: 0.5114149885155708 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,342] Trial 31 finished with value: 0.5155547246407777 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,509] Trial 32 finished with value: 0.520720047006036 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,674] Trial 33 finished with value: 0.5145291384007266 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:08,853] Trial 34 finished with value: 0.5134821857806741 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:09,065] Trial 35 finished with value: 0.4968698253298435 and parameters: {'n_neighbors': 25, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:09,242] Trial 36 finished with value: 0.5145131136157256 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5269216388013461.\n[I 2024-02-27 10:13:09,370] Trial 37 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:09,503] Trial 38 finished with value: 0.49895838897494793 and parameters: {'n_neighbors': 39, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:09,632] Trial 39 finished with value: 0.5031088082901555 and parameters: {'n_neighbors': 31, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:09,760] Trial 40 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:09,885] Trial 41 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,014] Trial 42 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,144] Trial 43 finished with value: 0.5196730943859835 and parameters: {'n_neighbors': 22, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,275] Trial 44 finished with value: 0.5227712194861386 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,401] Trial 45 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,528] Trial 46 finished with value: 0.5072538860103627 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,656] Trial 47 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,793] Trial 48 finished with value: 0.45546178088777306 and parameters: {'n_neighbors': 79, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:10,933] Trial 49 finished with value: 0.46271566689813576 and parameters: {'n_neighbors': 66, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,076] Trial 50 finished with value: 0.5206933390310347 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,203] Trial 51 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,333] Trial 52 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,464] Trial 53 finished with value: 0.5196730943859835 and parameters: {'n_neighbors': 22, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,592] Trial 54 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 37 with value: 0.5476203194273811.\n[I 2024-02-27 10:13:11,721] Trial 55 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 55 with value: 0.5497142246674857.\n[I 2024-02-27 10:13:11,933] Trial 56 finished with value: 0.5238074889161904 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 55 with value: 0.5497142246674857.\n[I 2024-02-27 10:13:12,065] Trial 57 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 55 with value: 0.5497142246674857.\n[I 2024-02-27 10:13:12,191] Trial 58 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 55 with value: 0.5497142246674857.\n[I 2024-02-27 10:13:12,321] Trial 59 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:12,448] Trial 60 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:12,577] Trial 61 finished with value: 0.5455744885422787 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:12,719] Trial 62 finished with value: 0.4368463223118423 and parameters: {'n_neighbors': 100, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:12,850] Trial 63 finished with value: 0.5269056140163453 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:12,991] Trial 64 finished with value: 0.44408418353720414 and parameters: {'n_neighbors': 91, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,117] Trial 65 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,245] Trial 66 finished with value: 0.5455744885422787 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,374] Trial 67 finished with value: 0.5207093638160354 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,448] Trial 68 finished with value: 0.494861385609743 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,583] Trial 69 finished with value: 0.4834143475241707 and parameters: {'n_neighbors': 47, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,795] Trial 70 finished with value: 0.5269056140163453 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:13,928] Trial 71 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,061] Trial 72 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,193] Trial 73 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,322] Trial 74 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,458] Trial 75 finished with value: 0.4709844559585492 and parameters: {'n_neighbors': 57, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,583] Trial 76 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,658] Trial 77 finished with value: 0.494861385609743 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,783] Trial 78 finished with value: 0.5310506917365526 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:14,987] Trial 79 finished with value: 0.5217456332460872 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,118] Trial 80 finished with value: 0.5310506917365526 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,244] Trial 81 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,373] Trial 82 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,503] Trial 83 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,632] Trial 84 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,760] Trial 85 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:15,891] Trial 86 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,019] Trial 87 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,148] Trial 88 finished with value: 0.5331445969766572 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,224] Trial 89 finished with value: 0.49690721649484537 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,353] Trial 90 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,484] Trial 91 finished with value: 0.5331445969766572 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,613] Trial 92 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,744] Trial 93 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:16,874] Trial 94 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,007] Trial 95 finished with value: 0.5269056140163453 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,138] Trial 96 finished with value: 0.5206933390310347 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,267] Trial 97 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,399] Trial 98 finished with value: 0.5227925858661396 and parameters: {'n_neighbors': 24, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,530] Trial 99 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,742] Trial 100 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:17,872] Trial 101 finished with value: 0.5455744885422787 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,001] Trial 102 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,131] Trial 103 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,262] Trial 104 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,392] Trial 105 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,520] Trial 106 finished with value: 0.5310506917365526 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,656] Trial 107 finished with value: 0.45753966134287694 and parameters: {'n_neighbors': 72, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,736] Trial 108 finished with value: 0.5021045884301052 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:18,896] Trial 109 finished with value: 0.5248437583462422 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,024] Trial 110 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,154] Trial 111 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,285] Trial 112 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,415] Trial 113 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,543] Trial 114 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,672] Trial 115 finished with value: 0.5331445969766572 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,802] Trial 116 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:19,960] Trial 117 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,093] Trial 118 finished with value: 0.5238074889161904 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,222] Trial 119 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,353] Trial 120 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,483] Trial 121 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,612] Trial 122 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,769] Trial 123 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:20,897] Trial 124 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,107] Trial 125 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,235] Trial 126 finished with value: 0.5331445969766572 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,369] Trial 127 finished with value: 0.49065755034453284 and parameters: {'n_neighbors': 44, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,495] Trial 128 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,623] Trial 129 finished with value: 0.5269056140163453 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,700] Trial 130 finished with value: 0.5021045884301052 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,830] Trial 131 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:21,956] Trial 132 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,087] Trial 133 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,219] Trial 134 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,355] Trial 135 finished with value: 0.49688585011484426 and parameters: {'n_neighbors': 37, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,486] Trial 136 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,643] Trial 137 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,772] Trial 138 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:22,900] Trial 139 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,029] Trial 140 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,164] Trial 141 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,295] Trial 142 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,425] Trial 143 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,555] Trial 144 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,685] Trial 145 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:23,816] Trial 146 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,023] Trial 147 finished with value: 0.47305165322365256 and parameters: {'n_neighbors': 55, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,157] Trial 148 finished with value: 0.5310506917365526 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,261] Trial 149 finished with value: 0.46271566689813576 and parameters: {'n_neighbors': 64, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,336] Trial 150 finished with value: 0.49175791891458787 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,464] Trial 151 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,589] Trial 152 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,724] Trial 153 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,855] Trial 154 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:24,984] Trial 155 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,114] Trial 156 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,256] Trial 157 finished with value: 0.4451151113722557 and parameters: {'n_neighbors': 90, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,331] Trial 158 finished with value: 0.5021045884301052 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,459] Trial 159 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,691] Trial 160 finished with value: 0.5331445969766572 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,822] Trial 161 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:25,954] Trial 162 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,086] Trial 163 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,215] Trial 164 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,341] Trial 165 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,468] Trial 166 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,595] Trial 167 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,724] Trial 168 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,850] Trial 169 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:26,981] Trial 170 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,110] Trial 171 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,267] Trial 172 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,396] Trial 173 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,524] Trial 174 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,655] Trial 175 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,787] Trial 176 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:27,876] Trial 177 finished with value: 0.5528176913626409 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,011] Trial 178 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,221] Trial 179 finished with value: 0.5424549970621229 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,354] Trial 180 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,485] Trial 181 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,615] Trial 182 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,753] Trial 183 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:28,919] Trial 184 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,055] Trial 185 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,218] Trial 186 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,295] Trial 187 finished with value: 0.494861385609743 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,428] Trial 188 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,557] Trial 189 finished with value: 0.5455531221622778 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,688] Trial 190 finished with value: 0.5310506917365526 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,817] Trial 191 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:29,948] Trial 192 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,029] Trial 193 finished with value: 0.494861385609743 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,161] Trial 194 finished with value: 0.5497142246674857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,293] Trial 195 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,526] Trial 196 finished with value: 0.5476203194273811 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,663] Trial 197 finished with value: 0.539362213556968 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,792] Trial 198 finished with value: 0.5538325944126916 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n[I 2024-02-27 10:13:30,923] Trial 199 finished with value: 0.5144970888307249 and parameters: {'n_neighbors': 28, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 59 with value: 0.5538325944126916.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}\naccuracy: 0.5714285714285714\nrecall: 0.39584183757753283\nprecision: 0.5327985506556935\nf1-score: 0.40724846160411915\nroc_auc:  0.6535381266764505\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:30.980705Z","iopub.execute_input":"2024-02-27T10:13:30.980977Z","iopub.status.idle":"2024-02-27T10:13:30.993266Z","shell.execute_reply.started":"2024-02-27T10:13:30.980955Z","shell.execute_reply":"2024-02-27T10:13:30.992311Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"K-Nearest Neighbors - Modular PCA 4\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Gaussian NB","metadata":{}},{"cell_type":"markdown","source":"**Pre-tunning**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train_reduced, y_train)\n\ny_pred = gnb.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovr')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:30.994805Z","iopub.execute_input":"2024-02-27T10:13:30.995189Z","iopub.status.idle":"2024-02-27T10:13:31.014267Z","shell.execute_reply.started":"2024-02-27T10:13:30.995163Z","shell.execute_reply":"2024-02-27T10:13:31.013409Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"accuracy: 0.6863354037267081\nrecall: 0.5661784269659892\nprecision: 0.6666803891578297\nf1-score: 0.588131087739933\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    hyperparams = {\n        'var_smoothing': trial.suggest_float('var_smoothing', 1e-9, 1e-4, log = True)\n    }\n    \n    model = GaussianNB(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:31.015367Z","iopub.execute_input":"2024-02-27T10:13:31.015686Z","iopub.status.idle":"2024-02-27T10:13:31.021273Z","shell.execute_reply.started":"2024-02-27T10:13:31.015642Z","shell.execute_reply":"2024-02-27T10:13:31.020317Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = GaussianNB(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['gnb'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Gaussian Naives Bayes'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-27T10:13:31.022305Z","iopub.execute_input":"2024-02-27T10:13:31.022564Z","iopub.status.idle":"2024-02-27T10:13:32.990034Z","shell.execute_reply.started":"2024-02-27T10:13:31.022541Z","shell.execute_reply":"2024-02-27T10:13:32.989016Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:13:31,028] A new study created in memory with name: no-name-6aca5521-e9a3-4732-b789-0fc87ad85033\n[I 2024-02-27 10:13:31,047] Trial 0 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 3.647383468687307e-09}. Best is trial 0 with value: 0.6252871107312643.\n[I 2024-02-27 10:13:31,062] Trial 1 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.0527007102533975e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,077] Trial 2 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.0545466422952066e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,093] Trial 3 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 3.61790106587869e-08}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,108] Trial 4 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 1.2146795996823164e-09}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,125] Trial 5 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 3.7173470717794195e-06}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,140] Trial 6 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.855511771082056e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,158] Trial 7 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 1.2395278357703472e-07}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,174] Trial 8 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 3.311053168246047e-06}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,190] Trial 9 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 3.050578508831065e-08}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,210] Trial 10 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 2.1846474168862e-06}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,230] Trial 11 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 8.036656793312153e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,250] Trial 12 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.2600524000841136e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,272] Trial 13 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 5.622755316160985e-07}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,292] Trial 14 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.4562426948580396e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,315] Trial 15 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.120850871136879e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,337] Trial 16 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 5.690138371514646e-07}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,358] Trial 17 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 9.354929886949771e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,380] Trial 18 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 5.946723900538174e-06}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,400] Trial 19 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 1.0918265111600579e-06}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,422] Trial 20 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.3739361705356985e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,441] Trial 21 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.978371649542142e-05}. Best is trial 1 with value: 0.6263180385663158.\n[I 2024-02-27 10:13:31,461] Trial 22 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.5302347340501643e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,480] Trial 23 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 6.458440680090639e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,500] Trial 24 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 8.659077622714638e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,521] Trial 25 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.51423281915778e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,542] Trial 26 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 9.123288150120013e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,562] Trial 27 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.976486044347508e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,585] Trial 28 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 2.1952769279031546e-07}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,605] Trial 29 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 1.7606617154764272e-08}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,627] Trial 30 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.5793113871457546e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,646] Trial 31 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.4227880316320994e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,667] Trial 32 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.5225838534322986e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,687] Trial 33 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.043158665391484e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,708] Trial 34 finished with value: 0.6273489664013674 and parameters: {'var_smoothing': 9.951526839125769e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,730] Trial 35 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 8.558020017806345e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,749] Trial 36 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.207744855675205e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,769] Trial 37 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 5.382776362053465e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,788] Trial 38 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 6.57548719554302e-09}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,806] Trial 39 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 8.75128969486463e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,824] Trial 40 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 1.3865756511308095e-09}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,846] Trial 41 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 5.121356449926596e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,867] Trial 42 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.5048826288329372e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,886] Trial 43 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 4.462500757407524e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,909] Trial 44 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.7348996412731086e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,931] Trial 45 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.222924006311018e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,952] Trial 46 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 5.2539062353553384e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,972] Trial 47 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.4044145109658666e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:31,991] Trial 48 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.668536839506492e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,009] Trial 49 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.194859991116855e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,028] Trial 50 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.2714234598608034e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,046] Trial 51 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.8784987293652816e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,066] Trial 52 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 2.735431983187514e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,085] Trial 53 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.513128004944718e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,105] Trial 54 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 9.50644472359233e-08}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,124] Trial 55 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 1.7862907586196545e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,143] Trial 56 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.314137396078511e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,162] Trial 57 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 8.896686033978512e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,181] Trial 58 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 7.038743031769846e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,200] Trial 59 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 2.32724796840435e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,219] Trial 60 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.1535517207787316e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,238] Trial 61 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.6896862974385317e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,257] Trial 62 finished with value: 0.6273489664013674 and parameters: {'var_smoothing': 9.901694804138033e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,275] Trial 63 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.312614034181238e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,294] Trial 64 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.989863594670504e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,313] Trial 65 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.0420798924788353e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,332] Trial 66 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.772974701548654e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,353] Trial 67 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 7.629004484102373e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,374] Trial 68 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.0979481821833589e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,393] Trial 69 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 1.8419263603646023e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,412] Trial 70 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 5.137892049685707e-06}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,430] Trial 71 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 7.009405366660696e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,450] Trial 72 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.159353615088178e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,469] Trial 73 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 2.9178689303141517e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,488] Trial 74 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.1121241170261965e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,508] Trial 75 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 7.355785914385491e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,527] Trial 76 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.4517720757295704e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,547] Trial 77 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.514126824996053e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,566] Trial 78 finished with value: 0.6273489664013674 and parameters: {'var_smoothing': 9.703183501643799e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,586] Trial 79 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 9.213985036695174e-07}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,605] Trial 80 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.196514757771796e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,624] Trial 81 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.933497742925556e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,643] Trial 82 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 5.858350206099554e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,662] Trial 83 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.716021208814857e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,681] Trial 84 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 7.087203040177284e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,702] Trial 85 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.6392178295445155e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,723] Trial 86 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 2.6437670971737038e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,743] Trial 87 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 8.18874788104887e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,762] Trial 88 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.933415320044014e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,780] Trial 89 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 5.234822837186101e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,799] Trial 90 finished with value: 0.6252871107312643 and parameters: {'var_smoothing': 5.1280490635715324e-08}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,818] Trial 91 finished with value: 0.6273489664013674 and parameters: {'var_smoothing': 9.985400289585009e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,837] Trial 92 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 5.1672171017824653e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,855] Trial 93 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 6.107030844599781e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,874] Trial 94 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 3.415376399666983e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,893] Trial 95 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 2.2842510779216604e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,912] Trial 96 finished with value: 0.6273543079963677 and parameters: {'var_smoothing': 7.224136830089712e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,931] Trial 97 finished with value: 0.6263180385663158 and parameters: {'var_smoothing': 4.075604876152238e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,950] Trial 98 finished with value: 0.6242508413012124 and parameters: {'var_smoothing': 1.0902784541399636e-05}. Best is trial 22 with value: 0.6273543079963677.\n[I 2024-02-27 10:13:32,968] Trial 99 finished with value: 0.625281769136264 and parameters: {'var_smoothing': 1.895007182461151e-05}. Best is trial 22 with value: 0.6273543079963677.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'var_smoothing': 5.5302347340501643e-05}\naccuracy: 0.6894409937888198\nrecall: 0.5736972239584703\nprecision: 0.6689707907770904\nf1-score: 0.5955621975549148\nroc_auc:  0.756986066481303\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:32.990868Z","iopub.execute_input":"2024-02-27T10:13:32.991081Z","iopub.status.idle":"2024-02-27T10:13:33.002643Z","shell.execute_reply.started":"2024-02-27T10:13:32.991061Z","shell.execute_reply":"2024-02-27T10:13:33.001957Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Gaussian Naives Bayes - Modular PCA 4\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train_reduced, y_train)\ny_pred = lr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# # One-hot encoding for probability calculation (adapt if necessary)\n# y_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\n# y_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:33.003624Z","iopub.execute_input":"2024-02-27T10:13:33.003868Z","iopub.status.idle":"2024-02-27T10:13:33.096554Z","shell.execute_reply.started":"2024-02-27T10:13:33.003848Z","shell.execute_reply":"2024-02-27T10:13:33.095852Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"accuracy: 0.8260869565217391\nrecall: 0.7370674129499158\nprecision: 0.8005931766064412\nf1-score: 0.7638506690107051\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'saga']),\n        'penalty': trial.suggest_categorical('penalty', ['l2']),\n        'multi_class': trial.suggest_categorical('multi_class', ['ovr']),\n        'C': trial.suggest_loguniform(\"C\", 1e-3, 1e3),\n        'n_jobs': -1\n    }\n\n    model = LogisticRegression(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:13:33.099621Z","iopub.execute_input":"2024-02-27T10:13:33.100244Z","iopub.status.idle":"2024-02-27T10:13:33.106743Z","shell.execute_reply.started":"2024-02-27T10:13:33.100218Z","shell.execute_reply":"2024-02-27T10:13:33.105892Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = LogisticRegression(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['logistic regression'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Logistic Regression'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-27T10:13:33.107802Z","iopub.execute_input":"2024-02-27T10:13:33.108594Z","iopub.status.idle":"2024-02-27T10:16:06.248524Z","shell.execute_reply.started":"2024-02-27T10:13:33.108570Z","shell.execute_reply":"2024-02-27T10:16:06.247796Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:13:33,116] A new study created in memory with name: no-name-8636ab50-5455-42a5-af2e-146eb247b35f\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n[I 2024-02-27 10:13:34,390] Trial 0 finished with value: 0.7660488221783025 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.5468674212993465}. Best is trial 0 with value: 0.7660488221783025.\n[I 2024-02-27 10:13:36,387] Trial 1 finished with value: 0.7733133913786657 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9597499641914542}. Best is trial 1 with value: 0.7733133913786657.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[I 2024-02-27 10:13:36,958] Trial 2 finished with value: 0.7556861278777843 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 371.2142334171926}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:39,652] Trial 3 finished with value: 0.7670850916083543 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 344.7840982404925}. Best is trial 1 with value: 0.7733133913786657.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:13:39,982] Trial 4 finished with value: 0.4202873778110144 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0011110115022985798}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:40,132] Trial 5 finished with value: 0.5796912558089845 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.010885474589719987}. Best is trial 1 with value: 0.7733133913786657.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:13:40,461] Trial 6 finished with value: 0.4823673949041184 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.003592523269138987}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:40,900] Trial 7 finished with value: 0.7235991667111799 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.07518957496215602}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:41,367] Trial 8 finished with value: 0.7577586667378879 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 193.8407515093524}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:41,505] Trial 9 finished with value: 0.4213236472410662 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0011497172575200174}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:44,127] Trial 10 finished with value: 0.7660541637733027 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.3686498348500082}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:46,584] Trial 11 finished with value: 0.7681267026334064 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 17.48865961696636}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:50,064] Trial 12 finished with value: 0.7670904332033546 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 15.811029395302905}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:52,349] Trial 13 finished with value: 0.7567437636878372 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1787785669524107}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:54,832] Trial 14 finished with value: 0.7681213610384061 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 18.743943415608406}. Best is trial 1 with value: 0.7733133913786657.\n[I 2024-02-27 10:13:56,355] Trial 15 finished with value: 0.775380588643769 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.23282682335847538}. Best is trial 15 with value: 0.775380588643769.\n[I 2024-02-27 10:13:57,735] Trial 16 finished with value: 0.766059505368303 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.17493173382366867}. Best is trial 15 with value: 0.775380588643769.\n[I 2024-02-27 10:13:58,590] Trial 17 finished with value: 0.6935740612146787 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.019914109081506873}. Best is trial 15 with value: 0.775380588643769.\n[I 2024-02-27 10:14:00,304] Trial 18 finished with value: 0.7764168580738209 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.41010185842735813}. Best is trial 18 with value: 0.7764168580738209.\n[I 2024-02-27 10:14:02,018] Trial 19 finished with value: 0.7764168580738209 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.40322042847551315}. Best is trial 18 with value: 0.7764168580738209.\n[I 2024-02-27 10:14:02,961] Trial 20 finished with value: 0.7090860530954542 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.027420316663811214}. Best is trial 18 with value: 0.7764168580738209.\n[I 2024-02-27 10:14:04,779] Trial 21 finished with value: 0.7722878051386144 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5553951298145688}. Best is trial 18 with value: 0.7764168580738209.\n[I 2024-02-27 10:14:06,385] Trial 22 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2943418963976298}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:09,408] Trial 23 finished with value: 0.7660541637733027 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 6.317681638313909}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:10,638] Trial 24 finished with value: 0.7360290582768014 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.06252669542451782}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:12,358] Trial 25 finished with value: 0.7764168580738209 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4111779810145578}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:14,834] Trial 26 finished with value: 0.765017894343251 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.532576543598519}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:16,027] Trial 27 finished with value: 0.7505368302975268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.07771616128172197}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:17,922] Trial 28 finished with value: 0.7743496608087175 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7352350962605726}. Best is trial 22 with value: 0.7795203247689759.\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n[I 2024-02-27 10:14:18,304] Trial 29 finished with value: 0.7639762833181989 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 94.41176771400055}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:18,637] Trial 30 finished with value: 0.7670850916083543 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.6379537329134402}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:20,153] Trial 31 finished with value: 0.7743443192137172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.22709522066412904}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:21,910] Trial 32 finished with value: 0.7733133913786656 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5038545413318337}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:23,986] Trial 33 finished with value: 0.7691629720634582 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.1307215155412675}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:26,893] Trial 34 finished with value: 0.7670904332033546 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 5.578989341037121}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:28,614] Trial 35 finished with value: 0.7774531275038725 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.41425169558073527}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:29,675] Trial 36 finished with value: 0.719459430585973 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.04407923489109781}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:30,334] Trial 37 finished with value: 0.5434431921371722 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.007489460441738624}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:30,757] Trial 38 finished with value: 0.7432776026921639 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.11681340898533724}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:32,454] Trial 39 finished with value: 0.7774477859088724 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.38794704584562056}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:32,763] Trial 40 finished with value: 0.7660488221783025 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.4657179651333863}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:34,457] Trial 41 finished with value: 0.778478713743924 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.36414650823211475}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:36,037] Trial 42 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2770342912122529}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:37,309] Trial 43 finished with value: 0.7588269857379414 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.11462354848908309}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:37,712] Trial 44 finished with value: 0.6707975001335399 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.03058071675202855}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:40,263] Trial 45 finished with value: 0.7660541637733027 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.0900086124966797}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:42,198] Trial 46 finished with value: 0.7743496608087176 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.8104481482463852}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:44,596] Trial 47 finished with value: 0.7588163025479409 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1921587756859986}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:45,419] Trial 48 finished with value: 0.680118583409006 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.01681229342367707}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:45,853] Trial 49 finished with value: 0.7660488221783025 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3025792670955001}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:47,110] Trial 50 finished with value: 0.7557128358527857 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.10199472245217213}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:49,075] Trial 51 finished with value: 0.7743496608087176 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9136461815030615}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:50,751] Trial 52 finished with value: 0.7774477859088724 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3391387154530487}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:52,107] Trial 53 finished with value: 0.766059505368303 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1612715428649681}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:54,379] Trial 54 finished with value: 0.7691629720634582 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.541641861349456}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:55,494] Trial 55 finished with value: 0.7277442444313872 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.05367928161050347}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:55,878] Trial 56 finished with value: 0.7525826611826292 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 932.9428650404817}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:57,487] Trial 57 finished with value: 0.7784840553389242 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.30372465148866895}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:14:59,962] Trial 58 finished with value: 0.7681320442284066 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5777231317090942}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:01,574] Trial 59 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2940280023805469}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:02,897] Trial 60 finished with value: 0.7639976496981999 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.13421370765292898}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:04,498] Trial 61 finished with value: 0.7784893969339244 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.27212963436215537}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:06,103] Trial 62 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2870949056986523}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:07,680] Trial 63 finished with value: 0.7784893969339244 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2692286116678819}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:08,860] Trial 64 finished with value: 0.7505368302975268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.07745209113873495}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:10,406] Trial 65 finished with value: 0.7764115164788206 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.24224270664861533}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:11,444] Trial 66 finished with value: 0.7204903584210245 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.040956194677132025}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:13,313] Trial 67 finished with value: 0.7733133913786656 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6931499423998684}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:13,724] Trial 68 finished with value: 0.7588056193579403 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2441317873490035}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:14,938] Trial 69 finished with value: 0.7526093691576305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.08670800280003092}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:17,266] Trial 70 finished with value: 0.7681267026334064 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.7708672266036634}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:18,634] Trial 71 finished with value: 0.766059505368303 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.15904931848466786}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:20,690] Trial 72 finished with value: 0.7691683136584585 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.0724986407432437}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:22,290] Trial 73 finished with value: 0.7784893969339244 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2736344058932596}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:23,885] Trial 74 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.28521706250176077}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:24,157] Trial 75 finished with value: 0.7670957747983549 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5490240765479879}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:25,633] Trial 76 finished with value: 0.7722717803536137 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.20260499672837862}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:26,754] Trial 77 finished with value: 0.7339565194166978 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.060368660744171826}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:28,693] Trial 78 finished with value: 0.7494952192724748 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1361660233921901}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:31,627] Trial 79 finished with value: 0.7670904332033546 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 5.499333479341932}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:33,507] Trial 80 finished with value: 0.7733133913786656 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7075138180951521}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:35,115] Trial 81 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.29162390824618517}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:36,708] Trial 82 finished with value: 0.7784893969339244 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2718806595131146}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:38,489] Trial 83 finished with value: 0.7733133913786656 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4958194249255171}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:40,578] Trial 84 finished with value: 0.7691629720634582 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.1285734333637334}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:41,809] Trial 85 finished with value: 0.7546819080177342 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.09197982625139334}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:44,262] Trial 86 finished with value: 0.7660541637733027 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.302808380167688}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:45,682] Trial 87 finished with value: 0.766059505368303 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.18256272071757}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:47,440] Trial 88 finished with value: 0.7753859302387693 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4687784554443617}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:47,684] Trial 89 finished with value: 0.769157630468458 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3380246094856656}. Best is trial 22 with value: 0.7795203247689759.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:15:48,007] Trial 90 finished with value: 0.4503018001175151 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0020332250480580077}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:49,580] Trial 91 finished with value: 0.7784893969339244 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2673919502385252}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:50,893] Trial 92 finished with value: 0.7629613802681481 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1299555383794738}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:52,480] Trial 93 finished with value: 0.7795203247689759 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.27902817201483765}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:54,386] Trial 94 finished with value: 0.7743496608087176 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7949105663934253}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:55,928] Trial 95 finished with value: 0.7743443192137172 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2280856833299725}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:57,202] Trial 96 finished with value: 0.7577907163078896 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.11077816755727003}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:15:59,685] Trial 97 finished with value: 0.7712355109235618 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.39948701957034305}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:16:01,504] Trial 98 finished with value: 0.7712461941135623 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6162383079110147}. Best is trial 22 with value: 0.7795203247689759.\n[I 2024-02-27 10:16:05,813] Trial 99 finished with value: 0.7577640083328883 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 71.02176446922968}. Best is trial 22 with value: 0.7795203247689759.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2943418963976298}\naccuracy: 0.8416149068322981\nrecall: 0.7430625595465662\nprecision: 0.8341664313468825\nf1-score: 0.7778779861245309\nroc_auc:  0.8555528859911625\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:16:06.249561Z","iopub.execute_input":"2024-02-27T10:16:06.250290Z","iopub.status.idle":"2024-02-27T10:16:06.261501Z","shell.execute_reply.started":"2024-02-27T10:16:06.250262Z","shell.execute_reply":"2024-02-27T10:16:06.260718Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Logistic Regression - Modular PCA 4\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:16:06.262579Z","iopub.execute_input":"2024-02-27T10:16:06.263041Z","iopub.status.idle":"2024-02-27T10:16:06.327482Z","shell.execute_reply.started":"2024-02-27T10:16:06.263014Z","shell.execute_reply":"2024-02-27T10:16:06.326737Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestClassifier(random_state=42)\nrfr.fit(X_train_reduced,y_train)\ny_pred = rfr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:16:06.331288Z","iopub.execute_input":"2024-02-27T10:16:06.333066Z","iopub.status.idle":"2024-02-27T10:16:07.197487Z","shell.execute_reply.started":"2024-02-27T10:16:06.333035Z","shell.execute_reply":"2024-02-27T10:16:07.196695Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"accuracy: 0.5062111801242236\nrecall: 0.22073110540677762\nprecision: 0.47349709114415\nf1-score: 0.1960425280157361\nroc_auc:  0.5026446351954662\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\n\n\ndef objective(trial):\n    hyperparams = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'max_depth': trial.suggest_int('max_depth', 10, 50),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n        'random_state': trial.suggest_categorical('random_state', [42]),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n        'n_jobs': -1\n    }\n\n    model = RandomForestClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:16:07.198526Z","iopub.execute_input":"2024-02-27T10:16:07.199203Z","iopub.status.idle":"2024-02-27T10:16:07.205037Z","shell.execute_reply.started":"2024-02-27T10:16:07.199175Z","shell.execute_reply":"2024-02-27T10:16:07.204157Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\naccuracy_score(y_test, y_pred)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-27T10:16:07.206242Z","iopub.execute_input":"2024-02-27T10:16:07.206480Z","iopub.status.idle":"2024-02-27T10:28:08.152219Z","shell.execute_reply.started":"2024-02-27T10:16:07.206456Z","shell.execute_reply":"2024-02-27T10:28:08.149814Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:16:07,214] A new study created in memory with name: no-name-953aaaff-9b0c-4838-833b-bcb9cd997238\n[I 2024-02-27 10:16:21,745] Trial 0 finished with value: 0.42340152769617 and parameters: {'n_estimators': 938, 'max_depth': 48, 'min_samples_split': 16, 'random_state': 42, 'min_samples_leaf': 24}. Best is trial 0 with value: 0.42340152769617.\n[I 2024-02-27 10:16:26,591] Trial 1 finished with value: 0.41822018054591104 and parameters: {'n_estimators': 335, 'max_depth': 42, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 32}. Best is trial 0 with value: 0.42340152769617.\n[I 2024-02-27 10:16:41,484] Trial 2 finished with value: 0.43583141926179153 and parameters: {'n_estimators': 866, 'max_depth': 38, 'min_samples_split': 32, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.43583141926179153.\n[I 2024-02-27 10:16:55,006] Trial 3 finished with value: 0.4327226109716361 and parameters: {'n_estimators': 840, 'max_depth': 40, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.43583141926179153.\n[I 2024-02-27 10:17:01,542] Trial 4 finished with value: 0.4347951498317397 and parameters: {'n_estimators': 385, 'max_depth': 43, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 12}. Best is trial 2 with value: 0.43583141926179153.\n[I 2024-02-27 10:17:33,617] Trial 6 finished with value: 0.43065007211153244 and parameters: {'n_estimators': 940, 'max_depth': 19, 'min_samples_split': 17, 'random_state': 42, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.4410127664120506.\n[I 2024-02-27 10:17:48,039] Trial 7 finished with value: 0.4337588804016879 and parameters: {'n_estimators': 862, 'max_depth': 28, 'min_samples_split': 31, 'random_state': 42, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.4410127664120506.\n[I 2024-02-27 10:17:55,269] Trial 8 finished with value: 0.41925644997596284 and parameters: {'n_estimators': 493, 'max_depth': 26, 'min_samples_split': 31, 'random_state': 42, 'min_samples_leaf': 31}. Best is trial 5 with value: 0.4410127664120506.\n[I 2024-02-27 10:18:02,367] Trial 9 finished with value: 0.42029271940601465 and parameters: {'n_estimators': 473, 'max_depth': 24, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 28}. Best is trial 5 with value: 0.4410127664120506.\n[I 2024-02-27 10:18:04,436] Trial 10 finished with value: 0.4430746220821537 and parameters: {'n_estimators': 109, 'max_depth': 50, 'min_samples_split': 23, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.4430746220821537.\n[I 2024-02-27 10:18:06,526] Trial 11 finished with value: 0.447219699802361 and parameters: {'n_estimators': 105, 'max_depth': 49, 'min_samples_split': 23, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.447219699802361.\n[I 2024-02-27 10:18:08,567] Trial 12 finished with value: 0.4420383526521019 and parameters: {'n_estimators': 104, 'max_depth': 10, 'min_samples_split': 25, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.447219699802361.\n[I 2024-02-27 10:18:11,121] Trial 13 finished with value: 0.4503178249025159 and parameters: {'n_estimators': 128, 'max_depth': 34, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:15,667] Trial 14 finished with value: 0.44618877196730944 and parameters: {'n_estimators': 238, 'max_depth': 35, 'min_samples_split': 26, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:27,127] Trial 15 finished with value: 0.43997115538699855 and parameters: {'n_estimators': 648, 'max_depth': 32, 'min_samples_split': 21, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:31,454] Trial 16 finished with value: 0.4379039581218952 and parameters: {'n_estimators': 240, 'max_depth': 18, 'min_samples_split': 27, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:41,915] Trial 17 finished with value: 0.4275466054163773 and parameters: {'n_estimators': 675, 'max_depth': 33, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 22}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:45,845] Trial 18 finished with value: 0.44307996367715397 and parameters: {'n_estimators': 213, 'max_depth': 45, 'min_samples_split': 20, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:51,412] Trial 19 finished with value: 0.43583141926179153 and parameters: {'n_estimators': 329, 'max_depth': 37, 'min_samples_split': 28, 'random_state': 42, 'min_samples_leaf': 13}. Best is trial 13 with value: 0.4503178249025159.\n[I 2024-02-27 10:18:55,576] Trial 20 finished with value: 0.45860798034293043 and parameters: {'n_estimators': 197, 'max_depth': 19, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:18:58,992] Trial 21 finished with value: 0.45653544148282676 and parameters: {'n_estimators': 165, 'max_depth': 10, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:02,581] Trial 22 finished with value: 0.4399764969819988 and parameters: {'n_estimators': 188, 'max_depth': 11, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:08,917] Trial 23 finished with value: 0.45136477752256826 and parameters: {'n_estimators': 325, 'max_depth': 15, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:14,944] Trial 24 finished with value: 0.45240104695262007 and parameters: {'n_estimators': 312, 'max_depth': 14, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:22,521] Trial 25 finished with value: 0.4378986165268949 and parameters: {'n_estimators': 435, 'max_depth': 14, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:27,645] Trial 26 finished with value: 0.4472143582073607 and parameters: {'n_estimators': 285, 'max_depth': 21, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:30,851] Trial 27 finished with value: 0.4368623470968431 and parameters: {'n_estimators': 190, 'max_depth': 14, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 15}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:42,418] Trial 28 finished with value: 0.4503338496875166 and parameters: {'n_estimators': 594, 'max_depth': 17, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:46,601] Trial 29 finished with value: 0.4265103359863255 and parameters: {'n_estimators': 262, 'max_depth': 21, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 21}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:53,596] Trial 30 finished with value: 0.4389295443619464 and parameters: {'n_estimators': 399, 'max_depth': 13, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:19:59,711] Trial 31 finished with value: 0.45032850809251646 and parameters: {'n_estimators': 309, 'max_depth': 16, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:03,048] Trial 32 finished with value: 0.4482559692324128 and parameters: {'n_estimators': 170, 'max_depth': 12, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:09,717] Trial 33 finished with value: 0.4503338496875167 and parameters: {'n_estimators': 366, 'max_depth': 23, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:15,357] Trial 34 finished with value: 0.44618877196730944 and parameters: {'n_estimators': 309, 'max_depth': 15, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:25,820] Trial 35 finished with value: 0.4482559692324128 and parameters: {'n_estimators': 545, 'max_depth': 10, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:39,003] Trial 36 finished with value: 0.4420383526521019 and parameters: {'n_estimators': 765, 'max_depth': 19, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:42,227] Trial 37 finished with value: 0.45654612467282735 and parameters: {'n_estimators': 162, 'max_depth': 16, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:45,236] Trial 38 finished with value: 0.447219699802361 and parameters: {'n_estimators': 153, 'max_depth': 21, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:49,713] Trial 39 finished with value: 0.44307996367715397 and parameters: {'n_estimators': 239, 'max_depth': 29, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:52,196] Trial 40 finished with value: 0.4171892527108595 and parameters: {'n_estimators': 162, 'max_depth': 26, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 27}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:20:59,417] Trial 41 finished with value: 0.4586079803429303 and parameters: {'n_estimators': 359, 'max_depth': 16, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:21:07,569] Trial 42 finished with value: 0.4492975802574649 and parameters: {'n_estimators': 407, 'max_depth': 12, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:21:12,930] Trial 43 finished with value: 0.44722504139736124 and parameters: {'n_estimators': 281, 'max_depth': 17, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:21:20,363] Trial 44 finished with value: 0.4555045136477752 and parameters: {'n_estimators': 359, 'max_depth': 19, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.45860798034293043.\n[I 2024-02-27 10:21:29,911] Trial 45 finished with value: 0.4596549329629827 and parameters: {'n_estimators': 467, 'max_depth': 20, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:21:38,831] Trial 46 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 457, 'max_depth': 24, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:21:47,174] Trial 47 finished with value: 0.4337588804016879 and parameters: {'n_estimators': 517, 'max_depth': 22, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 19}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:21:51,364] Trial 48 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 204, 'max_depth': 26, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:21:54,330] Trial 49 finished with value: 0.45240104695262007 and parameters: {'n_estimators': 146, 'max_depth': 19, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:22:05,848] Trial 50 finished with value: 0.44928689706746433 and parameters: {'n_estimators': 575, 'max_depth': 10, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:22:13,499] Trial 51 finished with value: 0.45653544148282676 and parameters: {'n_estimators': 373, 'max_depth': 19, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:22:33,244] Trial 52 finished with value: 0.45240638854762033 and parameters: {'n_estimators': 1000, 'max_depth': 17, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:22:41,433] Trial 53 finished with value: 0.4534373163826719 and parameters: {'n_estimators': 430, 'max_depth': 20, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:22:51,763] Trial 54 finished with value: 0.45654612467282724 and parameters: {'n_estimators': 496, 'max_depth': 16, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:23:00,968] Trial 55 finished with value: 0.4441162331072058 and parameters: {'n_estimators': 515, 'max_depth': 16, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:23:10,028] Trial 56 finished with value: 0.44618877196730944 and parameters: {'n_estimators': 482, 'max_depth': 12, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 45 with value: 0.4596549329629827.\n[I 2024-02-27 10:23:12,682] Trial 57 finished with value: 0.4617061054430853 and parameters: {'n_estimators': 129, 'max_depth': 15, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:25,107] Trial 58 finished with value: 0.45032850809251646 and parameters: {'n_estimators': 660, 'max_depth': 24, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:27,386] Trial 59 finished with value: 0.4461780887773089 and parameters: {'n_estimators': 121, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:37,831] Trial 60 finished with value: 0.44100742481705035 and parameters: {'n_estimators': 603, 'max_depth': 18, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 9}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:42,638] Trial 61 finished with value: 0.4555151968377758 and parameters: {'n_estimators': 231, 'max_depth': 13, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:45,434] Trial 62 finished with value: 0.45652475829282624 and parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:47,557] Trial 63 finished with value: 0.44514181934725705 and parameters: {'n_estimators': 104, 'max_depth': 11, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:51,829] Trial 64 finished with value: 0.45653544148282676 and parameters: {'n_estimators': 208, 'max_depth': 13, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:55,136] Trial 65 finished with value: 0.4461834303723092 and parameters: {'n_estimators': 176, 'max_depth': 14, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:23:57,750] Trial 66 finished with value: 0.44722504139736124 and parameters: {'n_estimators': 137, 'max_depth': 18, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:02,500] Trial 67 finished with value: 0.43065007211153244 and parameters: {'n_estimators': 282, 'max_depth': 16, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 13}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:10,815] Trial 68 finished with value: 0.4430853052721543 and parameters: {'n_estimators': 446, 'max_depth': 41, 'min_samples_split': 18, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:16,279] Trial 69 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 256, 'max_depth': 20, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:29,735] Trial 70 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 713, 'max_depth': 31, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:37,188] Trial 71 finished with value: 0.4565514662678275 and parameters: {'n_estimators': 365, 'max_depth': 22, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:47,220] Trial 72 finished with value: 0.4534319747876716 and parameters: {'n_estimators': 502, 'max_depth': 22, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:24:54,069] Trial 73 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 350, 'max_depth': 17, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:02,507] Trial 74 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 413, 'max_depth': 15, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:06,303] Trial 75 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 188, 'max_depth': 27, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:13,512] Trial 76 finished with value: 0.42029271940601465 and parameters: {'n_estimators': 468, 'max_depth': 22, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 25}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:23,690] Trial 77 finished with value: 0.45240104695262007 and parameters: {'n_estimators': 536, 'max_depth': 20, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:28,194] Trial 78 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 225, 'max_depth': 11, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:34,444] Trial 79 finished with value: 0.44100742481705035 and parameters: {'n_estimators': 333, 'max_depth': 46, 'min_samples_split': 32, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:41,946] Trial 80 finished with value: 0.4441162331072058 and parameters: {'n_estimators': 396, 'max_depth': 13, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:49,726] Trial 81 finished with value: 0.45964959136798245 and parameters: {'n_estimators': 378, 'max_depth': 18, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:25:55,439] Trial 82 finished with value: 0.4182255221409113 and parameters: {'n_estimators': 383, 'max_depth': 18, 'min_samples_split': 29, 'random_state': 42, 'min_samples_leaf': 30}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:04,113] Trial 83 finished with value: 0.456540783077827 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:12,828] Trial 84 finished with value: 0.4555045136477752 and parameters: {'n_estimators': 432, 'max_depth': 25, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:22,449] Trial 85 finished with value: 0.45032850809251646 and parameters: {'n_estimators': 483, 'max_depth': 23, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:31,028] Trial 86 finished with value: 0.4513540943325677 and parameters: {'n_estimators': 419, 'max_depth': 21, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:42,013] Trial 87 finished with value: 0.45240104695262007 and parameters: {'n_estimators': 574, 'max_depth': 18, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:50,511] Trial 88 finished with value: 0.4441108915122055 and parameters: {'n_estimators': 455, 'max_depth': 15, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:26:55,485] Trial 89 finished with value: 0.4327226109716361 and parameters: {'n_estimators': 302, 'max_depth': 17, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 16}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:03,154] Trial 90 finished with value: 0.4575770525078789 and parameters: {'n_estimators': 377, 'max_depth': 20, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:10,141] Trial 91 finished with value: 0.45446290262272315 and parameters: {'n_estimators': 340, 'max_depth': 20, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:17,957] Trial 92 finished with value: 0.45654612467282724 and parameters: {'n_estimators': 385, 'max_depth': 22, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:24,849] Trial 93 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 357, 'max_depth': 19, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:33,225] Trial 94 finished with value: 0.4492975802574649 and parameters: {'n_estimators': 404, 'max_depth': 21, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:40,712] Trial 95 finished with value: 0.4492922386624646 and parameters: {'n_estimators': 379, 'max_depth': 16, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:46,362] Trial 96 finished with value: 0.45548848886277443 and parameters: {'n_estimators': 271, 'max_depth': 17, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:27:52,550] Trial 97 finished with value: 0.45240104695262007 and parameters: {'n_estimators': 320, 'max_depth': 14, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:28:02,111] Trial 98 finished with value: 0.4461834303723092 and parameters: {'n_estimators': 508, 'max_depth': 22, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 57 with value: 0.4617061054430853.\n[I 2024-02-27 10:28:07,106] Trial 99 finished with value: 0.4482559692324128 and parameters: {'n_estimators': 252, 'max_depth': 18, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 57 with value: 0.4617061054430853.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_estimators': 129, 'max_depth': 15, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 2}\n","output_type":"stream"},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"0.4968944099378882"},"metadata":{}}]},{"cell_type":"code","source":"final_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['random forest'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Random Forest'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:08.155161Z","iopub.execute_input":"2024-02-27T10:28:08.155976Z","iopub.status.idle":"2024-02-27T10:28:09.313972Z","shell.execute_reply.started":"2024-02-27T10:28:08.155908Z","shell.execute_reply":"2024-02-27T10:28:09.312692Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"accuracy: 0.4968944099378882\nrecall: 0.21211998923863332\nprecision: 0.4783337992731339\nf1-score: 0.1884521685293785\nroc_auc:  0.5451545170924377\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:09.314984Z","iopub.execute_input":"2024-02-27T10:28:09.315245Z","iopub.status.idle":"2024-02-27T10:28:09.327064Z","shell.execute_reply.started":"2024-02-27T10:28:09.315216Z","shell.execute_reply":"2024-02-27T10:28:09.326117Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Random Forest\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# num_image = 9","metadata":{}},{"cell_type":"code","source":"n_components_pca = 150\nnum_images = 9\n\npca = ModularPCA(n_components=n_components_pca, num_image= num_images)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced = pca.transform(X_test)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:28:09.328260Z","iopub.execute_input":"2024-02-27T10:28:09.328478Z","iopub.status.idle":"2024-02-27T10:28:09.997343Z","shell.execute_reply.started":"2024-02-27T10:28:09.328459Z","shell.execute_reply":"2024-02-27T10:28:09.996587Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine ","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:10.001058Z","iopub.execute_input":"2024-02-27T10:28:10.002850Z","iopub.status.idle":"2024-02-27T10:28:10.142539Z","shell.execute_reply.started":"2024-02-27T10:28:10.002819Z","shell.execute_reply":"2024-02-27T10:28:10.141921Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"accuracy: 0.7950310559006211\nrecall: 0.7237967126586982\nprecision: 0.7458721996035428\nf1-score: 0.7295151543031084\nroc_auc:  0.8430982115250217\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        # 'degree': trial.suggest_int('degree', 2, 5),  # for polynomial kernel\n        'tol': trial.suggest_loguniform('tol', 1e-4, 1e-2),\n        'shrinking': trial.suggest_categorical('shrinking', [True, False]),\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = SVC(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:10.143563Z","iopub.execute_input":"2024-02-27T10:28:10.144018Z","iopub.status.idle":"2024-02-27T10:28:10.151137Z","shell.execute_reply.started":"2024-02-27T10:28:10.143992Z","shell.execute_reply":"2024-02-27T10:28:10.150344Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = SVC(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['svc'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'SVM'\nmodel_scores[model_name +str(num_images)] = [accuracy,recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:10.152461Z","iopub.execute_input":"2024-02-27T10:28:10.152785Z","iopub.status.idle":"2024-02-27T10:28:41.588425Z","shell.execute_reply.started":"2024-02-27T10:28:10.152759Z","shell.execute_reply":"2024-02-27T10:28:41.587491Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:28:10,161] A new study created in memory with name: no-name-d08ae600-4071-44f7-a24d-17735827c0d2\n[I 2024-02-27 10:28:10,395] Trial 0 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.00040791246824018504, 'gamma': 0.21581134773089813, 'tol': 0.0007672710619779824, 'shrinking': False}. Best is trial 0 with value: 0.41097163613054855.\n[I 2024-02-27 10:28:10,819] Trial 1 finished with value: 0.6211153250360557 and parameters: {'kernel': 'poly', 'C': 0.11418699619277518, 'gamma': 3.3945293308510482, 'tol': 0.0004515002919890405, 'shrinking': True}. Best is trial 1 with value: 0.6211153250360557.\n[I 2024-02-27 10:28:11,239] Trial 2 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 56931.58149752372, 'gamma': 1044.182963180477, 'tol': 0.00024830649586407577, 'shrinking': False}. Best is trial 2 with value: 0.7360183750868009.\n[I 2024-02-27 10:28:11,465] Trial 3 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 2.8411861613325452e-05, 'gamma': 4920.054482239078, 'tol': 0.0005446528858050967, 'shrinking': False}. Best is trial 2 with value: 0.7360183750868009.\n[I 2024-02-27 10:28:11,813] Trial 4 finished with value: 0.613861439025693 and parameters: {'kernel': 'poly', 'C': 7.702088844421244e-05, 'gamma': 1.129214374912891, 'tol': 0.002041821223526614, 'shrinking': False}. Best is trial 2 with value: 0.7360183750868009.\n[I 2024-02-27 10:28:12,100] Trial 5 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 119.4190317924464, 'gamma': 20169.697355300683, 'tol': 0.001167054579686204, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:12,519] Trial 6 finished with value: 0.6211153250360557 and parameters: {'kernel': 'poly', 'C': 0.007151473288721677, 'gamma': 48.303888661138245, 'tol': 0.007423279571602481, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:12,732] Trial 7 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 4.163500970541345e-05, 'gamma': 0.005513587707209297, 'tol': 0.0021549127040088913, 'shrinking': False}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:12,932] Trial 8 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 5241.909789400968, 'gamma': 1.779169205399394e-05, 'tol': 0.0014829099566890124, 'shrinking': False}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:13,231] Trial 9 finished with value: 0.4109662945355483 and parameters: {'kernel': 'poly', 'C': 0.009885399962749074, 'gamma': 0.03994864777164434, 'tol': 0.0001825886851768914, 'shrinking': False}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:13,976] Trial 10 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 56.22177293272278, 'gamma': 31242.29863534098, 'tol': 0.008920468347501148, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:14,338] Trial 11 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 93968.64580910713, 'gamma': 552.3343810061319, 'tol': 0.00010190875884430447, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:14,674] Trial 12 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 45.519458366443466, 'gamma': 311.7487547611296, 'tol': 0.00029632266518214224, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:15,414] Trial 13 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 21.38749800738864, 'gamma': 77.31655998992393, 'tol': 0.0039409528395496635, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:15,777] Trial 14 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 97.31197373229276, 'gamma': 48754.42497220683, 'tol': 0.0002807268836874641, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:16,096] Trial 15 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 4.8625245015035885, 'gamma': 44.90994099830486, 'tol': 0.0009860135766879613, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:16,421] Trial 16 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 683.6660777315207, 'gamma': 86666.30613097265, 'tol': 0.0004390288619898403, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:17,184] Trial 17 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.9453462699415563, 'gamma': 2028.4714590919648, 'tol': 0.00010429675287857527, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:17,459] Trial 18 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 692.5120115905104, 'gamma': 10.099298705817002, 'tol': 0.0036985716209999206, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:17,767] Trial 19 finished with value: 0.7339458362266973 and parameters: {'kernel': 'linear', 'C': 0.5822352284958029, 'gamma': 8426.752715791697, 'tol': 0.0007577574218942117, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:18,534] Trial 20 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 3414.4727080319994, 'gamma': 292.49166728033106, 'tol': 0.0014733578263018026, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:18,864] Trial 21 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 7.499830539404077, 'gamma': 32.886978669703, 'tol': 0.0009730489375438685, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:19,156] Trial 22 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 5.098547021183288, 'gamma': 264.78044985919826, 'tol': 0.0014400822083815838, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:19,483] Trial 23 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 230.64339536132454, 'gamma': 6561.886697417161, 'tol': 0.0003382918733517157, 'shrinking': True}. Best is trial 5 with value: 0.7370493029218524.\n[I 2024-02-27 10:28:19,761] Trial 24 finished with value: 0.7670637252283532 and parameters: {'kernel': 'linear', 'C': 0.10692825358993502, 'gamma': 5.361521504412416, 'tol': 0.00015632719658336766, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:20,025] Trial 25 finished with value: 0.763960258533198 and parameters: {'kernel': 'linear', 'C': 0.0790363889242212, 'gamma': 0.003362058847418903, 'tol': 0.0001534723934594924, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:20,285] Trial 26 finished with value: 0.7608674750280434 and parameters: {'kernel': 'linear', 'C': 0.06369637289197402, 'gamma': 0.00025860947226061503, 'tol': 0.00016267927473367038, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:20,545] Trial 27 finished with value: 0.7629293306981465 and parameters: {'kernel': 'linear', 'C': 0.07441088108574682, 'gamma': 0.0003454990067654682, 'tol': 0.00015916973698552983, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:20,892] Trial 28 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.002272332811573657, 'gamma': 0.001424273169180111, 'tol': 0.00015665420344967184, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:21,140] Trial 29 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.00039314263904733623, 'gamma': 0.09634976068474164, 'tol': 0.0002084398738764602, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:21,433] Trial 30 finished with value: 0.7660274557983013 and parameters: {'kernel': 'linear', 'C': 0.10932397328107422, 'gamma': 1.3553007940986937e-05, 'tol': 0.00013463832515449184, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:21,688] Trial 31 finished with value: 0.7619037444580952 and parameters: {'kernel': 'linear', 'C': 0.06082756980740767, 'gamma': 1.2020005127043194e-05, 'tol': 0.0001290777751074126, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:21,981] Trial 32 finished with value: 0.762918647508146 and parameters: {'kernel': 'linear', 'C': 0.13633390993096556, 'gamma': 0.00015641304292825128, 'tol': 0.00013510223038037188, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:22,291] Trial 33 finished with value: 0.7494578281074729 and parameters: {'kernel': 'linear', 'C': 0.31228971512340453, 'gamma': 8.217307424957436e-05, 'tol': 0.00022254508418652997, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:22,522] Trial 34 finished with value: 0.6904705945195235 and parameters: {'kernel': 'linear', 'C': 0.0153173143974625, 'gamma': 0.0055967904959200445, 'tol': 0.00037050236780562595, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:22,764] Trial 35 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.001239377388135212, 'gamma': 0.37199031229979307, 'tol': 0.0005665241091705645, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:22,973] Trial 36 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.03500363989361263, 'gamma': 0.0006770254499790031, 'tol': 0.00023708952132365477, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:23,356] Trial 37 finished with value: 0.755659419902783 and parameters: {'kernel': 'linear', 'C': 0.22521033629057205, 'gamma': 0.015118933312037104, 'tol': 0.00011956498433442893, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:23,702] Trial 38 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 1.6871409438633016, 'gamma': 3.571580729011447e-05, 'tol': 0.00017365849209780755, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:24,148] Trial 39 finished with value: 0.6211153250360557 and parameters: {'kernel': 'poly', 'C': 0.0017551028140307002, 'gamma': 1.636077463081272, 'tol': 0.0005155260823075286, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:24,401] Trial 40 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0004012233298961601, 'gamma': 0.0009949850501003983, 'tol': 0.00013565328813064953, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:24,681] Trial 41 finished with value: 0.7608567918380429 and parameters: {'kernel': 'linear', 'C': 0.12255475619664809, 'gamma': 0.00013254363181872068, 'tol': 0.00014157104416177594, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:24,915] Trial 42 finished with value: 0.7173868917258692 and parameters: {'kernel': 'linear', 'C': 0.023310218058410312, 'gamma': 5.826277110204536e-05, 'tol': 0.00020346970460621556, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:25,162] Trial 43 finished with value: 0.49170984455958544 and parameters: {'kernel': 'linear', 'C': 0.00407683824603776, 'gamma': 0.00045715791199832145, 'tol': 0.00010808180536471662, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:25,504] Trial 44 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 1.4947195932316053, 'gamma': 0.0034616047635623137, 'tol': 0.0002591623273717443, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:25,713] Trial 45 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.14079036512558646, 'gamma': 0.00018610864356266444, 'tol': 0.00018039370030644515, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:26,138] Trial 46 finished with value: 0.7401367448320068 and parameters: {'kernel': 'linear', 'C': 0.44526506271764166, 'gamma': 3.900154168409889e-05, 'tol': 0.00014613210446732988, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:26,375] Trial 47 finished with value: 0.541381336467069 and parameters: {'kernel': 'linear', 'C': 0.005801927100905441, 'gamma': 0.024635198039021616, 'tol': 0.0003227738162809486, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:26,938] Trial 48 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.04100347854172995, 'gamma': 0.3547282289694485, 'tol': 0.00010057711336579314, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:27,172] Trial 49 finished with value: 0.6863308583943166 and parameters: {'kernel': 'linear', 'C': 0.01482619092034577, 'gamma': 7.939866109841356, 'tol': 0.0004157630420682074, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:27,416] Trial 50 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 9.42136847668701e-05, 'gamma': 1.0806494269485915e-05, 'tol': 0.00026505709466556236, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:27,676] Trial 51 finished with value: 0.7650072111532504 and parameters: {'kernel': 'linear', 'C': 0.06607826305509937, 'gamma': 2.0649431362846662e-05, 'tol': 0.00012328728164857003, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:27,962] Trial 52 finished with value: 0.7608514502430426 and parameters: {'kernel': 'linear', 'C': 0.130241525973238, 'gamma': 2.317868662351899e-05, 'tol': 0.00013056789650896746, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:28,306] Trial 53 finished with value: 0.7370493029218524 and parameters: {'kernel': 'linear', 'C': 2.023216104310411, 'gamma': 0.0019958069493615405, 'tol': 0.00018368241661812106, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:28,664] Trial 54 finished with value: 0.7360237166818011 and parameters: {'kernel': 'linear', 'C': 0.6343065966401473, 'gamma': 0.0004202089790359186, 'tol': 0.00012148008563733243, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:28,993] Trial 55 finished with value: 0.7494685112974734 and parameters: {'kernel': 'linear', 'C': 0.261000757825841, 'gamma': 9.526847258909624e-05, 'tol': 0.00015937452712292565, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:29,204] Trial 56 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.0626567594178118, 'gamma': 2.6919371589577472e-05, 'tol': 0.0002026552310572006, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:29,674] Trial 57 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 10.369853476090082, 'gamma': 0.012100870738728573, 'tol': 0.0001169459699919724, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:30,012] Trial 58 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.008684174981494637, 'gamma': 0.00022275185741340257, 'tol': 0.00014479971897606822, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:30,354] Trial 59 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 2.4992607498161803, 'gamma': 2.3965693144339646, 'tol': 0.00023827455100285932, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:30,579] Trial 60 finished with value: 0.734982105656749 and parameters: {'kernel': 'linear', 'C': 0.03125073254685227, 'gamma': 0.06289378692366829, 'tol': 0.0027848327536396282, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:30,844] Trial 61 finished with value: 0.7660434805833022 and parameters: {'kernel': 'linear', 'C': 0.06704077836640672, 'gamma': 2.453406919443985e-05, 'tol': 0.0001279022107305575, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:31,107] Trial 62 finished with value: 0.7660274557983013 and parameters: {'kernel': 'linear', 'C': 0.08225151150773898, 'gamma': 7.124426682295668e-05, 'tol': 0.0001821948026610482, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:31,450] Trial 63 finished with value: 0.7380855723519042 and parameters: {'kernel': 'linear', 'C': 0.8240886790248575, 'gamma': 5.851791239611664e-05, 'tol': 0.00018042564562532036, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:31,719] Trial 64 finished with value: 0.7639656001281983 and parameters: {'kernel': 'linear', 'C': 0.07090451111941512, 'gamma': 1.1269229612928348e-05, 'tol': 0.00010074366950743767, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:31,958] Trial 65 finished with value: 0.6842583195342129 and parameters: {'kernel': 'linear', 'C': 0.014413147171913658, 'gamma': 1.638073253477464e-05, 'tol': 0.00010138119801358484, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:32,189] Trial 66 finished with value: 0.5041343945302067 and parameters: {'kernel': 'linear', 'C': 0.004425904204749525, 'gamma': 5.454626594460465, 'tol': 0.00696576320335237, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:32,505] Trial 67 finished with value: 0.7556647614977832 and parameters: {'kernel': 'linear', 'C': 0.22973093161884534, 'gamma': 1.0841010363588099e-05, 'tol': 0.00011860638020391697, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:32,824] Trial 68 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.028441858692969866, 'gamma': 4.082036344912967e-05, 'tol': 0.00011476421085947257, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:33,074] Trial 69 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0009620711261120175, 'gamma': 2.285393436408827e-05, 'tol': 0.0001913094942589683, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:33,372] Trial 70 finished with value: 0.7629239891031462 and parameters: {'kernel': 'linear', 'C': 0.08107337128072671, 'gamma': 8.0185988191439e-05, 'tol': 0.0002855714716872785, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:33,710] Trial 71 finished with value: 0.748421558677421 and parameters: {'kernel': 'linear', 'C': 0.4061013785073328, 'gamma': 0.00033771609601565203, 'tol': 0.0001546537232544982, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:33,971] Trial 72 finished with value: 0.7629293306981465 and parameters: {'kernel': 'linear', 'C': 0.07443415351065344, 'gamma': 0.00011800835309313097, 'tol': 0.00016504812793845147, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:34,201] Trial 73 finished with value: 0.709102077880455 and parameters: {'kernel': 'linear', 'C': 0.01987824720565413, 'gamma': 1.951495008186151e-05, 'tol': 0.0002258266576305825, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:34,443] Trial 74 finished with value: 0.6542332140377117 and parameters: {'kernel': 'linear', 'C': 0.011017872885876717, 'gamma': 0.6823484644088975, 'tol': 0.00012854981506431627, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:34,753] Trial 75 finished with value: 0.7535975642326799 and parameters: {'kernel': 'linear', 'C': 0.24755196490332682, 'gamma': 0.0008214184676896327, 'tol': 0.00014569020253039382, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:34,962] Trial 76 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 0.045077485059225764, 'gamma': 4.9647480780815713e-05, 'tol': 0.00011181169529533058, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:35,225] Trial 77 finished with value: 0.7629133059131457 and parameters: {'kernel': 'linear', 'C': 0.15340081393838387, 'gamma': 80.40541730060767, 'tol': 0.0007026408308406874, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:35,575] Trial 78 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 1.1304657822652795, 'gamma': 27.19293825405169, 'tol': 0.00020113541020664805, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:35,852] Trial 79 finished with value: 0.7670583836333529 and parameters: {'kernel': 'linear', 'C': 0.09364656128582782, 'gamma': 1.0234600230631996e-05, 'tol': 0.0001562908424185929, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:36,205] Trial 80 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 25446.28036830475, 'gamma': 1.157638737805671e-05, 'tol': 0.00013483284314898635, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:36,472] Trial 81 finished with value: 0.7670583836333529 and parameters: {'kernel': 'linear', 'C': 0.09568087192598473, 'gamma': 3.192443690275736e-05, 'tol': 0.0001618687197778013, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:36,811] Trial 82 finished with value: 0.738080230756904 and parameters: {'kernel': 'linear', 'C': 0.50465362118771, 'gamma': 2.1956945984592415e-05, 'tol': 0.00016254221682624641, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:37,072] Trial 83 finished with value: 0.7660327973933017 and parameters: {'kernel': 'linear', 'C': 0.08469628942930592, 'gamma': 3.651905435264111e-05, 'tol': 0.000214264036091628, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:37,311] Trial 84 finished with value: 0.7432776026921639 and parameters: {'kernel': 'linear', 'C': 0.03785502034148961, 'gamma': 3.309463254567013e-05, 'tol': 0.0001741921690240405, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:37,587] Trial 85 finished with value: 0.7618930612680946 and parameters: {'kernel': 'linear', 'C': 0.11888145225943958, 'gamma': 6.710946613614597e-05, 'tol': 0.0002154467287790107, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:37,838] Trial 86 finished with value: 0.4616954222530848 and parameters: {'kernel': 'linear', 'C': 0.002745933969762293, 'gamma': 0.0001514117322136847, 'tol': 0.00010300990607410618, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:38,079] Trial 87 finished with value: 0.5941776614497088 and parameters: {'kernel': 'linear', 'C': 0.007588914860013445, 'gamma': 1.4595159179829357e-05, 'tol': 0.00032696486508173314, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:38,422] Trial 88 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.19409597169755857, 'gamma': 3.296801318908191e-05, 'tol': 0.00012764582393030085, 'shrinking': False}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:38,656] Trial 89 finished with value: 0.7080711500454034 and parameters: {'kernel': 'linear', 'C': 0.019094015296361167, 'gamma': 1.0558100946153305e-05, 'tol': 0.00024739265633772915, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:38,889] Trial 90 finished with value: 0.41097163613054855 and parameters: {'kernel': 'poly', 'C': 1.09367395348814e-05, 'gamma': 9.094314828874519e-05, 'tol': 0.0012080591935242334, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:39,155] Trial 91 finished with value: 0.7629346722931467 and parameters: {'kernel': 'linear', 'C': 0.07685405477139609, 'gamma': 5.573129576538917e-05, 'tol': 0.0001471760464152138, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:39,409] Trial 92 finished with value: 0.7608674750280434 and parameters: {'kernel': 'linear', 'C': 0.05301608970246895, 'gamma': 0.00022271303906567944, 'tol': 0.00017398342207221906, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:39,745] Trial 93 finished with value: 0.7504940975375247 and parameters: {'kernel': 'linear', 'C': 0.31436189698370465, 'gamma': 1.9032752420065364e-05, 'tol': 0.00011187565343204344, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:40,023] Trial 94 finished with value: 0.7649911863682496 and parameters: {'kernel': 'linear', 'C': 0.10173487389755641, 'gamma': 3.488431369626855e-05, 'tol': 0.00013554414360566504, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:40,265] Trial 95 finished with value: 0.7277335612413867 and parameters: {'kernel': 'linear', 'C': 0.027689725751403122, 'gamma': 3.4752820302249394e-05, 'tol': 0.0001330855231288538, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:40,540] Trial 96 finished with value: 0.7670583836333529 and parameters: {'kernel': 'linear', 'C': 0.10441797539557204, 'gamma': 0.00012001213832119002, 'tol': 0.0001924107067448385, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:40,889] Trial 97 finished with value: 0.7360183750868009 and parameters: {'kernel': 'linear', 'C': 3.580614239793806, 'gamma': 0.00010901390287188875, 'tol': 0.0002195838111176093, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:41,166] Trial 98 finished with value: 0.7670637252283532 and parameters: {'kernel': 'linear', 'C': 0.10647394280604168, 'gamma': 18.85786451847906, 'tol': 0.00018720043543509775, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n[I 2024-02-27 10:28:41,493] Trial 99 finished with value: 0.7380855723519042 and parameters: {'kernel': 'linear', 'C': 0.7407279870607236, 'gamma': 21.734688181833558, 'tol': 0.00038215479727346925, 'shrinking': True}. Best is trial 24 with value: 0.7670637252283532.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'kernel': 'linear', 'C': 0.10692825358993502, 'gamma': 5.361521504412416, 'tol': 0.00015632719658336766, 'shrinking': True}\naccuracy: 0.8322981366459627\nrecall: 0.7472462094164655\nprecision: 0.8171440409725823\nf1-score: 0.774114611546821\nroc_auc:  0.8570684423934002\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:41.589440Z","iopub.execute_input":"2024-02-27T10:28:41.590045Z","iopub.status.idle":"2024-02-27T10:28:41.601469Z","shell.execute_reply.started":"2024-02-27T10:28:41.590021Z","shell.execute_reply":"2024-02-27T10:28:41.600362Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"SVM - Modular PCA 9\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train_reduced, y_train)\ny_pred = dt.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:41.602848Z","iopub.execute_input":"2024-02-27T10:28:41.603291Z","iopub.status.idle":"2024-02-27T10:28:41.834206Z","shell.execute_reply.started":"2024-02-27T10:28:41.603267Z","shell.execute_reply":"2024-02-27T10:28:41.833240Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"accuracy: 0.3944099378881988\nrecall: 0.3092346483642521\nprecision: 0.32130728043885937\nf1-score: 0.31248156230410135\nroc_auc:  0.5992395416078091\naccuracy: 0.7950310559006211\nrecall: 0.7237967126586982\nprecision: 0.7458721996035428\nf1-score: 0.7295151543031084\nroc_auc:  0.8430982115250217\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 10),\n        \"min_samples_split\" : trial.suggest_int(\"min_samples_split\", 2, 20),\n        \"min_samples_leaf\" : trial.suggest_int(\"min_samples_leaf\", 1, 10),\n        \"criterion\" : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n        'random_state': trial.suggest_categorical('random_state', [42])\n\n    }\n\n    # Create KNN model with tuned hyperparameters\n    model = DecisionTreeClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:41.835211Z","iopub.execute_input":"2024-02-27T10:28:41.835625Z","iopub.status.idle":"2024-02-27T10:28:41.841628Z","shell.execute_reply.started":"2024-02-27T10:28:41.835603Z","shell.execute_reply":"2024-02-27T10:28:41.840889Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = DecisionTreeClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['decison tree'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Decision Tree'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:28:41.842740Z","iopub.execute_input":"2024-02-27T10:28:41.843147Z","iopub.status.idle":"2024-02-27T10:29:06.310464Z","shell.execute_reply.started":"2024-02-27T10:28:41.843125Z","shell.execute_reply":"2024-02-27T10:29:06.309536Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:28:41,856] A new study created in memory with name: no-name-bc88a7ca-5b69-4569-ad74-2343bc5c6c9a\n[I 2024-02-27 10:28:42,227] Trial 0 finished with value: 0.35921692217296086 and parameters: {'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 0 with value: 0.35921692217296086.\n[I 2024-02-27 10:28:42,733] Trial 1 finished with value: 0.40579028898028946 and parameters: {'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 1 with value: 0.40579028898028946.\n[I 2024-02-27 10:28:43,100] Trial 2 finished with value: 0.3540569414027029 and parameters: {'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 1 with value: 0.40579028898028946.\n[I 2024-02-27 10:28:43,742] Trial 3 finished with value: 0.3663960258533198 and parameters: {'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 1 with value: 0.40579028898028946.\n[I 2024-02-27 10:28:44,420] Trial 4 finished with value: 0.3539981838576999 and parameters: {'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 1 with value: 0.40579028898028946.\n[I 2024-02-27 10:28:44,818] Trial 5 finished with value: 0.4368570055018429 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 8, 'criterion': 'entropy', 'random_state': 42}. Best is trial 5 with value: 0.4368570055018429.\n[I 2024-02-27 10:28:45,226] Trial 6 finished with value: 0.4368570055018429 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 5 with value: 0.4368570055018429.\n[I 2024-02-27 10:28:45,565] Trial 7 finished with value: 0.36751776080337584 and parameters: {'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 5 with value: 0.4368570055018429.\n[I 2024-02-27 10:28:46,312] Trial 8 finished with value: 0.3467229314673362 and parameters: {'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'random_state': 42}. Best is trial 5 with value: 0.4368570055018429.\n[I 2024-02-27 10:28:46,896] Trial 9 finished with value: 0.37470220607873517 and parameters: {'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 5 with value: 0.4368570055018429.\n[I 2024-02-27 10:28:47,046] Trial 10 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:47,191] Trial 11 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:47,338] Trial 12 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:47,487] Trial 13 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:47,731] Trial 14 finished with value: 0.3995619892099781 and parameters: {'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:47,880] Trial 15 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:48,167] Trial 16 finished with value: 0.39542225308477114 and parameters: {'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:48,365] Trial 17 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:48,613] Trial 18 finished with value: 0.40680519203034027 and parameters: {'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:48,933] Trial 19 finished with value: 0.37892740772394634 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:49,080] Trial 20 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:49,225] Trial 21 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:49,427] Trial 22 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:49,574] Trial 23 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:49,772] Trial 24 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:50,019] Trial 25 finished with value: 0.40577960579028904 and parameters: {'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:50,306] Trial 26 finished with value: 0.3964531809198227 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:50,453] Trial 27 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:50,656] Trial 28 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:50,999] Trial 29 finished with value: 0.36542919715827143 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:51,245] Trial 30 finished with value: 0.40784146146039213 and parameters: {'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:51,394] Trial 31 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:51,541] Trial 32 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:51,743] Trial 33 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:51,891] Trial 34 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:52,089] Trial 35 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:52,609] Trial 36 finished with value: 0.40579028898028946 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:52,762] Trial 37 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:53,471] Trial 38 finished with value: 0.34256182896212806 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:53,670] Trial 39 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:54,363] Trial 40 finished with value: 0.3581058704129053 and parameters: {'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:54,509] Trial 41 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:54,656] Trial 42 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:54,855] Trial 43 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:55,005] Trial 44 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:55,155] Trial 45 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:55,356] Trial 46 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:56,035] Trial 47 finished with value: 0.3498424229474921 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:56,284] Trial 48 finished with value: 0.40473265317023666 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:56,583] Trial 49 finished with value: 0.39542225308477114 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:56,786] Trial 50 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:56,937] Trial 51 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:57,086] Trial 52 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:57,237] Trial 53 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:57,606] Trial 54 finished with value: 0.3768067945088403 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:57,757] Trial 55 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:57,956] Trial 56 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:58,104] Trial 57 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:58,520] Trial 58 finished with value: 0.4368570055018429 and parameters: {'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:58,720] Trial 59 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:58,977] Trial 60 finished with value: 0.40577960579028904 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,126] Trial 61 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,276] Trial 62 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,428] Trial 63 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,631] Trial 64 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,783] Trial 65 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:28:59,934] Trial 66 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:00,085] Trial 67 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:00,288] Trial 68 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:00,704] Trial 69 finished with value: 0.4368570055018429 and parameters: {'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:00,856] Trial 70 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,006] Trial 71 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,155] Trial 72 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,304] Trial 73 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,632] Trial 74 finished with value: 0.39236151914961803 and parameters: {'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,831] Trial 75 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:01,985] Trial 76 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:02,136] Trial 77 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:02,339] Trial 78 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:02,541] Trial 79 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:02,839] Trial 80 finished with value: 0.4326959029966348 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 9, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:02,989] Trial 81 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,139] Trial 82 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,289] Trial 83 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,439] Trial 84 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,587] Trial 85 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,796] Trial 86 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:03,946] Trial 87 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,150] Trial 88 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,300] Trial 89 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,504] Trial 90 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,654] Trial 91 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,803] Trial 92 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:04,952] Trial 93 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:05,099] Trial 94 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:05,300] Trial 95 finished with value: 0.4244057475562203 and parameters: {'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:05,597] Trial 96 finished with value: 0.4326959029966348 and parameters: {'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:05,750] Trial 97 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:06,110] Trial 98 finished with value: 0.37163078895358154 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n[I 2024-02-27 10:29:06,261] Trial 99 finished with value: 0.43786656695689335 and parameters: {'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.43786656695689335.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}\naccuracy: 0.4161490683229814\nrecall: 0.18299987256276284\nprecision: 0.11068691844553914\nf1-score: 0.13780060153140966\nroc_auc:  0.5269358766059692\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:29:06.311628Z","iopub.execute_input":"2024-02-27T10:29:06.312142Z","iopub.status.idle":"2024-02-27T10:29:06.323755Z","shell.execute_reply.started":"2024-02-27T10:29:06.312119Z","shell.execute_reply":"2024-02-27T10:29:06.322700Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Decision Tree - Modular PCA 9\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# KNN Classifier","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_reduced, y_train)\ny_pred = knn.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:06.324857Z","iopub.execute_input":"2024-02-27T10:29:06.325177Z","iopub.status.idle":"2024-02-27T10:29:06.365413Z","shell.execute_reply.started":"2024-02-27T10:29:06.325149Z","shell.execute_reply":"2024-02-27T10:29:06.364379Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"accuracy: 0.5093167701863354\nrecall: 0.3456875306371928\nprecision: 0.4437338585147595\nf1-score: 0.3420471327866159\nroc_auc:  0.6233888808004193\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'n_neighbors': trial.suggest_int(\"n_neighbors\", 5, 100),\n        'weights' : trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n        'metric' : trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"]),\n        'algorithm':trial.suggest_categorical('algorithm',['auto', 'ball_tree', 'kd_tree', 'brute']),\n        'n_jobs': -1\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = KNeighborsClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:06.366561Z","iopub.execute_input":"2024-02-27T10:29:06.367090Z","iopub.status.idle":"2024-02-27T10:29:06.373303Z","shell.execute_reply.started":"2024-02-27T10:29:06.367066Z","shell.execute_reply":"2024-02-27T10:29:06.372364Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 200)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model =KNeighborsClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['KNN'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'K-Nearest Neighbors'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall, f1,precision, roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:06.374505Z","iopub.execute_input":"2024-02-27T10:29:06.374781Z","iopub.status.idle":"2024-02-27T10:29:35.072460Z","shell.execute_reply.started":"2024-02-27T10:29:06.374758Z","shell.execute_reply":"2024-02-27T10:29:35.071130Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:29:06,383] A new study created in memory with name: no-name-cb5e6a85-7052-4d8d-bbfc-d52cae486734\n[I 2024-02-27 10:29:06,451] Trial 0 finished with value: 0.5227979274611398 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:06,681] Trial 1 finished with value: 0.4451151113722557 and parameters: {'n_neighbors': 90, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:06,812] Trial 2 finished with value: 0.45753966134287694 and parameters: {'n_neighbors': 76, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:06,854] Trial 3 finished with value: 0.456519416697826 and parameters: {'n_neighbors': 91, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:06,996] Trial 4 finished with value: 0.5206933390310347 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,156] Trial 5 finished with value: 0.4720420917686021 and parameters: {'n_neighbors': 65, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,193] Trial 6 finished with value: 0.48239410287911966 and parameters: {'n_neighbors': 46, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,383] Trial 7 finished with value: 0.4855082527642754 and parameters: {'n_neighbors': 37, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,583] Trial 8 finished with value: 0.4606538112280327 and parameters: {'n_neighbors': 82, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,716] Trial 9 finished with value: 0.4451151113722557 and parameters: {'n_neighbors': 88, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,789] Trial 10 finished with value: 0.5021152716201057 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 0 with value: 0.5227979274611398.\n[I 2024-02-27 10:29:07,945] Trial 11 finished with value: 0.5279899578013996 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,095] Trial 12 finished with value: 0.5175952139308798 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,128] Trial 13 finished with value: 0.5155280166657764 and parameters: {'n_neighbors': 25, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,271] Trial 14 finished with value: 0.521740291651087 and parameters: {'n_neighbors': 24, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,357] Trial 15 finished with value: 0.4855082527642754 and parameters: {'n_neighbors': 36, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,528] Trial 16 finished with value: 0.5176379466908819 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,607] Trial 17 finished with value: 0.47410928903370547 and parameters: {'n_neighbors': 49, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,777] Trial 18 finished with value: 0.47307836119865393 and parameters: {'n_neighbors': 60, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,932] Trial 19 finished with value: 0.5217082420810855 and parameters: {'n_neighbors': 34, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:08,985] Trial 20 finished with value: 0.5279899578013996 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,015] Trial 21 finished with value: 0.5186528497409327 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,048] Trial 22 finished with value: 0.5051760055552588 and parameters: {'n_neighbors': 28, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,079] Trial 23 finished with value: 0.5217669996260884 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,109] Trial 24 finished with value: 0.5248597831312429 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,265] Trial 25 finished with value: 0.4823887612841194 and parameters: {'n_neighbors': 44, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5279899578013996.\n[I 2024-02-27 10:29:09,431] Trial 26 finished with value: 0.5331339137866568 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 26 with value: 0.5331339137866568.\n[I 2024-02-27 10:29:09,590] Trial 27 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 27 with value: 0.574557983013728.\n[I 2024-02-27 10:29:09,756] Trial 28 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:09,916] Trial 29 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,080] Trial 30 finished with value: 0.5300144223065008 and parameters: {'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,242] Trial 31 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,435] Trial 32 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,612] Trial 33 finished with value: 0.5403877997970195 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,793] Trial 34 finished with value: 0.5589872335879494 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:10,959] Trial 35 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:11,154] Trial 36 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:11,327] Trial 37 finished with value: 0.4751295336787564 and parameters: {'n_neighbors': 68, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:11,506] Trial 38 finished with value: 0.5434805833021741 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:11,681] Trial 39 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:11,883] Trial 40 finished with value: 0.43994444741199723 and parameters: {'n_neighbors': 96, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,070] Trial 41 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,241] Trial 42 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,400] Trial 43 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,589] Trial 44 finished with value: 0.545558463757278 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,750] Trial 45 finished with value: 0.5217296084610865 and parameters: {'n_neighbors': 29, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:12,836] Trial 46 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,067] Trial 47 finished with value: 0.549676833502484 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,257] Trial 48 finished with value: 0.514481064045724 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,421] Trial 49 finished with value: 0.5176112387158807 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,549] Trial 50 finished with value: 0.5724640777736232 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,640] Trial 51 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,730] Trial 52 finished with value: 0.5589872335879494 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,819] Trial 53 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:13,908] Trial 54 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,078] Trial 55 finished with value: 0.5672827306233641 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,116] Trial 56 finished with value: 0.496880508519844 and parameters: {'n_neighbors': 32, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,287] Trial 57 finished with value: 0.5424443138721223 and parameters: {'n_neighbors': 23, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,499] Trial 58 finished with value: 0.48859035307942944 and parameters: {'n_neighbors': 60, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,688] Trial 59 finished with value: 0.4647882057582394 and parameters: {'n_neighbors': 74, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,849] Trial 60 finished with value: 0.5186421665509322 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:14,945] Trial 61 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,031] Trial 62 finished with value: 0.5672934138133646 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,130] Trial 63 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,216] Trial 64 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,307] Trial 65 finished with value: 0.5590032583729502 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,499] Trial 66 finished with value: 0.5672934138133646 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,593] Trial 67 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,804] Trial 68 finished with value: 0.5652315581432615 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:15,962] Trial 69 finished with value: 0.5383045777469152 and parameters: {'n_neighbors': 25, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,130] Trial 70 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,222] Trial 71 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,315] Trial 72 finished with value: 0.5672827306233641 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,407] Trial 73 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,496] Trial 74 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,585] Trial 75 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,761] Trial 76 finished with value: 0.545558463757278 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:16,928] Trial 77 finished with value: 0.5258960525612949 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,041] Trial 78 finished with value: 0.4471929918273596 and parameters: {'n_neighbors': 85, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,223] Trial 79 finished with value: 0.5020351476951017 and parameters: {'n_neighbors': 53, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,313] Trial 80 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,403] Trial 81 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,492] Trial 82 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,581] Trial 83 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,668] Trial 84 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:17,844] Trial 85 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:18,264] Trial 86 finished with value: 0.5631697024731585 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:18,484] Trial 87 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:18,662] Trial 88 finished with value: 0.5434805833021741 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:18,883] Trial 89 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,052] Trial 90 finished with value: 0.5175952139308798 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,141] Trial 91 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,230] Trial 92 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,324] Trial 93 finished with value: 0.5672827306233641 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,411] Trial 94 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,499] Trial 95 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,587] Trial 96 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,761] Trial 97 finished with value: 0.5269430051813472 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:19,927] Trial 98 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:20,141] Trial 99 finished with value: 0.5641899471182095 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:20,305] Trial 100 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:20,475] Trial 101 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:20,648] Trial 102 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:20,823] Trial 103 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,002] Trial 104 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,173] Trial 105 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,347] Trial 106 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,513] Trial 107 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,688] Trial 108 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:21,848] Trial 109 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,014] Trial 110 finished with value: 0.5589872335879494 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,174] Trial 111 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,371] Trial 112 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,566] Trial 113 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,755] Trial 114 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:22,954] Trial 115 finished with value: 0.5672934138133646 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:23,123] Trial 116 finished with value: 0.5124192083756209 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:23,293] Trial 117 finished with value: 0.5300357886865018 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:23,481] Trial 118 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:23,675] Trial 119 finished with value: 0.514481064045724 and parameters: {'n_neighbors': 40, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:23,888] Trial 120 finished with value: 0.573500347203675 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,060] Trial 121 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,227] Trial 122 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,386] Trial 123 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,562] Trial 124 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,728] Trial 125 finished with value: 0.4389188611719459 and parameters: {'n_neighbors': 99, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:24,901] Trial 126 finished with value: 0.5672934138133646 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,076] Trial 127 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,247] Trial 128 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,341] Trial 129 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,511] Trial 130 finished with value: 0.45961754179798087 and parameters: {'n_neighbors': 78, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,691] Trial 131 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:25,853] Trial 132 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,033] Trial 133 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,200] Trial 134 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,405] Trial 135 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,584] Trial 136 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,769] Trial 137 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:26,935] Trial 138 finished with value: 0.5258960525612949 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,111] Trial 139 finished with value: 0.496880508519844 and parameters: {'n_neighbors': 55, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,255] Trial 140 finished with value: 0.5248597831312429 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,470] Trial 141 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,651] Trial 142 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,817] Trial 143 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:27,986] Trial 144 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:28,162] Trial 145 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:28,337] Trial 146 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:28,545] Trial 147 finished with value: 0.5734950056086747 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:28,637] Trial 148 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:28,836] Trial 149 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,034] Trial 150 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,223] Trial 151 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,398] Trial 152 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,568] Trial 153 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,759] Trial 154 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:29,935] Trial 155 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,100] Trial 156 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,189] Trial 157 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,280] Trial 158 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,372] Trial 159 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,466] Trial 160 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,561] Trial 161 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,653] Trial 162 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,747] Trial 163 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,842] Trial 164 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:30,938] Trial 165 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,031] Trial 166 finished with value: 0.590080658084504 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,140] Trial 167 finished with value: 0.4751295336787564 and parameters: {'n_neighbors': 68, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,232] Trial 168 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,314] Trial 169 finished with value: 0.5021152716201057 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,353] Trial 170 finished with value: 0.5124192083756209 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,441] Trial 171 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,530] Trial 172 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,622] Trial 173 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,712] Trial 174 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,803] Trial 175 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,897] Trial 176 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:31,992] Trial 177 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,087] Trial 178 finished with value: 0.5724747609636237 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,180] Trial 179 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,273] Trial 180 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,374] Trial 181 finished with value: 0.5041130281502056 and parameters: {'n_neighbors': 47, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,464] Trial 182 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,554] Trial 183 finished with value: 0.5786816943539341 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,716] Trial 184 finished with value: 0.579701938998985 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,813] Trial 185 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,905] Trial 186 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:32,994] Trial 187 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:33,083] Trial 188 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:33,255] Trial 189 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:33,426] Trial 190 finished with value: 0.5683296832434165 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:33,618] Trial 191 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:33,806] Trial 192 finished with value: 0.5755675444687783 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,000] Trial 193 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,203] Trial 194 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,416] Trial 195 finished with value: 0.574557983013728 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,630] Trial 196 finished with value: 0.578660327973933 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,722] Trial 197 finished with value: 0.582821430479141 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,892] Trial 198 finished with value: 0.5786923775439347 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 28 with value: 0.590080658084504.\n[I 2024-02-27 10:29:34,972] Trial 199 finished with value: 0.5248864911062443 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 28 with value: 0.590080658084504.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}\naccuracy: 0.5745341614906833\nrecall: 0.3968019996183626\nprecision: 0.5312342564201614\nf1-score: 0.41724634413299694\nroc_auc:  0.6537222802539465\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:35.073350Z","iopub.execute_input":"2024-02-27T10:29:35.073602Z","iopub.status.idle":"2024-02-27T10:29:35.087423Z","shell.execute_reply.started":"2024-02-27T10:29:35.073579Z","shell.execute_reply":"2024-02-27T10:29:35.086400Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"K-Nearest Neighbors - Modular PCA 9\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Gaussian NB","metadata":{}},{"cell_type":"markdown","source":"**Pre-tunning**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train_reduced, y_train)\n\ny_pred = gnb.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovr')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:35.088451Z","iopub.execute_input":"2024-02-27T10:29:35.088720Z","iopub.status.idle":"2024-02-27T10:29:35.105358Z","shell.execute_reply.started":"2024-02-27T10:29:35.088695Z","shell.execute_reply":"2024-02-27T10:29:35.104445Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"accuracy: 0.7142857142857143\nrecall: 0.5816374403860066\nprecision: 0.694151910767325\nf1-score: 0.6035950933196474\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    hyperparams = {\n        'var_smoothing': trial.suggest_float('var_smoothing', 1e-9, 1e-4, log = True)\n    }\n    \n    model = GaussianNB(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:35.107295Z","iopub.execute_input":"2024-02-27T10:29:35.107743Z","iopub.status.idle":"2024-02-27T10:29:35.113181Z","shell.execute_reply.started":"2024-02-27T10:29:35.107718Z","shell.execute_reply":"2024-02-27T10:29:35.112320Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = GaussianNB(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['gnb'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Gaussian Naives Bayes'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:35.115387Z","iopub.execute_input":"2024-02-27T10:29:35.115594Z","iopub.status.idle":"2024-02-27T10:29:37.071138Z","shell.execute_reply.started":"2024-02-27T10:29:35.115575Z","shell.execute_reply":"2024-02-27T10:29:37.070365Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:29:35,120] A new study created in memory with name: no-name-5105349f-bd69-4d68-96c2-3f67c53c6e3e\n[I 2024-02-27 10:29:35,137] Trial 0 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.6925823260159494e-06}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,153] Trial 1 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.000842006610292e-08}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,168] Trial 2 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.022675388019251e-06}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,183] Trial 3 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.9083797903007153e-08}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,199] Trial 4 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.269692034339441e-09}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,213] Trial 5 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.5434364150222305e-07}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,229] Trial 6 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 2.5377059257652843e-07}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,246] Trial 7 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.817185629537047e-09}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,262] Trial 8 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 8.792944710183913e-06}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,278] Trial 9 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 7.0479791032355525e-06}. Best is trial 0 with value: 0.6201057635810053.\n[I 2024-02-27 10:29:35,297] Trial 10 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 6.961599804228123e-05}. Best is trial 10 with value: 0.6232092302761605.\n[I 2024-02-27 10:29:35,319] Trial 11 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.109340223175693e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,337] Trial 12 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 5.988202110891376e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,356] Trial 13 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.76968086503326e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,374] Trial 14 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.702454467048e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,394] Trial 15 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.225223255726525e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,413] Trial 16 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.2081176719447593e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,431] Trial 17 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.9903785926568707e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,450] Trial 18 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.7466302343801928e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,468] Trial 19 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.6140714591231505e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,486] Trial 20 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.949627576346073e-07}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,505] Trial 21 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 8.437397353618167e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,523] Trial 22 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 8.80276465202989e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,545] Trial 23 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.498872044124148e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,566] Trial 24 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 9.681082028091114e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,586] Trial 25 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 3.9724792099858247e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,606] Trial 26 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.966918537834231e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,626] Trial 27 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.3445674660973517e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,646] Trial 28 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 4.086786851192206e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,666] Trial 29 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.7927917768944683e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,686] Trial 30 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.01440199554014e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,707] Trial 31 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 9.930667807909354e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,728] Trial 32 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 4.7821766416223334e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,746] Trial 33 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.5100104696605622e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,765] Trial 34 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.178685601611615e-08}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,784] Trial 35 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 4.084472277079478e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,803] Trial 36 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 9.878686635900576e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,821] Trial 37 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 9.449825253487435e-08}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,841] Trial 38 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.399506076861755e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,861] Trial 39 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 8.752076724656612e-09}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,881] Trial 40 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 3.0117154117351564e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,901] Trial 41 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 5.639808796156192e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,920] Trial 42 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 6.972389076933954e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,939] Trial 43 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.1184936476503076e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,959] Trial 44 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 6.0267016949019564e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,978] Trial 45 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 8.061187952254806e-07}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:35,996] Trial 46 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.860407359757942e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,014] Trial 47 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 3.237179197960865e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,033] Trial 48 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 6.149107140015975e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,052] Trial 49 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.1412952210019e-09}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,071] Trial 50 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 6.653984306186838e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,089] Trial 51 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 6.856027595580359e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,108] Trial 52 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 6.809388558498817e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,128] Trial 53 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.1955657566093447e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,146] Trial 54 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 9.919929186120413e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,164] Trial 55 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 3.201482901342647e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,183] Trial 56 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.6317267792829046e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,202] Trial 57 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 5.7027475563829515e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,221] Trial 58 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.0817593074498078e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,240] Trial 59 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 3.858252145825885e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,259] Trial 60 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.5926236679888072e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,280] Trial 61 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.052380917431966e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,299] Trial 62 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 6.677676143979827e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,321] Trial 63 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 4.524500597749089e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,342] Trial 64 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.100856597765782e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,365] Trial 65 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.8754096457451886e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,385] Trial 66 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 7.912018116770103e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,406] Trial 67 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 4.462463890576652e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,426] Trial 68 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.8122061062516693e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,447] Trial 69 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 8.605689436863477e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,467] Trial 70 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 3.6584491578673383e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,488] Trial 71 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 4.818446783467416e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,508] Trial 72 finished with value: 0.6221729608461086 and parameters: {'var_smoothing': 6.318153520823402e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,528] Trial 73 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 3.4920099559816775e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,549] Trial 74 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.693945198476147e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,568] Trial 75 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.3242924103628608e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,587] Trial 76 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 9.296254592733468e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,605] Trial 77 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 1.8055306025579643e-07}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,623] Trial 78 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 4.539232610709993e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,643] Trial 79 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.2244303522470052e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,666] Trial 80 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 8.147131612420898e-06}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,686] Trial 81 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.328975752163992e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,708] Trial 82 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 7.854950389241957e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,728] Trial 83 finished with value: 0.620100421986005 and parameters: {'var_smoothing': 3.633971293736242e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,748] Trial 84 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 2.3229220394563468e-08}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,767] Trial 85 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 5.301008795167045e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,786] Trial 86 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 9.93245774216201e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,804] Trial 87 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.791999933260364e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,824] Trial 88 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.439177084573703e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,843] Trial 89 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 5.563915240490412e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,865] Trial 90 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.471085563895378e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,885] Trial 91 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.638208196589608e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,908] Trial 92 finished with value: 0.6232092302761604 and parameters: {'var_smoothing': 8.013998574623198e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,928] Trial 93 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 3.611544964413938e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,948] Trial 94 finished with value: 0.6211366914160569 and parameters: {'var_smoothing': 4.970617955066784e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,968] Trial 95 finished with value: 0.6232092302761605 and parameters: {'var_smoothing': 7.01313464770758e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:36,987] Trial 96 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.274615087873296e-09}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:37,008] Trial 97 finished with value: 0.6190694941509535 and parameters: {'var_smoothing': 2.440429978436454e-05}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:37,031] Trial 98 finished with value: 0.6201057635810053 and parameters: {'var_smoothing': 5.69532725625499e-07}. Best is trial 11 with value: 0.6242454997062122.\n[I 2024-02-27 10:29:37,052] Trial 99 finished with value: 0.6242454997062122 and parameters: {'var_smoothing': 7.561698067335352e-05}. Best is trial 11 with value: 0.6242454997062122.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'var_smoothing': 7.109340223175693e-05}\naccuracy: 0.717391304347826\nrecall: 0.5863993451479114\nprecision: 0.7195376748290473\nf1-score: 0.6087146998477048\nroc_auc:  0.7654934544544034\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:37.072260Z","iopub.execute_input":"2024-02-27T10:29:37.072565Z","iopub.status.idle":"2024-02-27T10:29:37.084592Z","shell.execute_reply.started":"2024-02-27T10:29:37.072539Z","shell.execute_reply":"2024-02-27T10:29:37.083556Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Gaussian Naives Bayes - Modular PCA 9\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train_reduced, y_train)\ny_pred = lr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# # One-hot encoding for probability calculation (adapt if necessary)\n# y_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\n# y_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:37.085426Z","iopub.execute_input":"2024-02-27T10:29:37.085635Z","iopub.status.idle":"2024-02-27T10:29:37.165652Z","shell.execute_reply.started":"2024-02-27T10:29:37.085616Z","shell.execute_reply":"2024-02-27T10:29:37.164842Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"accuracy: 0.8385093167701864\nrecall: 0.7598173197319368\nprecision: 0.810508065396356\nf1-score: 0.780496293634981\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'saga']),\n        'penalty': trial.suggest_categorical('penalty', ['l2']),\n        'multi_class': trial.suggest_categorical('multi_class', ['ovr']),\n        'C': trial.suggest_loguniform(\"C\", 1e-3, 1e3),\n        'n_jobs': -1\n    }\n\n    model = LogisticRegression(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:37.166649Z","iopub.execute_input":"2024-02-27T10:29:37.167042Z","iopub.status.idle":"2024-02-27T10:29:37.175401Z","shell.execute_reply.started":"2024-02-27T10:29:37.167018Z","shell.execute_reply":"2024-02-27T10:29:37.174650Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = LogisticRegression(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['logistic regression'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Logistic Regression'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:29:37.176395Z","iopub.execute_input":"2024-02-27T10:29:37.176919Z","iopub.status.idle":"2024-02-27T10:32:01.693679Z","shell.execute_reply.started":"2024-02-27T10:29:37.176892Z","shell.execute_reply":"2024-02-27T10:32:01.692956Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:29:37,184] A new study created in memory with name: no-name-f71151b2-0f9f-4576-96f7-3b1dd6ece576\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[I 2024-02-27 10:29:38,421] Trial 0 finished with value: 0.7660541637733027 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.859073381607703}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:38,932] Trial 1 finished with value: 0.7453501415522675 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 272.8384309970853}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:41,395] Trial 2 finished with value: 0.7660488221783025 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 119.93342611025456}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:42,840] Trial 3 finished with value: 0.7308477111265423 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.08741180386745927}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:46,946] Trial 4 finished with value: 0.7474226804123711 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 72.73998713302092}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:51,041] Trial 5 finished with value: 0.7463864109823193 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 73.91109057354988}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:51,911] Trial 6 finished with value: 0.6935687196196783 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.022401880767296847}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:52,493] Trial 7 finished with value: 0.46995886971849793 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.002985794613579281}. Best is trial 0 with value: 0.7660541637733027.\n[I 2024-02-27 10:29:52,908] Trial 8 finished with value: 0.7681320442284066 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5511844418561398}. Best is trial 8 with value: 0.7681320442284066.\n[I 2024-02-27 10:29:53,029] Trial 9 finished with value: 0.5693445862934672 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.010292544094084437}. Best is trial 8 with value: 0.7681320442284066.\n[I 2024-02-27 10:29:53,429] Trial 10 finished with value: 0.77019924149351 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.1714538028550956}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:53,816] Trial 11 finished with value: 0.7681267026334064 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7957849242909324}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:54,196] Trial 12 finished with value: 0.7681267026334064 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.8052602825228787}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:54,615] Trial 13 finished with value: 0.7619090860530955 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 5.996707827203854}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:54,791] Trial 14 finished with value: 0.7308477111265423 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.08627048497472503}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:55,210] Trial 15 finished with value: 0.7598365471929919 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 9.51833787232611}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:55,640] Trial 16 finished with value: 0.766059505368303 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2624883859865574}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:56,110] Trial 17 finished with value: 0.7681213610384061 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.888806403848315}. Best is trial 10 with value: 0.77019924149351.\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n[I 2024-02-27 10:29:56,491] Trial 18 finished with value: 0.7525933443726297 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 18.628800376482364}. Best is trial 10 with value: 0.77019924149351.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:29:56,849] Trial 19 finished with value: 0.4213236472410662 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.001132302610091983}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:57,219] Trial 20 finished with value: 0.7619090860530955 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2200995914001397}. Best is trial 10 with value: 0.77019924149351.\n[I 2024-02-27 10:29:57,675] Trial 21 finished with value: 0.7712301693285616 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9057963278876979}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:29:58,103] Trial 22 finished with value: 0.7681267026334064 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.3468570862926637}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:29:58,535] Trial 23 finished with value: 0.7670957747983549 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.45955899469876205}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:29:58,987] Trial 24 finished with value: 0.7194540889909726 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.06713345828387025}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:29:59,398] Trial 25 finished with value: 0.7505208055125261 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 26.63137519847259}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:01,918] Trial 26 finished with value: 0.7701885583035095 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.5961348135612914}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:04,391] Trial 27 finished with value: 0.7701885583035095 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.400808045092687}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:06,861] Trial 28 finished with value: 0.7701938998985097 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.732401227765926}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:09,341] Trial 29 finished with value: 0.7701938998985097 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.2211459705870795}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:11,799] Trial 30 finished with value: 0.7650125527482506 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 13.183431425076648}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:14,257] Trial 31 finished with value: 0.7712301693285616 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.321504799750806}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:16,727] Trial 32 finished with value: 0.7681160194434058 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 734.2146413558885}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:19,228] Trial 33 finished with value: 0.7681213610384061 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 4.372671784955858}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:21,841] Trial 34 finished with value: 0.7598312055979916 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2055779992135276}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:24,277] Trial 35 finished with value: 0.7691522888734577 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 40.50044536811915}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:27,300] Trial 36 finished with value: 0.7588056193579403 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 7.971986635947966}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:27,687] Trial 37 finished with value: 0.7443138721222157 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 169.65465862678226}. Best is trial 21 with value: 0.7712301693285616.\n[I 2024-02-27 10:30:30,085] Trial 38 finished with value: 0.7722610971636131 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.317607788158927}. Best is trial 38 with value: 0.7722610971636131.\n[I 2024-02-27 10:30:31,105] Trial 39 finished with value: 0.7184231611559211 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.04098050921446056}. Best is trial 38 with value: 0.7722610971636131.\n[I 2024-02-27 10:30:32,740] Trial 40 finished with value: 0.7753645638587683 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.37667181571788055}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:34,428] Trial 41 finished with value: 0.7722610971636131 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4259241967124787}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:35,982] Trial 42 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.28750917094991263}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:37,635] Trial 43 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4002480283599393}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:39,250] Trial 44 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3605651965269965}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:40,018] Trial 45 finished with value: 0.6790769723839539 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.014944440703304963}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:41,327] Trial 46 finished with value: 0.7608674750280434 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1481817541025647}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:42,285] Trial 47 finished with value: 0.7142780834357139 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.03366935134122628}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:43,499] Trial 48 finished with value: 0.7494791944874739 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.09974251271711294}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:45,075] Trial 49 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.33392272817560803}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:46,694] Trial 50 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.363963746315414}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:48,299] Trial 51 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3613584425582618}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:50,040] Trial 52 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5423007423317951}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:51,125] Trial 53 finished with value: 0.7339565194166978 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.055687012368289}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:52,383] Trial 54 finished with value: 0.754660541637733 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.12558680010849083}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:53,946] Trial 55 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2937799099257311}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:55,773] Trial 56 finished with value: 0.7722664387586133 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7121036127527134}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:57,108] Trial 57 finished with value: 0.7691469472784573 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.16690725380162172}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:30:58,731] Trial 58 finished with value: 0.7753645638587683 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.38206543368910156}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:00,650] Trial 59 finished with value: 0.7743389776187171 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.8819794017695713}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:01,268] Trial 60 finished with value: 0.6231718391111586 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.006159738638116798}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:03,166] Trial 61 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.85523410172718}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:04,888] Trial 62 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.48685004984927466}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:07,022] Trial 63 finished with value: 0.769157630468458 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.4504051372755113}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:08,194] Trial 64 finished with value: 0.7463757277923188 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.08918206636409759}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:08,469] Trial 65 finished with value: 0.7681267026334064 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6741538728514109}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:10,742] Trial 66 finished with value: 0.7722610971636131 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.907207763599726}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:12,723] Trial 67 finished with value: 0.7722664387586133 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.0862599663156476}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:14,172] Trial 68 finished with value: 0.7743282944287164 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.23111963206569922}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:15,809] Trial 69 finished with value: 0.7753645638587683 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3830213103676336}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:17,094] Trial 70 finished with value: 0.761898402863095 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.13586332743583895}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:18,679] Trial 71 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.324233057249612}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:20,367] Trial 72 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.41467319116971574}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:21,721] Trial 73 finished with value: 0.7722557555686128 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.189996035292324}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:21,974] Trial 74 finished with value: 0.7691629720634582 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5982812776757809}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:23,943] Trial 75 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9781567894147827}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:25,626] Trial 76 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.41484981787562825}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:26,758] Trial 77 finished with value: 0.7412050638320602 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.07388521461744606}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:29,570] Trial 78 finished with value: 0.7619037444580952 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 5.451220938037111}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:30,586] Trial 79 finished with value: 0.7204957000160247 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.04139499292483381}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:32,969] Trial 80 finished with value: 0.7722610971636131 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.2693020082188995}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:34,521] Trial 81 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2785206740293279}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:35,935] Trial 82 finished with value: 0.7753645638587683 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.22424103660537814}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:37,167] Trial 83 finished with value: 0.7515463917525773 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1166148207547237}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:38,513] Trial 84 finished with value: 0.7712194861385611 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.18229787515900378}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:40,484] Trial 85 finished with value: 0.7722664387586133 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.0881697533301884}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:40,719] Trial 86 finished with value: 0.7650285775332515 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3854746322122748}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:42,506] Trial 87 finished with value: 0.7722664387586133 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6451017168374807}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:43,960] Trial 88 finished with value: 0.7743282944287164 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.23888914041126635}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:45,059] Trial 89 finished with value: 0.737059986111853 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0624198586594637}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:46,813] Trial 90 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5216870867219293}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:48,358] Trial 91 finished with value: 0.7732973665936649 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2719072069309037}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:49,940] Trial 92 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3279927140820573}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:51,265] Trial 93 finished with value: 0.7670744084183537 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.15968850866394335}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:53,350] Trial 94 finished with value: 0.7712301693285616 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.3262533753105887}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:55,206] Trial 95 finished with value: 0.7722664387586133 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7728045828612008}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:56,410] Trial 96 finished with value: 0.7494791944874739 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.09560247169679295}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:31:58,604] Trial 97 finished with value: 0.7722610971636131 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.7607438679704515}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:32:00,017] Trial 98 finished with value: 0.7753645638587683 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.22002898576624325}. Best is trial 40 with value: 0.7753645638587683.\n[I 2024-02-27 10:32:01,243] Trial 99 finished with value: 0.7525826611826292 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.11930092682625429}. Best is trial 40 with value: 0.7753645638587683.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.37667181571788055}\naccuracy: 0.8478260869565217\nrecall: 0.757637266424064\nprecision: 0.8464531203910316\nf1-score: 0.7917214672506161\nroc_auc:  0.8635491516772549\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:32:01.694838Z","iopub.execute_input":"2024-02-27T10:32:01.695315Z","iopub.status.idle":"2024-02-27T10:32:01.709703Z","shell.execute_reply.started":"2024-02-27T10:32:01.695285Z","shell.execute_reply":"2024-02-27T10:32:01.708876Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Logistic Regression - Modular PCA 9\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:32:01.711234Z","iopub.execute_input":"2024-02-27T10:32:01.711568Z","iopub.status.idle":"2024-02-27T10:32:01.715406Z","shell.execute_reply.started":"2024-02-27T10:32:01.711539Z","shell.execute_reply":"2024-02-27T10:32:01.714534Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestClassifier(random_state=42)\nrfr.fit(X_train_reduced,y_train)\ny_pred = rfr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:32:01.716832Z","iopub.execute_input":"2024-02-27T10:32:01.717415Z","iopub.status.idle":"2024-02-27T10:32:02.590197Z","shell.execute_reply.started":"2024-02-27T10:32:01.717388Z","shell.execute_reply":"2024-02-27T10:32:02.588634Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"accuracy: 0.515527950310559\nrecall: 0.2315455709491647\nprecision: 0.4673469387755102\nf1-score: 0.20717227958499534\nroc_auc:  0.6009164953280999\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\n\n\ndef objective(trial):\n    hyperparams = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'max_depth': trial.suggest_int('max_depth', 10, 50),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n        'random_state': trial.suggest_categorical('random_state', [42]),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n        'n_jobs': -1\n    }\n\n    model = RandomForestClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:32:02.591595Z","iopub.execute_input":"2024-02-27T10:32:02.591903Z","iopub.status.idle":"2024-02-27T10:32:02.598124Z","shell.execute_reply.started":"2024-02-27T10:32:02.591880Z","shell.execute_reply":"2024-02-27T10:32:02.596821Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:32:02.599703Z","iopub.execute_input":"2024-02-27T10:32:02.600217Z","iopub.status.idle":"2024-02-27T10:54:34.126706Z","shell.execute_reply.started":"2024-02-27T10:32:02.600193Z","shell.execute_reply":"2024-02-27T10:54:34.125726Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:32:02,603] A new study created in memory with name: no-name-e311ecef-59d4-49ab-91cc-aa2f40ef3843\n[I 2024-02-27 10:32:05,657] Trial 0 finished with value: 0.4513540943325677 and parameters: {'n_estimators': 171, 'max_depth': 30, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:13,481] Trial 1 finished with value: 0.42132898883606645 and parameters: {'n_estimators': 517, 'max_depth': 42, 'min_samples_split': 17, 'random_state': 42, 'min_samples_leaf': 30}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:23,047] Trial 2 finished with value: 0.4420383526521019 and parameters: {'n_estimators': 567, 'max_depth': 29, 'min_samples_split': 29, 'random_state': 42, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:28,951] Trial 3 finished with value: 0.44928155547246407 and parameters: {'n_estimators': 331, 'max_depth': 20, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:41,783] Trial 4 finished with value: 0.43065007211153244 and parameters: {'n_estimators': 803, 'max_depth': 43, 'min_samples_split': 25, 'random_state': 42, 'min_samples_leaf': 21}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:45,892] Trial 5 finished with value: 0.43583141926179153 and parameters: {'n_estimators': 251, 'max_depth': 14, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:48,633] Trial 6 finished with value: 0.43686768869184334 and parameters: {'n_estimators': 161, 'max_depth': 15, 'min_samples_split': 28, 'random_state': 42, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:32:57,499] Trial 7 finished with value: 0.42029271940601465 and parameters: {'n_estimators': 578, 'max_depth': 31, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 30}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:33:05,221] Trial 8 finished with value: 0.43583141926179153 and parameters: {'n_estimators': 458, 'max_depth': 30, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:33:17,076] Trial 9 finished with value: 0.42340152769617 and parameters: {'n_estimators': 770, 'max_depth': 19, 'min_samples_split': 19, 'random_state': 42, 'min_samples_leaf': 27}. Best is trial 0 with value: 0.4513540943325677.\n[I 2024-02-27 10:33:37,635] Trial 10 finished with value: 0.472042091768602 and parameters: {'n_estimators': 984, 'max_depth': 48, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:33:58,710] Trial 11 finished with value: 0.47101650552855084 and parameters: {'n_estimators': 1000, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:34:18,703] Trial 12 finished with value: 0.4668874525933444 and parameters: {'n_estimators': 991, 'max_depth': 49, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:34:39,425] Trial 13 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 992, 'max_depth': 50, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:34:54,825] Trial 14 finished with value: 0.4658298167832915 and parameters: {'n_estimators': 814, 'max_depth': 42, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:35:10,902] Trial 15 finished with value: 0.45239036376261954 and parameters: {'n_estimators': 873, 'max_depth': 37, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:35:23,301] Trial 16 finished with value: 0.4503178249025159 and parameters: {'n_estimators': 659, 'max_depth': 46, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.472042091768602.\n[I 2024-02-27 10:35:42,112] Trial 17 finished with value: 0.47205277495860265 and parameters: {'n_estimators': 886, 'max_depth': 37, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:35:54,380] Trial 18 finished with value: 0.44515250253725763 and parameters: {'n_estimators': 703, 'max_depth': 36, 'min_samples_split': 17, 'random_state': 42, 'min_samples_leaf': 11}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:36:11,630] Trial 19 finished with value: 0.4616847390630842 and parameters: {'n_estimators': 891, 'max_depth': 36, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:36:25,995] Trial 20 finished with value: 0.4254740665562736 and parameters: {'n_estimators': 911, 'max_depth': 24, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 24}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:36:46,311] Trial 21 finished with value: 0.46792372202339616 and parameters: {'n_estimators': 992, 'max_depth': 46, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:37:01,861] Trial 22 finished with value: 0.4513540943325677 and parameters: {'n_estimators': 886, 'max_depth': 40, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 9}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:37:16,727] Trial 23 finished with value: 0.46894396666844723 and parameters: {'n_estimators': 710, 'max_depth': 46, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:37:34,756] Trial 24 finished with value: 0.4616847390630842 and parameters: {'n_estimators': 932, 'max_depth': 50, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:37:48,599] Trial 25 finished with value: 0.44307996367715397 and parameters: {'n_estimators': 817, 'max_depth': 39, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 14}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:38:05,973] Trial 26 finished with value: 0.45548848886277443 and parameters: {'n_estimators': 936, 'max_depth': 33, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:38:19,158] Trial 27 finished with value: 0.451359435927568 and parameters: {'n_estimators': 732, 'max_depth': 45, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:38:31,763] Trial 28 finished with value: 0.45548314726777417 and parameters: {'n_estimators': 660, 'max_depth': 26, 'min_samples_split': 14, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:38:49,064] Trial 29 finished with value: 0.4430746220821537 and parameters: {'n_estimators': 998, 'max_depth': 48, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 12}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:39:05,791] Trial 30 finished with value: 0.44928689706746433 and parameters: {'n_estimators': 855, 'max_depth': 34, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:39:25,336] Trial 31 finished with value: 0.4637733027081887 and parameters: {'n_estimators': 934, 'max_depth': 45, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:39:41,599] Trial 32 finished with value: 0.46893862507344697 and parameters: {'n_estimators': 771, 'max_depth': 40, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:39:53,876] Trial 33 finished with value: 0.46377864430318894 and parameters: {'n_estimators': 610, 'max_depth': 47, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:40:02,328] Trial 34 finished with value: 0.4389295443619464 and parameters: {'n_estimators': 481, 'max_depth': 43, 'min_samples_split': 32, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:40:18,212] Trial 35 finished with value: 0.45237968057261896 and parameters: {'n_estimators': 840, 'max_depth': 43, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:40:37,403] Trial 36 finished with value: 0.4585866139629293 and parameters: {'n_estimators': 941, 'max_depth': 10, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:40:50,295] Trial 37 finished with value: 0.4410127664120506 and parameters: {'n_estimators': 742, 'max_depth': 48, 'min_samples_split': 21, 'random_state': 42, 'min_samples_leaf': 13}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:40:56,952] Trial 38 finished with value: 0.447219699802361 and parameters: {'n_estimators': 369, 'max_depth': 44, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:41:07,942] Trial 39 finished with value: 0.43480049142674 and parameters: {'n_estimators': 669, 'max_depth': 39, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 19}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:41:09,997] Trial 40 finished with value: 0.4606538112280327 and parameters: {'n_estimators': 100, 'max_depth': 41, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:41:26,628] Trial 41 finished with value: 0.46479888894823995 and parameters: {'n_estimators': 792, 'max_depth': 38, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:41:42,147] Trial 42 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 770, 'max_depth': 41, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:41:59,678] Trial 43 finished with value: 0.4689493082634474 and parameters: {'n_estimators': 849, 'max_depth': 50, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:42:18,016] Trial 44 finished with value: 0.46272635008813634 and parameters: {'n_estimators': 965, 'max_depth': 50, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:42:31,232] Trial 45 finished with value: 0.4171892527108595 and parameters: {'n_estimators': 875, 'max_depth': 48, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 32}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:42:48,485] Trial 46 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 845, 'max_depth': 47, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:43:06,568] Trial 47 finished with value: 0.45962288339298113 and parameters: {'n_estimators': 902, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:43:24,415] Trial 48 finished with value: 0.447219699802361 and parameters: {'n_estimators': 965, 'max_depth': 45, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:43:35,769] Trial 49 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 610, 'max_depth': 48, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:43:46,991] Trial 50 finished with value: 0.4265103359863255 and parameters: {'n_estimators': 706, 'max_depth': 27, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 23}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:44:03,615] Trial 51 finished with value: 0.46894396666844723 and parameters: {'n_estimators': 792, 'max_depth': 42, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:44:20,259] Trial 52 finished with value: 0.4627316916831366 and parameters: {'n_estimators': 815, 'max_depth': 43, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.47205277495860265.\n[I 2024-02-27 10:44:40,572] Trial 53 finished with value: 0.4730783611986539 and parameters: {'n_estimators': 966, 'max_depth': 46, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:44:59,662] Trial 54 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 956, 'max_depth': 49, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:45:18,519] Trial 55 finished with value: 0.46791838042839584 and parameters: {'n_estimators': 918, 'max_depth': 46, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:45:35,133] Trial 56 finished with value: 0.4647935473532397 and parameters: {'n_estimators': 867, 'max_depth': 47, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:45:51,961] Trial 57 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 903, 'max_depth': 21, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:46:08,400] Trial 58 finished with value: 0.43686768869184334 and parameters: {'n_estimators': 972, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 16}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:46:19,152] Trial 59 finished with value: 0.4616847390630842 and parameters: {'n_estimators': 549, 'max_depth': 32, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:46:38,862] Trial 60 finished with value: 0.4586133219379306 and parameters: {'n_estimators': 990, 'max_depth': 44, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:46:56,476] Trial 61 finished with value: 0.465840499973292 and parameters: {'n_estimators': 850, 'max_depth': 42, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:47:15,309] Trial 62 finished with value: 0.4648042305432402 and parameters: {'n_estimators': 908, 'max_depth': 46, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:47:31,044] Trial 63 finished with value: 0.46065915282303294 and parameters: {'n_estimators': 791, 'max_depth': 49, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:47:44,717] Trial 64 finished with value: 0.447219699802361 and parameters: {'n_estimators': 749, 'max_depth': 35, 'min_samples_split': 27, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:48:01,462] Trial 65 finished with value: 0.4689493082634474 and parameters: {'n_estimators': 822, 'max_depth': 44, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:48:19,654] Trial 66 finished with value: 0.4616847390630842 and parameters: {'n_estimators': 939, 'max_depth': 45, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:48:35,141] Trial 67 finished with value: 0.45237968057261896 and parameters: {'n_estimators': 830, 'max_depth': 47, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:48:48,552] Trial 68 finished with value: 0.4244377971262218 and parameters: {'n_estimators': 875, 'max_depth': 44, 'min_samples_split': 18, 'random_state': 42, 'min_samples_leaf': 27}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:49:08,813] Trial 69 finished with value: 0.4668874525933444 and parameters: {'n_estimators': 993, 'max_depth': 37, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:49:27,849] Trial 70 finished with value: 0.4710165055285508 and parameters: {'n_estimators': 947, 'max_depth': 48, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:49:47,500] Trial 71 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 956, 'max_depth': 49, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:50:06,027] Trial 72 finished with value: 0.46065915282303294 and parameters: {'n_estimators': 918, 'max_depth': 46, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:50:24,634] Trial 73 finished with value: 0.4585866139629293 and parameters: {'n_estimators': 889, 'max_depth': 48, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:50:44,140] Trial 74 finished with value: 0.462721008493136 and parameters: {'n_estimators': 1000, 'max_depth': 50, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:51:03,645] Trial 75 finished with value: 0.47205811655360286 and parameters: {'n_estimators': 937, 'max_depth': 47, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:51:22,570] Trial 76 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 936, 'max_depth': 47, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:51:27,013] Trial 77 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 239, 'max_depth': 44, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:51:45,402] Trial 78 finished with value: 0.45548848886277443 and parameters: {'n_estimators': 972, 'max_depth': 49, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:51:54,352] Trial 79 finished with value: 0.47205811655360297 and parameters: {'n_estimators': 426, 'max_depth': 48, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:02,175] Trial 80 finished with value: 0.46272635008813634 and parameters: {'n_estimators': 394, 'max_depth': 29, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:10,197] Trial 81 finished with value: 0.4699962608834999 and parameters: {'n_estimators': 385, 'max_depth': 48, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:18,414] Trial 82 finished with value: 0.4699695529084985 and parameters: {'n_estimators': 393, 'max_depth': 49, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:27,350] Trial 83 finished with value: 0.45342663319267135 and parameters: {'n_estimators': 444, 'max_depth': 48, 'min_samples_split': 20, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:33,777] Trial 84 finished with value: 0.46999091928849956 and parameters: {'n_estimators': 297, 'max_depth': 49, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:39,378] Trial 85 finished with value: 0.465840499973292 and parameters: {'n_estimators': 276, 'max_depth': 47, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:44,226] Trial 86 finished with value: 0.451359435927568 and parameters: {'n_estimators': 249, 'max_depth': 45, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:50,562] Trial 87 finished with value: 0.4637679611131884 and parameters: {'n_estimators': 311, 'max_depth': 48, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:52:57,754] Trial 88 finished with value: 0.45859729715292985 and parameters: {'n_estimators': 342, 'max_depth': 46, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:07,243] Trial 89 finished with value: 0.462721008493136 and parameters: {'n_estimators': 485, 'max_depth': 49, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:10,894] Trial 90 finished with value: 0.4327226109716361 and parameters: {'n_estimators': 217, 'max_depth': 45, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 19}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:19,312] Trial 91 finished with value: 0.4648042305432402 and parameters: {'n_estimators': 397, 'max_depth': 49, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:27,799] Trial 92 finished with value: 0.4679023556433951 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:36,732] Trial 93 finished with value: 0.4699909192884995 and parameters: {'n_estimators': 431, 'max_depth': 47, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:45,559] Trial 94 finished with value: 0.4699855776934993 and parameters: {'n_estimators': 422, 'max_depth': 47, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:53:56,230] Trial 95 finished with value: 0.46791838042839584 and parameters: {'n_estimators': 510, 'max_depth': 48, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:54:03,314] Trial 96 finished with value: 0.45754500293787725 and parameters: {'n_estimators': 355, 'max_depth': 41, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:54:09,539] Trial 97 finished with value: 0.4668874525933443 and parameters: {'n_estimators': 304, 'max_depth': 46, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:54:19,027] Trial 98 finished with value: 0.46170076384808506 and parameters: {'n_estimators': 445, 'max_depth': 43, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.4730783611986539.\n[I 2024-02-27 10:54:26,168] Trial 99 finished with value: 0.46376261951818815 and parameters: {'n_estimators': 372, 'max_depth': 48, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 53 with value: 0.4730783611986539.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_estimators': 966, 'max_depth': 46, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 1}\n","output_type":"stream"},{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"0.5031055900621118"},"metadata":{}}]},{"cell_type":"code","source":"final_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['random forest'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Random Forest'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:54:34.127859Z","iopub.execute_input":"2024-02-27T10:54:34.128165Z","iopub.status.idle":"2024-02-27T10:54:42.154324Z","shell.execute_reply.started":"2024-02-27T10:54:34.128140Z","shell.execute_reply":"2024-02-27T10:54:42.153404Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"accuracy: 0.5031055900621118\nrecall: 0.21307506053268765\nprecision: 0.2077035592393954\nf1-score: 0.18335772209011644\nroc_auc:  0.5460688983691405\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:54:42.155713Z","iopub.execute_input":"2024-02-27T10:54:42.156456Z","iopub.status.idle":"2024-02-27T10:54:42.169553Z","shell.execute_reply.started":"2024-02-27T10:54:42.156401Z","shell.execute_reply":"2024-02-27T10:54:42.168490Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Random Forest\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# num_image = 16","metadata":{}},{"cell_type":"code","source":"n_components_pca = 150\nnum_images = 16\n\npca = ModularPCA(n_components=n_components_pca, num_image= num_images)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced = pca.transform(X_test)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:54:42.170526Z","iopub.execute_input":"2024-02-27T10:54:42.170833Z","iopub.status.idle":"2024-02-27T10:54:42.977352Z","shell.execute_reply.started":"2024-02-27T10:54:42.170809Z","shell.execute_reply":"2024-02-27T10:54:42.976592Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine ","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:54:42.978421Z","iopub.execute_input":"2024-02-27T10:54:42.979776Z","iopub.status.idle":"2024-02-27T10:54:43.128300Z","shell.execute_reply.started":"2024-02-27T10:54:42.979740Z","shell.execute_reply":"2024-02-27T10:54:43.127497Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"accuracy: 0.782608695652174\nrecall: 0.6939846589840217\nprecision: 0.7458541698000827\nf1-score: 0.7089703542266247\nroc_auc:  0.8266748408088155\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        # 'degree': trial.suggest_int('degree', 2, 5),  # for polynomial kernel\n        'tol': trial.suggest_loguniform('tol', 1e-4, 1e-2),\n        'shrinking': trial.suggest_categorical('shrinking', [True, False]),\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = SVC(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:54:43.129233Z","iopub.execute_input":"2024-02-27T10:54:43.129723Z","iopub.status.idle":"2024-02-27T10:54:43.136657Z","shell.execute_reply.started":"2024-02-27T10:54:43.129695Z","shell.execute_reply":"2024-02-27T10:54:43.135739Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = SVC(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['svc'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'SVM'\nmodel_scores[model_name +str(num_images)] = [accuracy,recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:54:43.145202Z","iopub.execute_input":"2024-02-27T10:54:43.145853Z","iopub.status.idle":"2024-02-27T10:55:17.820825Z","shell.execute_reply.started":"2024-02-27T10:54:43.145825Z","shell.execute_reply":"2024-02-27T10:55:17.819478Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:54:43,151] A new study created in memory with name: no-name-7bc6e369-8f6a-406a-a0ca-10d6b3a1c2f4\n[I 2024-02-27 10:54:43,883] Trial 0 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.06864618491723774, 'gamma': 27838.58909416482, 'tol': 0.00011418456127682226, 'shrinking': True}. Best is trial 0 with value: 0.41097163613054855.\n[I 2024-02-27 10:54:44,333] Trial 1 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 95694.64598824499, 'gamma': 49856.98116319246, 'tol': 0.00015838527575846035, 'shrinking': False}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:44,606] Trial 2 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 2.139779730515894, 'gamma': 58.1120112657683, 'tol': 0.0023447842364107286, 'shrinking': True}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:44,898] Trial 3 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 2.568741355363013, 'gamma': 0.00012739189823197922, 'tol': 0.001301908015817316, 'shrinking': True}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:45,283] Trial 4 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.023408372755242015, 'gamma': 0.012191993670337149, 'tol': 0.0005121071869263696, 'shrinking': True}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:45,654] Trial 5 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 28217.93501093811, 'gamma': 1241.0033819125174, 'tol': 0.000356274258149066, 'shrinking': False}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:46,078] Trial 6 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.0009624795210339732, 'gamma': 9004.093777184391, 'tol': 0.0009375651391923609, 'shrinking': True}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:46,473] Trial 7 finished with value: 0.5600235030180011 and parameters: {'kernel': 'poly', 'C': 1.437683280778812e-05, 'gamma': 1.0641548207308171, 'tol': 0.0007542719576017523, 'shrinking': True}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:46,834] Trial 8 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 6949.091280354988, 'gamma': 0.008688348168152962, 'tol': 0.00240120903067833, 'shrinking': False}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:47,161] Trial 9 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.06863432961810047, 'gamma': 0.0009083417556957532, 'tol': 0.00019879742264914148, 'shrinking': False}. Best is trial 1 with value: 0.7484375834624218.\n[I 2024-02-27 10:54:47,460] Trial 10 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 185.82296684582923, 'gamma': 15.05319452132018, 'tol': 0.007991497549596879, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:47,761] Trial 11 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 599.2449378458938, 'gamma': 10.418177893138738, 'tol': 0.009039144527188904, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:48,063] Trial 12 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 166.78983451592492, 'gamma': 6.002961714129364, 'tol': 0.0073343576659318, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:48,351] Trial 13 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 150.1251242140481, 'gamma': 42.295428480124144, 'tol': 0.009150502049044421, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:48,667] Trial 14 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 135.19852598913093, 'gamma': 0.061387324542048205, 'tol': 0.004396451178845857, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:49,002] Trial 15 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 1976.6904688737914, 'gamma': 301.4494528843187, 'tol': 0.004274644964269875, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:49,317] Trial 16 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 61.83892135227425, 'gamma': 0.32376448802141466, 'tol': 0.005054554554821878, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:49,656] Trial 17 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 1710.1816845538633, 'gamma': 6.483078498969484, 'tol': 0.0025890933482303267, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:49,951] Trial 18 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 13.347554224072702, 'gamma': 1532.2652595764685, 'tol': 0.009806045115352182, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:50,529] Trial 19 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 1396.142377936649, 'gamma': 2.1227015831651244, 'tol': 0.0015711866932964452, 'shrinking': False}. Best is trial 10 with value: 0.7494738528924737.\n[I 2024-02-27 10:54:50,838] Trial 20 finished with value: 0.7505101223225255 and parameters: {'kernel': 'linear', 'C': 11.756860153350258, 'gamma': 39.61566880868291, 'tol': 0.006156076129835487, 'shrinking': False}. Best is trial 20 with value: 0.7505101223225255.\n[I 2024-02-27 10:54:51,143] Trial 21 finished with value: 0.7505101223225255 and parameters: {'kernel': 'linear', 'C': 8.645363129533065, 'gamma': 44.37848422277537, 'tol': 0.006239616876892515, 'shrinking': False}. Best is trial 20 with value: 0.7505101223225255.\n[I 2024-02-27 10:54:51,454] Trial 22 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 15.236818726118244, 'gamma': 91.71255626428263, 'tol': 0.0054528300527156865, 'shrinking': False}. Best is trial 20 with value: 0.7505101223225255.\n[I 2024-02-27 10:54:51,770] Trial 23 finished with value: 0.7505154639175258 and parameters: {'kernel': 'linear', 'C': 0.49541138057851974, 'gamma': 1048.2325776125215, 'tol': 0.0036793526993247443, 'shrinking': False}. Best is trial 23 with value: 0.7505154639175258.\n[I 2024-02-27 10:54:52,092] Trial 24 finished with value: 0.7484322418674216 and parameters: {'kernel': 'linear', 'C': 0.719012241235357, 'gamma': 1295.8552850459855, 'tol': 0.0031842166622269787, 'shrinking': False}. Best is trial 23 with value: 0.7505154639175258.\n[I 2024-02-27 10:54:52,432] Trial 25 finished with value: 0.7515463917525773 and parameters: {'kernel': 'linear', 'C': 0.4371213252274524, 'gamma': 365.61453093772474, 'tol': 0.0016076383593213708, 'shrinking': False}. Best is trial 25 with value: 0.7515463917525773.\n[I 2024-02-27 10:54:52,772] Trial 26 finished with value: 0.7598312055979916 and parameters: {'kernel': 'linear', 'C': 0.3432789379810474, 'gamma': 5359.122753215755, 'tol': 0.0017306993385427522, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:53,012] Trial 27 finished with value: 0.47205277495860265 and parameters: {'kernel': 'linear', 'C': 0.0029378888810812067, 'gamma': 9127.259707150903, 'tol': 0.0016610072653122064, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:53,754] Trial 28 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.3470158090383029, 'gamma': 92498.27339808743, 'tol': 0.0006978878313633007, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:54,192] Trial 29 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.005316648743941293, 'gamma': 13535.730650089416, 'tol': 0.0012793147999777459, 'shrinking': True}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:54,924] Trial 30 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.1659027771692069, 'gamma': 726.3334239718309, 'tol': 0.0033291753305934304, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:55,159] Trial 31 finished with value: 0.7194540889909726 and parameters: {'kernel': 'linear', 'C': 0.02171028865374184, 'gamma': 171.00271429579234, 'tol': 0.0018636160246375101, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:55,499] Trial 32 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 1.3126687315085086, 'gamma': 2293.840651040525, 'tol': 0.0034550152311785976, 'shrinking': False}. Best is trial 26 with value: 0.7598312055979916.\n[I 2024-02-27 10:54:55,778] Trial 33 finished with value: 0.7701832167085092 and parameters: {'kernel': 'linear', 'C': 0.11362563734275087, 'gamma': 3934.8407411845506, 'tol': 0.0018527128836302517, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:56,060] Trial 34 finished with value: 0.7608621334330431 and parameters: {'kernel': 'linear', 'C': 0.09126021930644235, 'gamma': 46131.299455053326, 'tol': 0.0010365444631243285, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:56,303] Trial 35 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0003895420602478077, 'gamma': 25243.59679436338, 'tol': 0.0011616451211056383, 'shrinking': True}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:56,602] Trial 36 finished with value: 0.7639762833181989 and parameters: {'kernel': 'linear', 'C': 0.07695003816430973, 'gamma': 94125.82461175026, 'tol': 0.00039236382766734884, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:56,842] Trial 37 finished with value: 0.7401687944020084 and parameters: {'kernel': 'linear', 'C': 0.034653906523109936, 'gamma': 44693.49737566425, 'tol': 0.000306026455592178, 'shrinking': True}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:57,248] Trial 38 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.01040099716011658, 'gamma': 6000.908471443176, 'tol': 0.0005119076453038564, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:57,509] Trial 39 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.00015535923617583392, 'gamma': 1.2340111323860058e-05, 'tol': 0.00011885669017014796, 'shrinking': True}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:58,237] Trial 40 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.10047847873442771, 'gamma': 4658.652790721223, 'tol': 0.0006647874876848682, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:58,621] Trial 41 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 2.8388909187233575, 'gamma': 79280.28642615676, 'tol': 0.0009500949130673665, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:58,931] Trial 42 finished with value: 0.7660327973933017 and parameters: {'kernel': 'linear', 'C': 0.15196492427823738, 'gamma': 23742.98213762345, 'tol': 0.002075547222611945, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:59,173] Trial 43 finished with value: 0.7598365471929919 and parameters: {'kernel': 'linear', 'C': 0.04888540710811916, 'gamma': 30318.418656837297, 'tol': 0.0021514540847209686, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:59,419] Trial 44 finished with value: 0.42133433043106666 and parameters: {'kernel': 'linear', 'C': 0.001963825513350222, 'gamma': 23359.475490735185, 'tol': 0.002125505958544735, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:54:59,802] Trial 45 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.056174117542942874, 'gamma': 95768.74873873017, 'tol': 0.0003155153914691895, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:00,040] Trial 46 finished with value: 0.6739116500186956 and parameters: {'kernel': 'linear', 'C': 0.013799375477940523, 'gamma': 24337.689348340573, 'tol': 0.00048654210350802265, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:00,352] Trial 47 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 3.4663130001393574, 'gamma': 3421.7124857782755, 'tol': 0.0008377711336451734, 'shrinking': True}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:00,647] Trial 48 finished with value: 0.7701778751135089 and parameters: {'kernel': 'linear', 'C': 0.1266106539923517, 'gamma': 18601.935754583836, 'tol': 0.001123469513569072, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:00,950] Trial 49 finished with value: 0.7681106778484056 and parameters: {'kernel': 'linear', 'C': 0.1435413967686603, 'gamma': 18812.945633494463, 'tol': 0.0011097870114810252, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:01,340] Trial 50 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.19283360741898223, 'gamma': 13420.89667653494, 'tol': 0.00018509209669319854, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:01,617] Trial 51 finished with value: 0.7649965279632498 and parameters: {'kernel': 'linear', 'C': 0.0982646476601964, 'gamma': 52809.68202616763, 'tol': 0.0012840772152260356, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:01,863] Trial 52 finished with value: 0.5952139308797607 and parameters: {'kernel': 'linear', 'C': 0.007806072438793884, 'gamma': 12539.265841137936, 'tol': 0.0014034171233734568, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:02,239] Trial 53 finished with value: 0.7474013140323701 and parameters: {'kernel': 'linear', 'C': 1.134683102851659, 'gamma': 2626.7591047056303, 'tol': 0.0011207898114804905, 'shrinking': False}. Best is trial 33 with value: 0.7701832167085092.\n[I 2024-02-27 10:55:02,567] Trial 54 finished with value: 0.7722504139736126 and parameters: {'kernel': 'linear', 'C': 0.16182191888126635, 'gamma': 475.5395388146218, 'tol': 0.0006360077833867805, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:02,807] Trial 55 finished with value: 0.7235938251161796 and parameters: {'kernel': 'linear', 'C': 0.024886283660757392, 'gamma': 379.60831695539565, 'tol': 0.002767374389175138, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:03,145] Trial 56 finished with value: 0.7629239891031462 and parameters: {'kernel': 'linear', 'C': 0.24192295213170376, 'gamma': 0.24777234224407446, 'tol': 0.0008738934988299142, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:03,464] Trial 57 finished with value: 0.6977191389348858 and parameters: {'kernel': 'rbf', 'C': 4.277014758312221, 'gamma': 0.0019853688350007794, 'tol': 0.0005975018697455419, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:03,835] Trial 58 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 35.0637763014071, 'gamma': 585.7900922002024, 'tol': 0.0014061492839595206, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:04,195] Trial 59 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 77724.16111187468, 'gamma': 156.28200064983892, 'tol': 0.002022515630677426, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:04,587] Trial 60 finished with value: 0.7474013140323701 and parameters: {'kernel': 'linear', 'C': 0.9223406356905024, 'gamma': 7898.208585936672, 'tol': 0.0008168008457584055, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:04,924] Trial 61 finished with value: 0.7712141445435607 and parameters: {'kernel': 'linear', 'C': 0.15985851420158678, 'gamma': 52025.39545693337, 'tol': 0.00043733509487674276, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:05,248] Trial 62 finished with value: 0.7681106778484056 and parameters: {'kernel': 'linear', 'C': 0.1429647900326733, 'gamma': 17547.997097113894, 'tol': 0.00042114568895810925, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:05,587] Trial 63 finished with value: 0.7681053362534053 and parameters: {'kernel': 'linear', 'C': 0.14933687528893685, 'gamma': 17077.242223930505, 'tol': 0.0002690868791927622, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:06,038] Trial 64 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 1.518625991723661, 'gamma': 3061.411286031594, 'tol': 0.000266304492456689, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:06,448] Trial 65 finished with value: 0.7494738528924737 and parameters: {'kernel': 'linear', 'C': 0.5754816574932009, 'gamma': 1227.3539050942484, 'tol': 0.0004161660016955678, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:06,694] Trial 66 finished with value: 0.7194540889909726 and parameters: {'kernel': 'linear', 'C': 0.023063059168357613, 'gamma': 12294.751143812791, 'tol': 0.00026257884479345857, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:06,934] Trial 67 finished with value: 0.48653918059932694 and parameters: {'kernel': 'linear', 'C': 0.0038691733867737836, 'gamma': 2021.732355342437, 'tol': 0.0006045781125923772, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:07,176] Trial 68 finished with value: 0.41097163613054855 and parameters: {'kernel': 'linear', 'C': 0.0014321628356071747, 'gamma': 5333.788856277937, 'tol': 0.0002088264627789452, 'shrinking': True}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:07,916] Trial 69 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.21011169423150994, 'gamma': 37296.70813563718, 'tol': 0.0004668834606525942, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:08,299] Trial 70 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.04254741336506471, 'gamma': 15818.326641774216, 'tol': 0.00035604035381666977, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:08,601] Trial 71 finished with value: 0.7712141445435607 and parameters: {'kernel': 'linear', 'C': 0.10964965518602615, 'gamma': 7993.7559708920235, 'tol': 0.0005665991898980128, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:09,008] Trial 72 finished with value: 0.7505101223225255 and parameters: {'kernel': 'linear', 'C': 0.43822394896807076, 'gamma': 6673.983235786146, 'tol': 0.0005803404726760022, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:09,243] Trial 73 finished with value: 0.6635542973131777 and parameters: {'kernel': 'linear', 'C': 0.012730725969472488, 'gamma': 761.1007034541399, 'tol': 0.00044161594996873407, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:09,570] Trial 74 finished with value: 0.7701832167085092 and parameters: {'kernel': 'linear', 'C': 0.13786977294917357, 'gamma': 1680.5436686164708, 'tol': 0.0003747499881513809, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:09,963] Trial 75 finished with value: 0.7474013140323701 and parameters: {'kernel': 'linear', 'C': 0.8071362203960919, 'gamma': 22.06534957053945, 'tol': 0.0006809907433817888, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:10,374] Trial 76 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 7.41346171928379, 'gamma': 147.47778004994032, 'tol': 0.0005277001192155746, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:10,661] Trial 77 finished with value: 0.7701885583035095 and parameters: {'kernel': 'linear', 'C': 0.06943300099416323, 'gamma': 1832.4345445806778, 'tol': 0.00039161442120429153, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:11,051] Trial 78 finished with value: 0.7619037444580952 and parameters: {'kernel': 'linear', 'C': 0.32541231662726633, 'gamma': 1636.3479777009989, 'tol': 0.0003650071797400522, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:11,297] Trial 79 finished with value: 0.7670850916083543 and parameters: {'kernel': 'linear', 'C': 0.061593902958412036, 'gamma': 321.97457744314374, 'tol': 0.0007665410463113895, 'shrinking': True}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:11,682] Trial 80 finished with value: 0.7484375834624218 and parameters: {'kernel': 'linear', 'C': 1.792945312582463, 'gamma': 3393.989123176415, 'tol': 0.0010866631681742467, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:11,936] Trial 81 finished with value: 0.7339511778216975 and parameters: {'kernel': 'linear', 'C': 0.03037094700877336, 'gamma': 7696.834093767444, 'tol': 0.0003141250312439812, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:12,291] Trial 82 finished with value: 0.7701832167085092 and parameters: {'kernel': 'linear', 'C': 0.11826949056459618, 'gamma': 54414.867064860235, 'tol': 0.00037024744081728223, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:12,600] Trial 83 finished with value: 0.7670850916083543 and parameters: {'kernel': 'linear', 'C': 0.0807732113874919, 'gamma': 770.2540007640486, 'tol': 0.00022990409920155158, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:12,845] Trial 84 finished with value: 0.6925377917846269 and parameters: {'kernel': 'linear', 'C': 0.01758986908323432, 'gamma': 55374.69850676839, 'tol': 0.00036814432813931356, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:13,091] Trial 85 finished with value: 0.5434645585171732 and parameters: {'kernel': 'linear', 'C': 0.005859168069909209, 'gamma': 32424.313030241174, 'tol': 0.0005190594613395892, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:13,457] Trial 86 finished with value: 0.7650018695582501 and parameters: {'kernel': 'linear', 'C': 0.28651680982539834, 'gamma': 3.4421485672464542, 'tol': 0.0005558821930641733, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:14,184] Trial 87 finished with value: 0.41097163613054855 and parameters: {'kernel': 'rbf', 'C': 0.041721300620487005, 'gamma': 71.70661374610046, 'tol': 0.0009864586416238406, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:14,562] Trial 88 finished with value: 0.6252497195662625 and parameters: {'kernel': 'poly', 'C': 0.13046455047299535, 'gamma': 61215.5447546715, 'tol': 0.0006472635354713641, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:14,968] Trial 89 finished with value: 0.7474013140323701 and parameters: {'kernel': 'linear', 'C': 0.6898841915958164, 'gamma': 4714.284831547733, 'tol': 0.00045730142574670695, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:15,249] Trial 90 finished with value: 0.7701885583035095 and parameters: {'kernel': 'linear', 'C': 0.06887127810312305, 'gamma': 1703.0281815198093, 'tol': 0.0007399282105470431, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:15,529] Trial 91 finished with value: 0.7660488221783025 and parameters: {'kernel': 'linear', 'C': 0.08044567919215015, 'gamma': 2252.2871383586053, 'tol': 0.0007004098730357256, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:15,874] Trial 92 finished with value: 0.7618877196730944 and parameters: {'kernel': 'linear', 'C': 0.25639267907198154, 'gamma': 508.14826356310505, 'tol': 0.0007729153943162548, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:16,137] Trial 93 finished with value: 0.7401741359970087 and parameters: {'kernel': 'linear', 'C': 0.03881858365597664, 'gamma': 11210.811261323084, 'tol': 0.00033570209107490446, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:16,374] Trial 94 finished with value: 0.6055712835852786 and parameters: {'kernel': 'linear', 'C': 0.008331871523387682, 'gamma': 1365.002499120504, 'tol': 0.0009207886121527884, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:16,650] Trial 95 finished with value: 0.7691469472784573 and parameters: {'kernel': 'linear', 'C': 0.10569712626142215, 'gamma': 231.34614269447545, 'tol': 0.0014528107905280088, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:16,939] Trial 96 finished with value: 0.7505154639175258 and parameters: {'kernel': 'linear', 'C': 0.4207669094987808, 'gamma': 227.91300477964404, 'tol': 0.001816832432503518, 'shrinking': True}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:17,165] Trial 97 finished with value: 0.6935740612146787 and parameters: {'kernel': 'linear', 'C': 0.01752726412315324, 'gamma': 3540.0090399280616, 'tol': 0.0014745830428787667, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:17,442] Trial 98 finished with value: 0.7681213610384061 and parameters: {'kernel': 'linear', 'C': 0.060499249839822376, 'gamma': 991.8247463204159, 'tol': 0.0005013720536978966, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n[I 2024-02-27 10:55:17,706] Trial 99 finished with value: 0.761898402863095 and parameters: {'kernel': 'linear', 'C': 0.0910466176509315, 'gamma': 7971.279296788873, 'tol': 0.002547898581681187, 'shrinking': False}. Best is trial 54 with value: 0.7722504139736126.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'kernel': 'linear', 'C': 0.16182191888126635, 'gamma': 475.5395388146218, 'tol': 0.0006360077833867805, 'shrinking': False}\naccuracy: 0.8229813664596274\nrecall: 0.7335299507849526\nprecision: 0.8078215353338507\nf1-score: 0.7640179604177283\nroc_auc:  0.8491861267507675\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:17.822162Z","iopub.execute_input":"2024-02-27T10:55:17.822430Z","iopub.status.idle":"2024-02-27T10:55:17.833965Z","shell.execute_reply.started":"2024-02-27T10:55:17.822406Z","shell.execute_reply":"2024-02-27T10:55:17.832567Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"SVM - Modular PCA 16\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train_reduced, y_train)\ny_pred = dt.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:17.835466Z","iopub.execute_input":"2024-02-27T10:55:17.835720Z","iopub.status.idle":"2024-02-27T10:55:18.071404Z","shell.execute_reply.started":"2024-02-27T10:55:17.835699Z","shell.execute_reply":"2024-02-27T10:55:18.070238Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"accuracy: 0.3944099378881988\nrecall: 0.314480207783381\nprecision: 0.30454313049594356\nf1-score: 0.3073127255487607\nroc_auc:  0.6025150376344338\naccuracy: 0.782608695652174\nrecall: 0.6939846589840217\nprecision: 0.7458541698000827\nf1-score: 0.7089703542266247\nroc_auc:  0.8266748408088155\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 10),\n        \"min_samples_split\" : trial.suggest_int(\"min_samples_split\", 2, 20),\n        \"min_samples_leaf\" : trial.suggest_int(\"min_samples_leaf\", 1, 10),\n        \"criterion\" : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n        'random_state': trial.suggest_categorical('random_state', [42])\n\n    }\n\n    # Create KNN model with tuned hyperparameters\n    model = DecisionTreeClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:18.072647Z","iopub.execute_input":"2024-02-27T10:55:18.073230Z","iopub.status.idle":"2024-02-27T10:55:18.080046Z","shell.execute_reply.started":"2024-02-27T10:55:18.073202Z","shell.execute_reply":"2024-02-27T10:55:18.078770Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = DecisionTreeClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['decison tree'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Decision Tree'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:18.083421Z","iopub.execute_input":"2024-02-27T10:55:18.083757Z","iopub.status.idle":"2024-02-27T10:55:48.496335Z","shell.execute_reply.started":"2024-02-27T10:55:18.083729Z","shell.execute_reply":"2024-02-27T10:55:48.495461Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:55:18,091] A new study created in memory with name: no-name-2964370a-f7f7-4d88-8dcb-6aa16f0f0e99\n[I 2024-02-27 10:55:18,890] Trial 0 finished with value: 0.3612627530580631 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 0 with value: 0.3612627530580631.\n[I 2024-02-27 10:55:19,075] Trial 1 finished with value: 0.4244217723412211 and parameters: {'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 1 with value: 0.4244217723412211.\n[I 2024-02-27 10:55:19,214] Trial 2 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 1 with value: 0.4244217723412211.\n[I 2024-02-27 10:55:19,901] Trial 3 finished with value: 0.3726830831686342 and parameters: {'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 1 with value: 0.4244217723412211.\n[I 2024-02-27 10:55:20,132] Trial 4 finished with value: 0.43686768869184334 and parameters: {'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:20,315] Trial 5 finished with value: 0.4233855029111693 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 10, 'criterion': 'gini', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:21,030] Trial 6 finished with value: 0.3685380054484269 and parameters: {'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'entropy', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:21,380] Trial 7 finished with value: 0.39236686074461835 and parameters: {'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:22,043] Trial 8 finished with value: 0.3747182308637359 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 10, 'criterion': 'entropy', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:22,384] Trial 9 finished with value: 0.39543827786977187 and parameters: {'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 4 with value: 0.43686768869184334.\n[I 2024-02-27 10:55:22,680] Trial 10 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.4379039581218952.\n[I 2024-02-27 10:55:22,976] Trial 11 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.4379039581218952.\n[I 2024-02-27 10:55:23,271] Trial 12 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 10 with value: 0.4379039581218952.\n[I 2024-02-27 10:55:23,570] Trial 13 finished with value: 0.43893488595694674 and parameters: {'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:23,905] Trial 14 finished with value: 0.4089258052454462 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:24,199] Trial 15 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:24,530] Trial 16 finished with value: 0.41099300251054965 and parameters: {'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:24,779] Trial 17 finished with value: 0.4368570055018429 and parameters: {'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:25,545] Trial 18 finished with value: 0.3664814913733241 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 1, 'criterion': 'entropy', 'random_state': 42}. Best is trial 13 with value: 0.43893488595694674.\n[I 2024-02-27 10:55:25,794] Trial 19 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:25,945] Trial 20 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:26,195] Trial 21 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:26,443] Trial 22 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:26,641] Trial 23 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:26,893] Trial 24 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:27,142] Trial 25 finished with value: 0.4368570055018429 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:27,561] Trial 26 finished with value: 0.395459644249773 and parameters: {'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:27,895] Trial 27 finished with value: 0.4068479247903424 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:28,042] Trial 28 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 6, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:28,605] Trial 29 finished with value: 0.3913359329095668 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:28,820] Trial 30 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:29,071] Trial 31 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:29,322] Trial 32 finished with value: 0.4399658137919983 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:29,524] Trial 33 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:29,672] Trial 34 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:29,924] Trial 35 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:30,256] Trial 36 finished with value: 0.40683724160034185 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:30,676] Trial 37 finished with value: 0.395459644249773 and parameters: {'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:30,977] Trial 38 finished with value: 0.43687303028684366 and parameters: {'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:31,125] Trial 39 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 9, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:31,649] Trial 40 finished with value: 0.39029966347951495 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:31,902] Trial 41 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:32,155] Trial 42 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:32,450] Trial 43 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:32,872] Trial 44 finished with value: 0.39442871641472144 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:33,074] Trial 45 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:33,371] Trial 46 finished with value: 0.43997115538699855 and parameters: {'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:33,574] Trial 47 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:33,827] Trial 48 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:34,123] Trial 49 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:34,371] Trial 50 finished with value: 0.4389295443619464 and parameters: {'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 8, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:34,628] Trial 51 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:34,927] Trial 52 finished with value: 0.4368783718818439 and parameters: {'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:35,131] Trial 53 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:35,383] Trial 54 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:35,680] Trial 55 finished with value: 0.4368783718818439 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:36,216] Trial 56 finished with value: 0.3913359329095668 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:36,420] Trial 57 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:36,777] Trial 58 finished with value: 0.3923294695796165 and parameters: {'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:37,028] Trial 59 finished with value: 0.4368570055018429 and parameters: {'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:37,325] Trial 60 finished with value: 0.4368783718818439 and parameters: {'max_depth': 5, 'min_samples_split': 11, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:37,578] Trial 61 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:37,831] Trial 62 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:38,035] Trial 63 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:38,434] Trial 64 finished with value: 0.3882057582394103 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:38,686] Trial 65 finished with value: 0.4399658137919983 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:38,995] Trial 66 finished with value: 0.43997115538699855 and parameters: {'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:39,714] Trial 67 finished with value: 0.3933657390096683 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:39,865] Trial 68 finished with value: 0.410960952940548 and parameters: {'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:40,069] Trial 69 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:40,321] Trial 70 finished with value: 0.4368570055018429 and parameters: {'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:40,574] Trial 71 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:40,829] Trial 72 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:41,033] Trial 73 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:41,289] Trial 74 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:41,589] Trial 75 finished with value: 0.43687303028684366 and parameters: {'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:41,842] Trial 76 finished with value: 0.4399658137919983 and parameters: {'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:42,383] Trial 77 finished with value: 0.3913359329095668 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:42,683] Trial 78 finished with value: 0.43893488595694674 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:42,886] Trial 79 finished with value: 0.4244217723412211 and parameters: {'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:43,185] Trial 80 finished with value: 0.43997115538699855 and parameters: {'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:43,439] Trial 81 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:43,694] Trial 82 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:43,950] Trial 83 finished with value: 0.4399658137919983 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:44,156] Trial 84 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:44,409] Trial 85 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:44,705] Trial 86 finished with value: 0.4379039581218952 and parameters: {'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:44,959] Trial 87 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:45,163] Trial 88 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:45,704] Trial 89 finished with value: 0.3913359329095668 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:46,002] Trial 90 finished with value: 0.4379146413118957 and parameters: {'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:46,260] Trial 91 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:46,514] Trial 92 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:46,772] Trial 93 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:46,977] Trial 94 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:47,230] Trial 95 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:47,527] Trial 96 finished with value: 0.4379146413118957 and parameters: {'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 3, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:47,960] Trial 97 finished with value: 0.3788900165589445 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:48,165] Trial 98 finished with value: 0.4254580417712729 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 1, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n[I 2024-02-27 10:55:48,419] Trial 99 finished with value: 0.4410020832220501 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}. Best is trial 19 with value: 0.4410020832220501.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini', 'random_state': 42}\naccuracy: 0.468944099378882\nrecall: 0.30104579447003305\nprecision: 0.4125416459587314\nf1-score: 0.3060073275372722\nroc_auc:  0.5961351834926575\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T10:55:48.497229Z","iopub.execute_input":"2024-02-27T10:55:48.497532Z","iopub.status.idle":"2024-02-27T10:55:48.507701Z","shell.execute_reply.started":"2024-02-27T10:55:48.497504Z","shell.execute_reply":"2024-02-27T10:55:48.507136Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Decision Tree - Modular PCA 16\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# KNN Classifier","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_reduced, y_train)\ny_pred = knn.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:48.508477Z","iopub.execute_input":"2024-02-27T10:55:48.509168Z","iopub.status.idle":"2024-02-27T10:55:48.546903Z","shell.execute_reply.started":"2024-02-27T10:55:48.509146Z","shell.execute_reply":"2024-02-27T10:55:48.546039Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"accuracy: 0.531055900621118\nrecall: 0.3588451556655966\nprecision: 0.4567792303672703\nf1-score: 0.35991664112025934\nroc_auc:  0.6321558634190158\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'n_neighbors': trial.suggest_int(\"n_neighbors\", 5, 100),\n        'weights' : trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n        'metric' : trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"]),\n        'algorithm':trial.suggest_categorical('algorithm',['auto', 'ball_tree', 'kd_tree', 'brute']),\n        'n_jobs': -1\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = KNeighborsClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:48.547916Z","iopub.execute_input":"2024-02-27T10:55:48.548161Z","iopub.status.idle":"2024-02-27T10:55:48.554141Z","shell.execute_reply.started":"2024-02-27T10:55:48.548140Z","shell.execute_reply":"2024-02-27T10:55:48.553344Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 200)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model =KNeighborsClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['KNN'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'K-Nearest Neighbors'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall, f1,precision, roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:55:48.555187Z","iopub.execute_input":"2024-02-27T10:55:48.556206Z","iopub.status.idle":"2024-02-27T10:56:19.376127Z","shell.execute_reply.started":"2024-02-27T10:55:48.556068Z","shell.execute_reply":"2024-02-27T10:56:19.375037Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:55:48,562] A new study created in memory with name: no-name-4252c9ca-9a83-47b9-9e62-902f19a214c1\n[I 2024-02-27 10:55:48,656] Trial 0 finished with value: 0.47720741413386036 and parameters: {'n_neighbors': 57, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 0 with value: 0.47720741413386036.\n[I 2024-02-27 10:55:48,837] Trial 1 finished with value: 0.47721809732386095 and parameters: {'n_neighbors': 68, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 1 with value: 0.47721809732386095.\n[I 2024-02-27 10:55:48,889] Trial 2 finished with value: 0.4772287805138614 and parameters: {'n_neighbors': 62, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 2 with value: 0.4772287805138614.\n[I 2024-02-27 10:55:48,915] Trial 3 finished with value: 0.5279792746113989 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:48,988] Trial 4 finished with value: 0.462721008493136 and parameters: {'n_neighbors': 87, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,151] Trial 5 finished with value: 0.515560066235778 and parameters: {'n_neighbors': 23, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,220] Trial 6 finished with value: 0.5114043053255701 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,250] Trial 7 finished with value: 0.5113936221355697 and parameters: {'n_neighbors': 27, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,280] Trial 8 finished with value: 0.5020565140751028 and parameters: {'n_neighbors': 33, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,356] Trial 9 finished with value: 0.462721008493136 and parameters: {'n_neighbors': 87, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 3 with value: 0.5279792746113989.\n[I 2024-02-27 10:55:49,511] Trial 10 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 10 with value: 0.5797339885689867.\n[I 2024-02-27 10:55:49,670] Trial 11 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5817905026440895.\n[I 2024-02-27 10:55:49,828] Trial 12 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5817905026440895.\n[I 2024-02-27 10:55:49,988] Trial 13 finished with value: 0.5144703808557235 and parameters: {'n_neighbors': 39, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5817905026440895.\n[I 2024-02-27 10:55:50,158] Trial 14 finished with value: 0.5041237113402062 and parameters: {'n_neighbors': 44, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 11 with value: 0.5817905026440895.\n[I 2024-02-27 10:55:50,318] Trial 15 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:50,482] Trial 16 finished with value: 0.43581005288179053 and parameters: {'n_neighbors': 99, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:50,641] Trial 17 finished with value: 0.5558891084877945 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:50,847] Trial 18 finished with value: 0.49480262806474007 and parameters: {'n_neighbors': 49, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:51,013] Trial 19 finished with value: 0.5227765610811389 and parameters: {'n_neighbors': 33, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:51,197] Trial 20 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:51,355] Trial 21 finished with value: 0.5745633246087282 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 15 with value: 0.5921799049196089.\n[I 2024-02-27 10:55:51,513] Trial 22 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:51,674] Trial 23 finished with value: 0.5300197639015011 and parameters: {'n_neighbors': 24, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:51,845] Trial 24 finished with value: 0.5672934138133647 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,000] Trial 25 finished with value: 0.5331178890016559 and parameters: {'n_neighbors': 30, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,205] Trial 26 finished with value: 0.5413920196570696 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,368] Trial 27 finished with value: 0.5144703808557235 and parameters: {'n_neighbors': 39, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,541] Trial 28 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,626] Trial 29 finished with value: 0.4751295336787565 and parameters: {'n_neighbors': 54, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,792] Trial 30 finished with value: 0.46996421131349814 and parameters: {'n_neighbors': 70, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:52,959] Trial 31 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,115] Trial 32 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,271] Trial 33 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,431] Trial 34 finished with value: 0.5372469419368624 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,599] Trial 35 finished with value: 0.5331499385716575 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,693] Trial 36 finished with value: 0.5403557502270179 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,739] Trial 37 finished with value: 0.4720420917686021 and parameters: {'n_neighbors': 71, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,944] Trial 38 finished with value: 0.5145237968057261 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:53,981] Trial 39 finished with value: 0.5113936221355697 and parameters: {'n_neighbors': 27, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,150] Trial 40 finished with value: 0.5351744030767588 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,307] Trial 41 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,464] Trial 42 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,625] Trial 43 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,786] Trial 44 finished with value: 0.5569360611078469 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:54,829] Trial 45 finished with value: 0.5238288552961914 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,036] Trial 46 finished with value: 0.5724907857486246 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,199] Trial 47 finished with value: 0.5083008386304151 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,300] Trial 48 finished with value: 0.4761711447038085 and parameters: {'n_neighbors': 64, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,460] Trial 49 finished with value: 0.5444954863522248 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,626] Trial 50 finished with value: 0.4699695529084985 and parameters: {'n_neighbors': 75, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,789] Trial 51 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:55,951] Trial 52 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,112] Trial 53 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,275] Trial 54 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,432] Trial 55 finished with value: 0.5672934138133647 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,633] Trial 56 finished with value: 0.5289834944714492 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,727] Trial 57 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,819] Trial 58 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:56,908] Trial 59 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,014] Trial 60 finished with value: 0.4451151113722557 and parameters: {'n_neighbors': 83, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,106] Trial 61 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,196] Trial 62 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,288] Trial 63 finished with value: 0.5444954863522248 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,376] Trial 64 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,464] Trial 65 finished with value: 0.5569360611078469 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,551] Trial 66 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,776] Trial 67 finished with value: 0.4937823834196891 and parameters: {'n_neighbors': 38, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,817] Trial 68 finished with value: 0.5144970888307249 and parameters: {'n_neighbors': 24, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:57,916] Trial 69 finished with value: 0.501020244645051 and parameters: {'n_neighbors': 47, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,080] Trial 70 finished with value: 0.5672934138133647 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,239] Trial 71 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,412] Trial 72 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,574] Trial 73 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,737] Trial 74 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:58,925] Trial 75 finished with value: 0.43581005288179053 and parameters: {'n_neighbors': 99, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:59,089] Trial 76 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:59,272] Trial 77 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:59,446] Trial 78 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:55:59,965] Trial 79 finished with value: 0.5444954863522248 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:00,185] Trial 80 finished with value: 0.5062443245553123 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:00,389] Trial 81 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:00,582] Trial 82 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:00,805] Trial 83 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,014] Trial 84 finished with value: 0.5704022221035201 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,218] Trial 85 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,309] Trial 86 finished with value: 0.5455264141872764 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,476] Trial 87 finished with value: 0.5165429197158271 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,634] Trial 88 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,793] Trial 89 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:01,893] Trial 90 finished with value: 0.5372469419368624 and parameters: {'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,087] Trial 91 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,269] Trial 92 finished with value: 0.48134715025906727 and parameters: {'n_neighbors': 57, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,440] Trial 93 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,607] Trial 94 finished with value: 0.5704022221035201 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,796] Trial 95 finished with value: 0.5745633246087282 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:02,967] Trial 96 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,128] Trial 97 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,365] Trial 98 finished with value: 0.5413920196570696 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,534] Trial 99 finished with value: 0.4565140751028257 and parameters: {'n_neighbors': 94, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,621] Trial 100 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,797] Trial 101 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:03,975] Trial 102 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,147] Trial 103 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,320] Trial 104 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,413] Trial 105 finished with value: 0.5745633246087282 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,577] Trial 106 finished with value: 0.5290048608514503 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,752] Trial 107 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,908] Trial 108 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:04,996] Trial 109 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:05,160] Trial 110 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:05,337] Trial 111 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:05,501] Trial 112 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:05,668] Trial 113 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:05,840] Trial 114 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,027] Trial 115 finished with value: 0.5704022221035201 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,238] Trial 116 finished with value: 0.5724801025586241 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,331] Trial 117 finished with value: 0.5569360611078469 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,504] Trial 118 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,671] Trial 119 finished with value: 0.5269162972063459 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:06,830] Trial 120 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,015] Trial 121 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,189] Trial 122 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,357] Trial 123 finished with value: 0.5745633246087282 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,530] Trial 124 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,706] Trial 125 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,821] Trial 126 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:07,981] Trial 127 finished with value: 0.5279525666363977 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,095] Trial 128 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,264] Trial 129 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,429] Trial 130 finished with value: 0.5558891084877945 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,519] Trial 131 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,611] Trial 132 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,710] Trial 133 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,830] Trial 134 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:08,922] Trial 135 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,110] Trial 136 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,311] Trial 137 finished with value: 0.5589925751829498 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,412] Trial 138 finished with value: 0.5745633246087282 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,584] Trial 139 finished with value: 0.5041343945302067 and parameters: {'n_neighbors': 42, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,754] Trial 140 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:09,933] Trial 141 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,108] Trial 142 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,310] Trial 143 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,503] Trial 144 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,687] Trial 145 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,853] Trial 146 finished with value: 0.5248704663212436 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:10,951] Trial 147 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:11,154] Trial 148 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:11,330] Trial 149 finished with value: 0.4554724640777737 and parameters: {'n_neighbors': 75, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:11,502] Trial 150 finished with value: 0.5290048608514503 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:11,674] Trial 151 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:11,849] Trial 152 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,033] Trial 153 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,236] Trial 154 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,400] Trial 155 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,615] Trial 156 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,711] Trial 157 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,803] Trial 158 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:12,937] Trial 159 finished with value: 0.5725068105336254 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,033] Trial 160 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,125] Trial 161 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,220] Trial 162 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,310] Trial 163 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,483] Trial 164 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,674] Trial 165 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:13,840] Trial 166 finished with value: 0.5196570696009829 and parameters: {'n_neighbors': 35, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,048] Trial 167 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,142] Trial 168 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,308] Trial 169 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,476] Trial 170 finished with value: 0.5279525666363977 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,645] Trial 171 finished with value: 0.4927354307996367 and parameters: {'n_neighbors': 52, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,810] Trial 172 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:14,969] Trial 173 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,140] Trial 174 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,304] Trial 175 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,468] Trial 176 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,564] Trial 177 finished with value: 0.5714331499385716 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'brute'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,755] Trial 178 finished with value: 0.571438491533572 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:15,918] Trial 179 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,091] Trial 180 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,258] Trial 181 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,428] Trial 182 finished with value: 0.5817905026440895 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,597] Trial 183 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,762] Trial 184 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:16,930] Trial 185 finished with value: 0.5269430051813472 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'minkowski', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,100] Trial 186 finished with value: 0.4761658031088082 and parameters: {'n_neighbors': 62, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,258] Trial 187 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,470] Trial 188 finished with value: 0.5621387746381069 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,637] Trial 189 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,791] Trial 190 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:17,956] Trial 191 finished with value: 0.5921799049196089 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,125] Trial 192 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,296] Trial 193 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,449] Trial 194 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,610] Trial 195 finished with value: 0.5745472998237273 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,781] Trial 196 finished with value: 0.580759574809038 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:18,961] Trial 197 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:19,136] Trial 198 finished with value: 0.5983868383099193 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n[I 2024-02-27 10:56:19,298] Trial 199 finished with value: 0.5797339885689867 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}. Best is trial 22 with value: 0.5983868383099193.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_neighbors': 6, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree'}\naccuracy: 0.5962732919254659\nrecall: 0.41446409270418444\nprecision: 0.6313233949149443\nf1-score: 0.4373718385888771\nroc_auc:  0.66462556473289\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:19.377162Z","iopub.execute_input":"2024-02-27T10:56:19.377471Z","iopub.status.idle":"2024-02-27T10:56:19.390340Z","shell.execute_reply.started":"2024-02-27T10:56:19.377441Z","shell.execute_reply":"2024-02-27T10:56:19.389160Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"K-Nearest Neighbors - Modular PCA 16\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Gaussian NB","metadata":{}},{"cell_type":"markdown","source":"**Pre-tunning**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train_reduced, y_train)\n\ny_pred = gnb.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovr')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:19.391806Z","iopub.execute_input":"2024-02-27T10:56:19.392122Z","iopub.status.idle":"2024-02-27T10:56:19.410309Z","shell.execute_reply.started":"2024-02-27T10:56:19.392090Z","shell.execute_reply":"2024-02-27T10:56:19.409697Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"accuracy: 0.7204968944099379\nrecall: 0.5956020667757638\nprecision: 0.705407478306638\nf1-score: 0.6170065439688222\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    hyperparams = {\n        'var_smoothing': trial.suggest_float('var_smoothing', 1e-9, 1e-4, log = True)\n    }\n    \n    model = GaussianNB(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:19.411444Z","iopub.execute_input":"2024-02-27T10:56:19.412389Z","iopub.status.idle":"2024-02-27T10:56:19.417965Z","shell.execute_reply.started":"2024-02-27T10:56:19.412351Z","shell.execute_reply":"2024-02-27T10:56:19.416446Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = GaussianNB(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['gnb'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Gaussian Naives Bayes'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro, num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:19.419813Z","iopub.execute_input":"2024-02-27T10:56:19.420204Z","iopub.status.idle":"2024-02-27T10:56:21.440559Z","shell.execute_reply.started":"2024-02-27T10:56:19.420172Z","shell.execute_reply":"2024-02-27T10:56:21.439587Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:56:19,427] A new study created in memory with name: no-name-75b2ff91-3f1d-4a5a-929c-d94141fc6de8\n[I 2024-02-27 10:56:19,449] Trial 0 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 8.254460037458397e-06}. Best is trial 0 with value: 0.6345761444367288.\n[I 2024-02-27 10:56:19,465] Trial 1 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.9271558241026634e-07}. Best is trial 0 with value: 0.6345761444367288.\n[I 2024-02-27 10:56:19,482] Trial 2 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 8.534529708144e-06}. Best is trial 0 with value: 0.6345761444367288.\n[I 2024-02-27 10:56:19,499] Trial 3 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 4.219310581988156e-07}. Best is trial 0 with value: 0.6345761444367288.\n[I 2024-02-27 10:56:19,514] Trial 4 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 4.534595161140237e-09}. Best is trial 0 with value: 0.6345761444367288.\n[I 2024-02-27 10:56:19,530] Trial 5 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.206391670922358e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,545] Trial 6 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 6.514124254587446e-09}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,561] Trial 7 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.7325188500537668e-08}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,577] Trial 8 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 2.6357539044323137e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,592] Trial 9 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 5.7233939657487685e-08}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,612] Trial 10 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 6.67073263992071e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,631] Trial 11 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.4131320240338976e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,650] Trial 12 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.0135228752573205e-06}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,669] Trial 13 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 8.179447162065493e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,690] Trial 14 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 7.995642371894349e-06}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,710] Trial 15 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.5868327830333746e-06}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,732] Trial 16 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 2.5737668135680426e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,753] Trial 17 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.2518783113002014e-06}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,771] Trial 18 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.5449306382654117e-09}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,790] Trial 19 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 4.54487522890656e-07}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,809] Trial 20 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 1.947384091271058e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,828] Trial 21 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.2628862023408844e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,848] Trial 22 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 7.928478559916261e-05}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,869] Trial 23 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 4.49485626843325e-06}. Best is trial 5 with value: 0.6356124138667807.\n[I 2024-02-27 10:56:19,890] Trial 24 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.0625982659948102e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:19,909] Trial 25 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.4930710968648e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:19,929] Trial 26 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 8.570547201508129e-07}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:19,949] Trial 27 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.630372798184635e-07}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:19,968] Trial 28 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 4.135736384665117e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:19,989] Trial 29 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 9.313251336000564e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,009] Trial 30 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.4688713968456936e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,029] Trial 31 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 2.852878239246112e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,049] Trial 32 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 9.573622849007844e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,069] Trial 33 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.2552006809676301e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,089] Trial 34 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 5.50725350264702e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,111] Trial 35 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.0167257777092977e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,133] Trial 36 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.5827706219950882e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,155] Trial 37 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.322635014495661e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,175] Trial 38 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.4699065026947172e-07}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,195] Trial 39 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 3.909209891537625e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,215] Trial 40 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.5793243013078847e-08}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,234] Trial 41 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 5.8900533161022915e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,253] Trial 42 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 8.253064655176877e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,272] Trial 43 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.8797152404820765e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,292] Trial 44 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.7127307781621828e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,311] Trial 45 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 8.046980234159468e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,334] Trial 46 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.4129586936317425e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,355] Trial 47 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.0409950577311018e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,376] Trial 48 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.1697814811021918e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,395] Trial 49 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 3.0115248855950837e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,413] Trial 50 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 5.898112434411209e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,431] Trial 51 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.3764570137637115e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,450] Trial 52 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.118026988765778e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,473] Trial 53 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.1764915830123164e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,493] Trial 54 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.1907483727028453e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,512] Trial 55 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.1625355492701967e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,532] Trial 56 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.2030127258727084e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,554] Trial 57 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 1.9390433652475514e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,574] Trial 58 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 7.949200717820465e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,594] Trial 59 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.757391312739705e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,614] Trial 60 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 6.523740348959949e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,635] Trial 61 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.13398407689568e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,657] Trial 62 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.45398904368148e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,678] Trial 63 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 5.826407716900306e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,698] Trial 64 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.2147505255067098e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,719] Trial 65 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.4969547544947684e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,740] Trial 66 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.4708667313136546e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,759] Trial 67 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.1717024242543915e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,779] Trial 68 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.7500115992883606e-09}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,799] Trial 69 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 6.275331642125102e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,819] Trial 70 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.4982745814265692e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,838] Trial 71 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.4238585354151646e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,858] Trial 72 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.1221330557258e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,878] Trial 73 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.089961726352188e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,897] Trial 74 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.1011368999524699e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,920] Trial 75 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.012915324746014e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,942] Trial 76 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.4965551297771809e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,963] Trial 77 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 9.976629488314128e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:20,984] Trial 78 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 7.762125762272505e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,006] Trial 79 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 5.214379293031797e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,026] Trial 80 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 5.2762628370814045e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,047] Trial 81 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 2.5266186742334624e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,068] Trial 82 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.2604212347980365e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,088] Trial 83 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.0746054169602594e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,109] Trial 84 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.6361299837300582e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,130] Trial 85 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 4.294609415841292e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,151] Trial 86 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 5.979801389056024e-07}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,173] Trial 87 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 7.088426071119358e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,193] Trial 88 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 3.449376477583512e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,214] Trial 89 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 9.83212461393803e-09}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,234] Trial 90 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 9.976452578404566e-06}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,253] Trial 91 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 1.9210008393791153e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,275] Trial 92 finished with value: 0.6366486832968324 and parameters: {'var_smoothing': 2.239729626734251e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,295] Trial 93 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.326812228358094e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,314] Trial 94 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 2.4005431506928943e-07}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,334] Trial 95 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 2.8492679015182383e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,357] Trial 96 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 8.769104985109182e-08}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,377] Trial 97 finished with value: 0.6356124138667807 and parameters: {'var_smoothing': 3.793605568064541e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,399] Trial 98 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 1.8320744729581745e-05}. Best is trial 24 with value: 0.6366486832968324.\n[I 2024-02-27 10:56:21,421] Trial 99 finished with value: 0.6345761444367288 and parameters: {'var_smoothing': 9.891684863055038e-06}. Best is trial 24 with value: 0.6366486832968324.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'var_smoothing': 2.0625982659948102e-05}\naccuracy: 0.7236024844720497\nrecall: 0.5966761806318325\nprecision: 0.7079054471911614\nf1-score: 0.6187195855797879\nroc_auc:  0.7712813510187464\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:21.441558Z","iopub.execute_input":"2024-02-27T10:56:21.441825Z","iopub.status.idle":"2024-02-27T10:56:21.454559Z","shell.execute_reply.started":"2024-02-27T10:56:21.441802Z","shell.execute_reply":"2024-02-27T10:56:21.453546Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"Gaussian Naives Bayes - Modular PCA 16\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train_reduced, y_train)\ny_pred = lr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# # One-hot encoding for probability calculation (adapt if necessary)\n# y_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\n# y_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:21.455966Z","iopub.execute_input":"2024-02-27T10:56:21.456310Z","iopub.status.idle":"2024-02-27T10:56:21.545365Z","shell.execute_reply.started":"2024-02-27T10:56:21.456281Z","shell.execute_reply":"2024-02-27T10:56:21.544560Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"accuracy: 0.8322981366459627\nrecall: 0.7352863258495984\nprecision: 0.8044846360696838\nf1-score: 0.7601422759181673\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'saga']),\n        'penalty': trial.suggest_categorical('penalty', ['l2']),\n        'multi_class': trial.suggest_categorical('multi_class', ['ovr']),\n        'C': trial.suggest_loguniform(\"C\", 1e-3, 1e3),\n        'n_jobs': -1\n    }\n\n    model = LogisticRegression(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:21.546421Z","iopub.execute_input":"2024-02-27T10:56:21.547345Z","iopub.status.idle":"2024-02-27T10:56:21.553417Z","shell.execute_reply.started":"2024-02-27T10:56:21.547317Z","shell.execute_reply":"2024-02-27T10:56:21.552842Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = LogisticRegression(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['logistic regression'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Logistic Regression'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:56:21.554525Z","iopub.execute_input":"2024-02-27T10:56:21.555020Z","iopub.status.idle":"2024-02-27T10:59:01.346873Z","shell.execute_reply.started":"2024-02-27T10:56:21.554992Z","shell.execute_reply":"2024-02-27T10:59:01.346150Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:56:21,562] A new study created in memory with name: no-name-9352ae65-2f42-496e-9f7d-9377fc0efb1d\n[I 2024-02-27 10:56:23,151] Trial 0 finished with value: 0.7795042999839753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.35093824030717813}. Best is trial 0 with value: 0.7795042999839753.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[I 2024-02-27 10:56:24,395] Trial 1 finished with value: 0.7660434805833022 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 6.051307916650502}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:26,869] Trial 2 finished with value: 0.7743229528337162 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.9686312389946052}. Best is trial 0 with value: 0.7795042999839753.\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n[I 2024-02-27 10:56:27,250] Trial 3 finished with value: 0.7557021526627852 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 62.03121414793189}. Best is trial 0 with value: 0.7795042999839753.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:56:27,605] Trial 4 finished with value: 0.4192511083809626 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0010828374328389564}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:28,314] Trial 5 finished with value: 0.6594092195929705 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.011917085007855467}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:30,830] Trial 6 finished with value: 0.7732866834036644 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 34.22642717429529}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:31,401] Trial 7 finished with value: 0.744319213717216 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 674.8693220856463}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:31,559] Trial 8 finished with value: 0.5921318305646066 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.01285034443090863}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:32,633] Trial 9 finished with value: 0.733961861011698 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.05590845137775423}. Best is trial 0 with value: 0.7795042999839753.\n[I 2024-02-27 10:56:34,253] Trial 10 finished with value: 0.7795096415789755 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3907598872406662}. Best is trial 10 with value: 0.7795096415789755.\n[I 2024-02-27 10:56:35,635] Trial 11 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.206309983938512}. Best is trial 10 with value: 0.7795096415789755.\n[I 2024-02-27 10:56:37,369] Trial 12 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5450707128239214}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:39,466] Trial 13 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.4076763174730378}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:40,552] Trial 14 finished with value: 0.7391432081619571 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.06232511547526768}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:42,328] Trial 15 finished with value: 0.7836440361091823 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5901890790296943}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:45,521] Trial 16 finished with value: 0.7639816249131991 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 11.68609426537661}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:45,816] Trial 17 finished with value: 0.7743229528337162 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.89390420513796}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:48,304] Trial 18 finished with value: 0.7743229528337162 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 240.18997338448978}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:49,347] Trial 19 finished with value: 0.7298114416964905 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.05028867193182993}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:49,707] Trial 20 finished with value: 0.5455210725922761 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.0011180993434304462}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:51,702] Trial 21 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.123140231260574}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:53,824] Trial 22 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.5205824272818294}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:55,097] Trial 23 finished with value: 0.7639816249131991 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.14293417321918803}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:56:57,534] Trial 24 finished with value: 0.7784680305539234 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.755748764335701}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:00,803] Trial 25 finished with value: 0.7629453554831473 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 12.683220688651513}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:03,481] Trial 26 finished with value: 0.7743229528337162 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9721088701937907}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:03,867] Trial 27 finished with value: 0.6221622776561082 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.018077988425894854}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:04,102] Trial 28 finished with value: 0.7732973665936649 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4270255461670413}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:05,487] Trial 29 finished with value: 0.7733027081886652 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2066365386778881}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:09,390] Trial 30 finished with value: 0.7608728166230436 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 39.96005811665375}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:11,097] Trial 31 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.48389873641991793}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:12,867] Trial 32 finished with value: 0.7826077666791305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6354906793498316}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:15,557] Trial 33 finished with value: 0.7712141445435607 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 4.794719712213822}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:17,235] Trial 34 finished with value: 0.7826077666791305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.42872102294258135}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:18,530] Trial 35 finished with value: 0.7660488221783025 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.15039752124534272}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:19,036] Trial 36 finished with value: 0.7763901500988195 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.0073047756244455}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:21,537] Trial 37 finished with value: 0.7712141445435607 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 9.0192416813648}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:21,709] Trial 38 finished with value: 0.6625233694781263 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.02859921321346284}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:22,119] Trial 39 finished with value: 0.7391271833769564 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.09661016517281476}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:22,686] Trial 40 finished with value: 0.6128251695956413 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.004903355874142896}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:24,393] Trial 41 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.49998573769472976}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:26,159] Trial 42 finished with value: 0.7836440361091823 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5880420335122227}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:27,680] Trial 43 finished with value: 0.7774424443138722 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.2924649285288117}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:30,087] Trial 44 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.6961758237323976}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:31,823] Trial 45 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5472910769111969}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:34,070] Trial 46 finished with value: 0.7815714972490786 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.8982228612761038}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:35,701] Trial 47 finished with value: 0.7391271833769564 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.09619703884661039}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:35,938] Trial 48 finished with value: 0.7712301693285616 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.269379756915828}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:38,749] Trial 49 finished with value: 0.7681106778484056 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 6.1597631254959015}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:39,194] Trial 50 finished with value: 0.7743282944287164 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6597763775193148}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:40,953] Trial 51 finished with value: 0.7826077666791305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.553062183097996}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:43,105] Trial 52 finished with value: 0.7805298862240265 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.5992442998016356}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:45,029] Trial 53 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9342958576287919}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:46,584] Trial 54 finished with value: 0.7784733721489238 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3120580665001237}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:47,829] Trial 55 finished with value: 0.762940013888147 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.12493266133215693}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:48,903] Trial 56 finished with value: 0.7318786389615939 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.05145513634189875}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:50,690] Trial 57 finished with value: 0.7815714972490786 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6765237947144092}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:52,987] Trial 58 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 2.105789021704722}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:55,318] Trial 59 finished with value: 0.7660434805833022 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.20270714876459517}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:57:58,775] Trial 60 finished with value: 0.7629453554831473 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 21.166190191505216}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:00,531] Trial 61 finished with value: 0.7826077666791305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5607710695125024}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:02,408] Trial 62 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.900178705454144}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:04,053] Trial 63 finished with value: 0.7805459110090274 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.39708980389243853}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:06,110] Trial 64 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.288710942756333}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:07,236] Trial 65 finished with value: 0.7474119972223706 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.08088673319670955}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:07,448] Trial 66 finished with value: 0.7556861278777843 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.1622034949421697}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:10,103] Trial 67 finished with value: 0.7722504139736126 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 4.432649388650483}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:11,582] Trial 68 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.24201662929575238}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:13,354] Trial 69 finished with value: 0.7826077666791305 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.6450596999254153}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:13,833] Trial 70 finished with value: 0.744319213717216 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 306.352728508018}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:15,500] Trial 71 finished with value: 0.7805459110090274 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4116376761065396}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:17,516] Trial 72 finished with value: 0.7784626889589232 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.16606046782973}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:19,227] Trial 73 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.49780585601164634}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:21,683] Trial 74 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 3.0232504852667006}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:23,504] Trial 75 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7881193689855818}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:25,174] Trial 76 finished with value: 0.7805459110090274 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.4160476603524938}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:26,096] Trial 77 finished with value: 0.6718337695635916 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.03273191769931835}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:28,343] Trial 78 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.9545490272277544}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:28,598] Trial 79 finished with value: 0.7743336360237167 and parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.29786836543731104}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:30,650] Trial 80 finished with value: 0.7805352278190268 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.2867663125845092}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:32,356] Trial 81 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.496065607794997}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:33,696] Trial 82 finished with value: 0.77019924149351 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.175873555192768}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:35,410] Trial 83 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5055509364722677}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:37,118] Trial 84 finished with value: 0.783638694514182 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.46115030896173936}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:38,999] Trial 85 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.9024140325463575}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:40,217] Trial 86 finished with value: 0.7619037444580952 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.12121494405198081}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:41,728] Trial 87 finished with value: 0.7764115164788207 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.29298238966863616}. Best is trial 12 with value: 0.7846749639442339.\n/opt/conda/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n  warn(msg, LineSearchWarning)\n[I 2024-02-27 10:58:42,112] Trial 88 finished with value: 0.7608728166230436 and parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.18976486970913717}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:43,233] Trial 89 finished with value: 0.7474119972223706 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.07377527265430078}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:44,965] Trial 90 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5106707713179658}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:46,686] Trial 91 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5365823086377073}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:48,398] Trial 92 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.504764016734859}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:49,860] Trial 93 finished with value: 0.7743336360237167 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.24368623625448607}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:51,565] Trial 94 finished with value: 0.7846749639442339 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5058456462197736}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:53,164] Trial 95 finished with value: 0.7795042999839753 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.3540333327473338}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:55,296] Trial 96 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.5276731954057527}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:57,131] Trial 97 finished with value: 0.779498958388975 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.7910008920667683}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:58:59,653] Trial 98 finished with value: 0.7732920249986647 and parameters: {'solver': 'saga', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 1.097979827721791}. Best is trial 12 with value: 0.7846749639442339.\n[I 2024-02-27 10:59:00,876] Trial 99 finished with value: 0.7608728166230436 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.11429494366645787}. Best is trial 12 with value: 0.7846749639442339.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'solver': 'liblinear', 'penalty': 'l2', 'multi_class': 'ovr', 'C': 0.5450707128239214}\naccuracy: 0.8478260869565217\nrecall: 0.7593518703943071\nprecision: 0.8433552293823148\nf1-score: 0.7927757987515719\nroc_auc:  0.8645523590049715\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name} - Modular PCA {num_images}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:59:01.348273Z","iopub.execute_input":"2024-02-27T10:59:01.348819Z","iopub.status.idle":"2024-02-27T10:59:01.362340Z","shell.execute_reply.started":"2024-02-27T10:59:01.348791Z","shell.execute_reply":"2024-02-27T10:59:01.361704Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Logistic Regression - Modular PCA 16\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:59:01.365536Z","iopub.execute_input":"2024-02-27T10:59:01.367262Z","iopub.status.idle":"2024-02-27T10:59:01.371630Z","shell.execute_reply.started":"2024-02-27T10:59:01.367236Z","shell.execute_reply":"2024-02-27T10:59:01.371020Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestClassifier(random_state=42)\nrfr.fit(X_train_reduced,y_train)\ny_pred = rfr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:59:01.374597Z","iopub.execute_input":"2024-02-27T10:59:01.376223Z","iopub.status.idle":"2024-02-27T10:59:02.239386Z","shell.execute_reply.started":"2024-02-27T10:59:01.376192Z","shell.execute_reply":"2024-02-27T10:59:02.238504Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"accuracy: 0.5186335403726708\nrecall: 0.23940136863547082\nprecision: 0.5774555244519909\nf1-score: 0.23062191431756648\nroc_auc:  0.5840162757864565\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\n\n\ndef objective(trial):\n    hyperparams = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'max_depth': trial.suggest_int('max_depth', 10, 50),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n        'random_state': trial.suggest_categorical('random_state', [42]),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n        'n_jobs': -1\n    }\n\n    model = RandomForestClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:59:02.240537Z","iopub.execute_input":"2024-02-27T10:59:02.240854Z","iopub.status.idle":"2024-02-27T10:59:02.247126Z","shell.execute_reply.started":"2024-02-27T10:59:02.240828Z","shell.execute_reply":"2024-02-27T10:59:02.246186Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:59:02.248310Z","iopub.execute_input":"2024-02-27T10:59:02.248753Z","iopub.status.idle":"2024-02-27T11:10:28.104460Z","shell.execute_reply.started":"2024-02-27T10:59:02.248732Z","shell.execute_reply":"2024-02-27T11:10:28.103454Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stderr","text":"[I 2024-02-27 10:59:02,254] A new study created in memory with name: no-name-dbae7ae5-aec9-4818-87f7-343ca8dc3665\n[I 2024-02-27 10:59:07,120] Trial 0 finished with value: 0.44928689706746433 and parameters: {'n_estimators': 278, 'max_depth': 26, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.44928689706746433.\n[I 2024-02-27 10:59:19,861] Trial 1 finished with value: 0.447219699802361 and parameters: {'n_estimators': 709, 'max_depth': 27, 'min_samples_split': 31, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.44928689706746433.\n[I 2024-02-27 10:59:25,550] Trial 2 finished with value: 0.4554938304577747 and parameters: {'n_estimators': 312, 'max_depth': 30, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.4554938304577747.\n[I 2024-02-27 10:59:35,237] Trial 3 finished with value: 0.44514716094225737 and parameters: {'n_estimators': 553, 'max_depth': 22, 'min_samples_split': 28, 'random_state': 42, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.4554938304577747.\n[I 2024-02-27 10:59:49,652] Trial 4 finished with value: 0.451359435927568 and parameters: {'n_estimators': 810, 'max_depth': 30, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.4554938304577747.\n[I 2024-02-27 11:00:07,414] Trial 5 finished with value: 0.4617061054430853 and parameters: {'n_estimators': 917, 'max_depth': 44, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.4617061054430853.\n[I 2024-02-27 11:00:21,537] Trial 6 finished with value: 0.4244377971262218 and parameters: {'n_estimators': 883, 'max_depth': 17, 'min_samples_split': 20, 'random_state': 42, 'min_samples_leaf': 27}. Best is trial 5 with value: 0.4617061054430853.\n[I 2024-02-27 11:00:38,487] Trial 7 finished with value: 0.4461780887773089 and parameters: {'n_estimators': 909, 'max_depth': 35, 'min_samples_split': 32, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.4617061054430853.\n[I 2024-02-27 11:00:52,331] Trial 8 finished with value: 0.43997115538699855 and parameters: {'n_estimators': 824, 'max_depth': 42, 'min_samples_split': 31, 'random_state': 42, 'min_samples_leaf': 16}. Best is trial 5 with value: 0.4617061054430853.\n[I 2024-02-27 11:01:04,582] Trial 9 finished with value: 0.43375353880668766 and parameters: {'n_estimators': 743, 'max_depth': 44, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 18}. Best is trial 5 with value: 0.4617061054430853.\n[I 2024-02-27 11:01:14,427] Trial 10 finished with value: 0.4637679611131884 and parameters: {'n_estimators': 459, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.4637679611131884.\n[I 2024-02-27 11:01:24,591] Trial 11 finished with value: 0.4730890443886545 and parameters: {'n_estimators': 483, 'max_depth': 50, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:01:33,531] Trial 12 finished with value: 0.46067517760803367 and parameters: {'n_estimators': 443, 'max_depth': 50, 'min_samples_split': 14, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:01:41,895] Trial 13 finished with value: 0.42029271940601465 and parameters: {'n_estimators': 551, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 30}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:01:44,800] Trial 14 finished with value: 0.43169168313658457 and parameters: {'n_estimators': 177, 'max_depth': 38, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 23}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:01:53,389] Trial 15 finished with value: 0.45340526681267024 and parameters: {'n_estimators': 426, 'max_depth': 10, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:05,594] Trial 16 finished with value: 0.45549917205277496 and parameters: {'n_estimators': 657, 'max_depth': 37, 'min_samples_split': 18, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:12,814] Trial 17 finished with value: 0.43686768869184334 and parameters: {'n_estimators': 431, 'max_depth': 47, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 16}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:18,793] Trial 18 finished with value: 0.4575717109128786 and parameters: {'n_estimators': 325, 'max_depth': 40, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:20,901] Trial 19 finished with value: 0.42755194701137755 and parameters: {'n_estimators': 122, 'max_depth': 34, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 21}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:31,490] Trial 20 finished with value: 0.44306928048715344 and parameters: {'n_estimators': 614, 'max_depth': 46, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:02:40,767] Trial 21 finished with value: 0.4606698360130335 and parameters: {'n_estimators': 490, 'max_depth': 50, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:00,677] Trial 22 finished with value: 0.45860263874793017 and parameters: {'n_estimators': 999, 'max_depth': 45, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:08,276] Trial 23 finished with value: 0.4648042305432402 and parameters: {'n_estimators': 379, 'max_depth': 42, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:16,026] Trial 24 finished with value: 0.4617167886330858 and parameters: {'n_estimators': 382, 'max_depth': 41, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:20,528] Trial 25 finished with value: 0.4648362801132418 and parameters: {'n_estimators': 224, 'max_depth': 47, 'min_samples_split': 16, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:25,138] Trial 26 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 241, 'max_depth': 47, 'min_samples_split': 21, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:29,600] Trial 27 finished with value: 0.448261310827413 and parameters: {'n_estimators': 238, 'max_depth': 40, 'min_samples_split': 16, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:35,771] Trial 28 finished with value: 0.4503178249025159 and parameters: {'n_estimators': 345, 'max_depth': 34, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:37,919] Trial 29 finished with value: 0.447219699802361 and parameters: {'n_estimators': 118, 'max_depth': 47, 'min_samples_split': 16, 'random_state': 42, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:41,583] Trial 30 finished with value: 0.44514181934725705 and parameters: {'n_estimators': 204, 'max_depth': 43, 'min_samples_split': 24, 'random_state': 42, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:51,943] Trial 31 finished with value: 0.4617114470380856 and parameters: {'n_estimators': 519, 'max_depth': 48, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:03:59,969] Trial 32 finished with value: 0.465840499973292 and parameters: {'n_estimators': 393, 'max_depth': 50, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:06,961] Trial 33 finished with value: 0.4565300998878265 and parameters: {'n_estimators': 371, 'max_depth': 48, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:12,252] Trial 34 finished with value: 0.4534212915976711 and parameters: {'n_estimators': 268, 'max_depth': 45, 'min_samples_split': 18, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:17,759] Trial 35 finished with value: 0.4534212915976711 and parameters: {'n_estimators': 305, 'max_depth': 38, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:28,884] Trial 36 finished with value: 0.45964424977298224 and parameters: {'n_estimators': 579, 'max_depth': 43, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:36,460] Trial 37 finished with value: 0.4534212915976711 and parameters: {'n_estimators': 377, 'max_depth': 20, 'min_samples_split': 21, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:41,826] Trial 38 finished with value: 0.460680519203034 and parameters: {'n_estimators': 274, 'max_depth': 27, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:45,180] Trial 39 finished with value: 0.4523850221676192 and parameters: {'n_estimators': 184, 'max_depth': 31, 'min_samples_split': 26, 'random_state': 42, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:04:55,115] Trial 40 finished with value: 0.45549917205277496 and parameters: {'n_estimators': 499, 'max_depth': 48, 'min_samples_split': 19, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:04,292] Trial 41 finished with value: 0.4648042305432402 and parameters: {'n_estimators': 448, 'max_depth': 50, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:12,594] Trial 42 finished with value: 0.46584584156829234 and parameters: {'n_estimators': 403, 'max_depth': 45, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:20,460] Trial 43 finished with value: 0.45549917205277496 and parameters: {'n_estimators': 396, 'max_depth': 45, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:26,524] Trial 44 finished with value: 0.4544575610277229 and parameters: {'n_estimators': 317, 'max_depth': 42, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:36,491] Trial 45 finished with value: 0.46274237487313713 and parameters: {'n_estimators': 486, 'max_depth': 48, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:05:47,833] Trial 46 finished with value: 0.45446290262272315 and parameters: {'n_estimators': 593, 'max_depth': 43, 'min_samples_split': 15, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:01,536] Trial 47 finished with value: 0.459638908177982 and parameters: {'n_estimators': 665, 'max_depth': 45, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:07,721] Trial 48 finished with value: 0.4254740665562736 and parameters: {'n_estimators': 398, 'max_depth': 40, 'min_samples_split': 13, 'random_state': 42, 'min_samples_leaf': 28}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:17,846] Trial 49 finished with value: 0.4606751776080338 and parameters: {'n_estimators': 538, 'max_depth': 12, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:25,239] Trial 50 finished with value: 0.42650499439132517 and parameters: {'n_estimators': 467, 'max_depth': 49, 'min_samples_split': 11, 'random_state': 42, 'min_samples_leaf': 23}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:34,370] Trial 51 finished with value: 0.4617061054430853 and parameters: {'n_estimators': 440, 'max_depth': 50, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:41,629] Trial 52 finished with value: 0.4637679611131884 and parameters: {'n_estimators': 349, 'max_depth': 46, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:49,954] Trial 53 finished with value: 0.46170076384808506 and parameters: {'n_estimators': 405, 'max_depth': 50, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:06:59,036] Trial 54 finished with value: 0.4565300998878265 and parameters: {'n_estimators': 468, 'max_depth': 46, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:05,286] Trial 55 finished with value: 0.46687142780834356 and parameters: {'n_estimators': 305, 'max_depth': 49, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:09,817] Trial 56 finished with value: 0.46585652475829276 and parameters: {'n_estimators': 235, 'max_depth': 44, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:12,747] Trial 57 finished with value: 0.456519416697826 and parameters: {'n_estimators': 154, 'max_depth': 48, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:16,763] Trial 58 finished with value: 0.4327279525666364 and parameters: {'n_estimators': 240, 'max_depth': 44, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 18}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:22,483] Trial 59 finished with value: 0.4596442497729821 and parameters: {'n_estimators': 295, 'max_depth': 25, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:26,159] Trial 60 finished with value: 0.45446290262272315 and parameters: {'n_estimators': 201, 'max_depth': 36, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:33,039] Trial 61 finished with value: 0.4617061054430853 and parameters: {'n_estimators': 336, 'max_depth': 41, 'min_samples_split': 14, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:38,147] Trial 62 finished with value: 0.46066449441803325 and parameters: {'n_estimators': 263, 'max_depth': 46, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:42,418] Trial 63 finished with value: 0.4679290636183964 and parameters: {'n_estimators': 216, 'max_depth': 49, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:44,682] Trial 64 finished with value: 0.42132898883606645 and parameters: {'n_estimators': 145, 'max_depth': 49, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 32}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:48,992] Trial 65 finished with value: 0.4658511831632925 and parameters: {'n_estimators': 214, 'max_depth': 47, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:50,963] Trial 66 finished with value: 0.4544682442177234 and parameters: {'n_estimators': 102, 'max_depth': 49, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:54,080] Trial 67 finished with value: 0.46482025532824095 and parameters: {'n_estimators': 155, 'max_depth': 44, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:07:59,783] Trial 68 finished with value: 0.45653544148282676 and parameters: {'n_estimators': 289, 'max_depth': 47, 'min_samples_split': 12, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:04,312] Trial 69 finished with value: 0.46688211099834415 and parameters: {'n_estimators': 217, 'max_depth': 49, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:08,041] Trial 70 finished with value: 0.45860798034293043 and parameters: {'n_estimators': 202, 'max_depth': 46, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:12,804] Trial 71 finished with value: 0.4616954222530848 and parameters: {'n_estimators': 230, 'max_depth': 49, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:20,219] Trial 72 finished with value: 0.46584584156829223 and parameters: {'n_estimators': 353, 'max_depth': 50, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:25,403] Trial 73 finished with value: 0.46273703327813687 and parameters: {'n_estimators': 255, 'max_depth': 47, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:32,685] Trial 74 finished with value: 0.46583515837829176 and parameters: {'n_estimators': 353, 'max_depth': 48, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:36,157] Trial 75 finished with value: 0.4617114470380856 and parameters: {'n_estimators': 177, 'max_depth': 49, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:42,413] Trial 76 finished with value: 0.4637679611131884 and parameters: {'n_estimators': 306, 'max_depth': 45, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:46,541] Trial 77 finished with value: 0.4575717109128786 and parameters: {'n_estimators': 216, 'max_depth': 44, 'min_samples_split': 8, 'random_state': 42, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:53,348] Trial 78 finished with value: 0.4689546498584477 and parameters: {'n_estimators': 325, 'max_depth': 47, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:08:58,857] Trial 79 finished with value: 0.460680519203034 and parameters: {'n_estimators': 281, 'max_depth': 43, 'min_samples_split': 5, 'random_state': 42, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:06,955] Trial 80 finished with value: 0.45756102772287804 and parameters: {'n_estimators': 417, 'max_depth': 38, 'min_samples_split': 9, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:14,363] Trial 81 finished with value: 0.46584584156829223 and parameters: {'n_estimators': 355, 'max_depth': 47, 'min_samples_split': 7, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:20,748] Trial 82 finished with value: 0.4575717109128786 and parameters: {'n_estimators': 311, 'max_depth': 49, 'min_samples_split': 6, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:26,019] Trial 83 finished with value: 0.4637679611131884 and parameters: {'n_estimators': 253, 'max_depth': 50, 'min_samples_split': 10, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:29,738] Trial 84 finished with value: 0.4668714278083435 and parameters: {'n_estimators': 180, 'max_depth': 48, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:33,467] Trial 85 finished with value: 0.4668714278083435 and parameters: {'n_estimators': 182, 'max_depth': 46, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:36,915] Trial 86 finished with value: 0.4637679611131883 and parameters: {'n_estimators': 176, 'max_depth': 48, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:39,464] Trial 87 finished with value: 0.4679076972383954 and parameters: {'n_estimators': 122, 'max_depth': 32, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:41,922] Trial 88 finished with value: 0.44307996367715397 and parameters: {'n_estimators': 139, 'max_depth': 19, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:09:44,175] Trial 89 finished with value: 0.45446290262272315 and parameters: {'n_estimators': 117, 'max_depth': 33, 'min_samples_split': 4, 'random_state': 42, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:10:00,213] Trial 90 finished with value: 0.4627423748731371 and parameters: {'n_estimators': 787, 'max_depth': 15, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:10:04,162] Trial 91 finished with value: 0.46687142780834356 and parameters: {'n_estimators': 192, 'max_depth': 28, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:10:07,935] Trial 92 finished with value: 0.4679076972383953 and parameters: {'n_estimators': 183, 'max_depth': 28, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:10:11,511] Trial 93 finished with value: 0.46687142780834356 and parameters: {'n_estimators': 168, 'max_depth': 29, 'min_samples_split': 3, 'random_state': 42, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.4730890443886545.\n[I 2024-02-27 11:10:14,412] Trial 94 finished with value: 0.4751455584637572 and parameters: {'n_estimators': 131, 'max_depth': 29, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 94 with value: 0.4751455584637572.\n[I 2024-02-27 11:10:17,358] Trial 95 finished with value: 0.47823834196891185 and parameters: {'n_estimators': 135, 'max_depth': 27, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 95 with value: 0.47823834196891185.\n[I 2024-02-27 11:10:20,246] Trial 96 finished with value: 0.47617114470380856 and parameters: {'n_estimators': 133, 'max_depth': 26, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 95 with value: 0.47823834196891185.\n[I 2024-02-27 11:10:22,513] Trial 97 finished with value: 0.4824101276641205 and parameters: {'n_estimators': 101, 'max_depth': 23, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 97 with value: 0.4824101276641205.\n[I 2024-02-27 11:10:24,849] Trial 98 finished with value: 0.48033758880401684 and parameters: {'n_estimators': 105, 'max_depth': 24, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 97 with value: 0.4824101276641205.\n[I 2024-02-27 11:10:27,246] Trial 99 finished with value: 0.4761871694888093 and parameters: {'n_estimators': 109, 'max_depth': 25, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}. Best is trial 97 with value: 0.4824101276641205.\n","output_type":"stream"},{"name":"stdout","text":"Best params found : {'n_estimators': 101, 'max_depth': 23, 'min_samples_split': 2, 'random_state': 42, 'min_samples_leaf': 1}\n","output_type":"stream"},{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"0.515527950310559"},"metadata":{}}]},{"cell_type":"code","source":"final_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['random forest'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Random Forest'\nmodel_scores[model_name +str(num_images)] = [accuracy, recall,f1,precision,roc_auc_macro,num_images]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T11:10:28.105715Z","iopub.execute_input":"2024-02-27T11:10:28.106049Z","iopub.status.idle":"2024-02-27T11:10:29.011155Z","shell.execute_reply.started":"2024-02-27T11:10:28.106018Z","shell.execute_reply":"2024-02-27T11:10:29.010106Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"accuracy: 0.515527950310559\nrecall: 0.23698006112941755\nprecision: 0.5731265201229866\nf1-score: 0.2275163242554547\nroc_auc:  0.5600866428565954\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T11:10:29.012320Z","iopub.execute_input":"2024-02-27T11:10:29.012573Z","iopub.status.idle":"2024-02-27T11:10:29.023735Z","shell.execute_reply.started":"2024-02-27T11:10:29.012552Z","shell.execute_reply":"2024-02-27T11:10:29.022788Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"Random Forest\n\n==================================================\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.29      0.26      0.28        19\n     Colin Powell       0.46      0.53      0.49        59\n  Donald Rumsfeld       0.41      0.40      0.41        30\n    George W Bush       0.59      0.64      0.62       133\nGerhard Schroeder       0.16      0.11      0.13        27\n      Hugo Chavez       0.25      0.11      0.15        18\n       Tony Blair       0.36      0.39      0.37        36\n\n         accuracy                           0.47       322\n        macro avg       0.36      0.35      0.35       322\n     weighted avg       0.45      0.47      0.46       322\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# SUMMARY","metadata":{}},{"cell_type":"markdown","source":"**Classification over all models**","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame(model_scores, index=['Accuracy', 'Recall','F1 Score','Precision','ROC AUC','Number Images']).T\nresults_df.sort_values(by=['Accuracy','Number Images'],ascending = [False,True])","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-27T11:31:43.520498Z","iopub.execute_input":"2024-02-27T11:31:43.520799Z","iopub.status.idle":"2024-02-27T11:31:43.537066Z","shell.execute_reply.started":"2024-02-27T11:31:43.520777Z","shell.execute_reply":"2024-02-27T11:31:43.536290Z"},"trusted":true},"execution_count":149,"outputs":[{"execution_count":149,"output_type":"execute_result","data":{"text/plain":"                         Accuracy    Recall  F1 Score  Precision   ROC AUC  \\\nLogistic Regression9     0.847826  0.757637  0.791721   0.846453  0.863549   \nLogistic Regression16    0.847826  0.759352  0.792776   0.843355  0.864552   \nLogistic Regression4     0.841615  0.743063  0.777878   0.834166  0.855553   \nSVM9                     0.832298  0.747246  0.774115   0.817144  0.857068   \nSVM4                     0.822981  0.741386  0.766038   0.809885  0.853233   \nSVM16                    0.822981  0.733530  0.764018   0.807822  0.849186   \nGaussian Naives Bayes16  0.723602  0.596676  0.618720   0.707905  0.771281   \nGaussian Naives Bayes9   0.717391  0.586399  0.608715   0.719538  0.765493   \nGaussian Naives Bayes4   0.689441  0.573697  0.595562   0.668971  0.756986   \nK-Nearest Neighbors16    0.596273  0.414464  0.437372   0.631323  0.664626   \nK-Nearest Neighbors9     0.574534  0.396802  0.417246   0.531234  0.653722   \nK-Nearest Neighbors4     0.571429  0.395842  0.407248   0.532799  0.653538   \nRandom Forest16          0.515528  0.236980  0.227516   0.573127  0.560087   \nRandom Forest9           0.503106  0.213075  0.183358   0.207704  0.546069   \nRandom Forest4           0.496894  0.212120  0.188452   0.478334  0.545155   \nDecision Tree16          0.468944  0.301046  0.306007   0.412542  0.596135   \nDecision Tree9           0.416149  0.183000  0.137801   0.110687  0.526936   \nDecision Tree4           0.403727  0.185439  0.137601   0.109458  0.527707   \n\n                         Number Images  \nLogistic Regression9               9.0  \nLogistic Regression16             16.0  \nLogistic Regression4               4.0  \nSVM9                               9.0  \nSVM4                               4.0  \nSVM16                             16.0  \nGaussian Naives Bayes16           16.0  \nGaussian Naives Bayes9             9.0  \nGaussian Naives Bayes4             4.0  \nK-Nearest Neighbors16             16.0  \nK-Nearest Neighbors9               9.0  \nK-Nearest Neighbors4               4.0  \nRandom Forest16                   16.0  \nRandom Forest9                     9.0  \nRandom Forest4                     4.0  \nDecision Tree16                   16.0  \nDecision Tree9                     9.0  \nDecision Tree4                     4.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n      <th>Precision</th>\n      <th>ROC AUC</th>\n      <th>Number Images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression9</th>\n      <td>0.847826</td>\n      <td>0.757637</td>\n      <td>0.791721</td>\n      <td>0.846453</td>\n      <td>0.863549</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression16</th>\n      <td>0.847826</td>\n      <td>0.759352</td>\n      <td>0.792776</td>\n      <td>0.843355</td>\n      <td>0.864552</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression4</th>\n      <td>0.841615</td>\n      <td>0.743063</td>\n      <td>0.777878</td>\n      <td>0.834166</td>\n      <td>0.855553</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>SVM9</th>\n      <td>0.832298</td>\n      <td>0.747246</td>\n      <td>0.774115</td>\n      <td>0.817144</td>\n      <td>0.857068</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>SVM4</th>\n      <td>0.822981</td>\n      <td>0.741386</td>\n      <td>0.766038</td>\n      <td>0.809885</td>\n      <td>0.853233</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>SVM16</th>\n      <td>0.822981</td>\n      <td>0.733530</td>\n      <td>0.764018</td>\n      <td>0.807822</td>\n      <td>0.849186</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naives Bayes16</th>\n      <td>0.723602</td>\n      <td>0.596676</td>\n      <td>0.618720</td>\n      <td>0.707905</td>\n      <td>0.771281</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naives Bayes9</th>\n      <td>0.717391</td>\n      <td>0.586399</td>\n      <td>0.608715</td>\n      <td>0.719538</td>\n      <td>0.765493</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naives Bayes4</th>\n      <td>0.689441</td>\n      <td>0.573697</td>\n      <td>0.595562</td>\n      <td>0.668971</td>\n      <td>0.756986</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbors16</th>\n      <td>0.596273</td>\n      <td>0.414464</td>\n      <td>0.437372</td>\n      <td>0.631323</td>\n      <td>0.664626</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbors9</th>\n      <td>0.574534</td>\n      <td>0.396802</td>\n      <td>0.417246</td>\n      <td>0.531234</td>\n      <td>0.653722</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbors4</th>\n      <td>0.571429</td>\n      <td>0.395842</td>\n      <td>0.407248</td>\n      <td>0.532799</td>\n      <td>0.653538</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>Random Forest16</th>\n      <td>0.515528</td>\n      <td>0.236980</td>\n      <td>0.227516</td>\n      <td>0.573127</td>\n      <td>0.560087</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Random Forest9</th>\n      <td>0.503106</td>\n      <td>0.213075</td>\n      <td>0.183358</td>\n      <td>0.207704</td>\n      <td>0.546069</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>Random Forest4</th>\n      <td>0.496894</td>\n      <td>0.212120</td>\n      <td>0.188452</td>\n      <td>0.478334</td>\n      <td>0.545155</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>Decision Tree16</th>\n      <td>0.468944</td>\n      <td>0.301046</td>\n      <td>0.306007</td>\n      <td>0.412542</td>\n      <td>0.596135</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Decision Tree9</th>\n      <td>0.416149</td>\n      <td>0.183000</td>\n      <td>0.137801</td>\n      <td>0.110687</td>\n      <td>0.526936</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>Decision Tree4</th>\n      <td>0.403727</td>\n      <td>0.185439</td>\n      <td>0.137601</td>\n      <td>0.109458</td>\n      <td>0.527707</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Summary - Best ModularPCA works in each model**","metadata":{}},{"cell_type":"code","source":"import re\nfinal_results_df = results_df.sort_values(by=['Accuracy','Number Images'],ascending = [False,True]).iloc[::3]\n\nnew_index_name_df = [re.findall(r\"[^\\d]+\", idx)[0] for idx in final_results_df.index.tolist()]\nfinal_results_df.index = new_index_name\nfinal_results_df","metadata":{"execution":{"iopub.status.busy":"2024-02-27T11:44:19.345294Z","iopub.execute_input":"2024-02-27T11:44:19.347513Z","iopub.status.idle":"2024-02-27T11:44:19.363140Z","shell.execute_reply.started":"2024-02-27T11:44:19.347484Z","shell.execute_reply":"2024-02-27T11:44:19.361838Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"                       Accuracy    Recall  F1 Score  Precision   ROC AUC  \\\nLogistic Regression    0.847826  0.757637  0.791721   0.846453  0.863549   \nSVM                    0.832298  0.747246  0.774115   0.817144  0.857068   \nGaussian Naives Bayes  0.723602  0.596676  0.618720   0.707905  0.771281   \nK-Nearest Neighbors    0.596273  0.414464  0.437372   0.631323  0.664626   \nRandom Forest          0.515528  0.236980  0.227516   0.573127  0.560087   \nDecision Tree          0.468944  0.301046  0.306007   0.412542  0.596135   \n\n                       Number Images  \nLogistic Regression              9.0  \nSVM                              9.0  \nGaussian Naives Bayes           16.0  \nK-Nearest Neighbors             16.0  \nRandom Forest                   16.0  \nDecision Tree                   16.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n      <th>Precision</th>\n      <th>ROC AUC</th>\n      <th>Number Images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.847826</td>\n      <td>0.757637</td>\n      <td>0.791721</td>\n      <td>0.846453</td>\n      <td>0.863549</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>SVM</th>\n      <td>0.832298</td>\n      <td>0.747246</td>\n      <td>0.774115</td>\n      <td>0.817144</td>\n      <td>0.857068</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naives Bayes</th>\n      <td>0.723602</td>\n      <td>0.596676</td>\n      <td>0.618720</td>\n      <td>0.707905</td>\n      <td>0.771281</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbors</th>\n      <td>0.596273</td>\n      <td>0.414464</td>\n      <td>0.437372</td>\n      <td>0.631323</td>\n      <td>0.664626</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.515528</td>\n      <td>0.236980</td>\n      <td>0.227516</td>\n      <td>0.573127</td>\n      <td>0.560087</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>Decision Tree</th>\n      <td>0.468944</td>\n      <td>0.301046</td>\n      <td>0.306007</td>\n      <td>0.412542</td>\n      <td>0.596135</td>\n      <td>16.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"****\n## Visualization","metadata":{}},{"cell_type":"code","source":"plt.style.use('ggplot')\n# Data\nlabels = [(' '*10 +'Accuracy'), 'Recall', ('F1-score'+ ' ' * 10) , ('Precision'+ ' ' * 10), 'ROC AUC']\n\nsvm = final_results_df.loc['SVM',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\ndt = final_results_df.loc['Decision Tree',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\nknn = final_results_df.loc['K-Nearest Neighbors',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\ngnb = final_results_df.loc['Gaussian Naives Bayes',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\nlr = final_results_df.loc['Logistic Regression',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\nrf = final_results_df.loc['Random Forest',['Accuracy', 'Recall', 'F1 Score', 'Precision', 'ROC AUC']].tolist()\n\n# Number of variables we're plotting.\ncategories = labels\nN = len(categories)\n\n# What will be the angle of each axis in the plot?\nangles = np.linspace(0, 2*np.pi, len(labels), endpoint = False)\nangles = np.concatenate((angles, [angles[0]]))\n\n\n# Initialise the spider plot\nplt.figure(figsize=(8, 8))  # Increase the size of the radar\n\n# Draw one axe per variable + add labels yet\nplt.xticks(angles[:-1], categories, color='white')  # White labels\nplt.yticks([i/10 for i in range(11)], [\"{:.2f}\".format(i/10) for i in range(11)], color=\"white\", size=7)\nplt.ylim(0, 1)\n\n# Set gray background\nax = plt.subplot(111, polar=True, facecolor='#E6ECF5', alpha = 0.7)  \n\n# Plot each classifier's data\nfor data, label, color in zip([svm, dt, knn, gnb, lr, rf],\n                              [\"SVM (linear)\", \"Decision Trees\", \"K-Nearest Neighbor\",\n                               \"Gaussian Naive Bayes\", \"Logistic Regression\", \"Random Forest\"],\n                              ['#292AF4', '#A3B763', '#818181', 'orange', 'maroon', 'teal']):\n \n    ax.plot(angles, data + data[:1], 'o-', linewidth=1.5, label=label, color=color, alpha = 0.9)\n    ax.fill(angles, data + data[:1], alpha=0)  # Fill only the edges\n    \n# Modify grids\nlabels.append(labels[0])\nax.set_thetagrids(angles * 180/np.pi, labels, color = 'black')\nplt.grid(True)\n\n# Add labels for each coordinate system\n# for angle, lab in zip(angles, labels):\n# plt.annotate(labels[0], xy=(angles[0], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[1], xy=(angles[1], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[2], xy=(angles[2], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[3], xy=(angles[3], 1.1), color='white', fontsize=10, ha='center')\n\nplt.legend(loc='upper right', bbox_to_anchor=(1.3, 1))\nplt.title(\"Modular PCA - Models Evaluation\\n\", size = 24,color='navy', weight = 'bold')\nplt.grid(color='white', linestyle='-', alpha = 0.8)  # White grid lines\nplt.yticks([0,0.2, 0.4, 0.6, 0.8, 1.0], [\"0\",\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"],color=\"black\", size=10)  # Custom y-ticks\nplt.show()\n","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-02-27T11:49:04.168552Z","iopub.execute_input":"2024-02-27T11:49:04.168863Z","iopub.status.idle":"2024-02-27T11:49:04.581900Z","shell.execute_reply.started":"2024-02-27T11:49:04.168840Z","shell.execute_reply":"2024-02-27T11:49:04.580793Z"},"trusted":true},"execution_count":165,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# dump prediction results\nimport json\npredictions = {}\nfor k in prediction_results.keys():\n    predictions[k] = list(prediction_results[k])\n\n# with open(\"/kaggle/working/prediction_results.json\", \"w\") as json_file:\n#     json.dump(predictions, json_file)\n\npredictions","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-02-27T11:49:57.334963Z","iopub.execute_input":"2024-02-27T11:49:57.335259Z","iopub.status.idle":"2024-02-27T11:49:57.367709Z","shell.execute_reply.started":"2024-02-27T11:49:57.335236Z","shell.execute_reply":"2024-02-27T11:49:57.366900Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"{'svc': [1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  4,\n  5,\n  3,\n  3,\n  3,\n  5,\n  4,\n  3,\n  3,\n  4,\n  1,\n  4,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  2,\n  1,\n  1,\n  4,\n  2,\n  1,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  5,\n  6,\n  1,\n  2,\n  3,\n  3,\n  3,\n  0,\n  1,\n  1,\n  3,\n  0,\n  3,\n  0,\n  3,\n  3,\n  1,\n  4,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  6,\n  3,\n  1,\n  3,\n  1,\n  2,\n  3,\n  6,\n  6,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  1,\n  0,\n  4,\n  2,\n  1,\n  5,\n  3,\n  3,\n  2,\n  6,\n  3,\n  3,\n  1,\n  2,\n  3,\n  3,\n  3,\n  1,\n  3,\n  5,\n  4,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  1,\n  3,\n  3,\n  0,\n  1,\n  1,\n  3,\n  2,\n  2,\n  1,\n  3,\n  3,\n  3,\n  5,\n  6,\n  2,\n  2,\n  1,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  3,\n  3,\n  1,\n  2,\n  6,\n  3,\n  6,\n  3,\n  1,\n  1,\n  3,\n  1,\n  2,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  6,\n  6,\n  3,\n  3,\n  3,\n  3,\n  2,\n  6,\n  3,\n  3,\n  3,\n  4,\n  3,\n  2,\n  3,\n  1,\n  1,\n  3,\n  3,\n  0,\n  1,\n  3,\n  6,\n  2,\n  6,\n  3,\n  4,\n  3,\n  6,\n  0,\n  3,\n  0,\n  2,\n  3,\n  3,\n  4,\n  4,\n  1,\n  3,\n  2,\n  3,\n  1,\n  3,\n  4,\n  4,\n  1,\n  2,\n  3,\n  3,\n  3,\n  3,\n  0,\n  4,\n  4,\n  4,\n  3,\n  2,\n  3,\n  3,\n  5,\n  1,\n  5,\n  3,\n  3,\n  0,\n  6,\n  2,\n  1,\n  3,\n  3,\n  3,\n  5,\n  3,\n  3,\n  1,\n  3,\n  5,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  6,\n  4,\n  4,\n  1,\n  3,\n  2,\n  4,\n  3,\n  6,\n  3,\n  2,\n  2,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  0,\n  5,\n  3,\n  3,\n  2,\n  3,\n  2,\n  3,\n  6,\n  3,\n  3,\n  6,\n  3,\n  3,\n  3,\n  6,\n  3,\n  1,\n  1,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  0,\n  3,\n  1,\n  5,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  6,\n  6,\n  2,\n  3,\n  1,\n  0,\n  6,\n  3,\n  5,\n  3,\n  3,\n  3,\n  1,\n  3,\n  2,\n  4,\n  6,\n  6],\n 'decison tree': [3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  1,\n  3,\n  2,\n  0,\n  4,\n  0,\n  3,\n  3,\n  3,\n  3,\n  1,\n  2,\n  1,\n  1,\n  3,\n  3,\n  0,\n  2,\n  3,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  0,\n  3,\n  1,\n  3,\n  3,\n  0,\n  2,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  2,\n  0,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  6,\n  3,\n  4,\n  2,\n  3,\n  3,\n  3,\n  4,\n  2,\n  3,\n  3,\n  0,\n  1,\n  2,\n  3,\n  2,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  5,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  0,\n  3,\n  1,\n  3,\n  3,\n  2,\n  3,\n  2,\n  6,\n  3,\n  3,\n  3,\n  6,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  0,\n  3,\n  2,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  0,\n  3,\n  3,\n  3,\n  3,\n  3,\n  0,\n  3,\n  6,\n  4,\n  3,\n  3,\n  1,\n  3,\n  2,\n  3,\n  3,\n  4,\n  3,\n  2,\n  3,\n  2,\n  3,\n  1,\n  0,\n  3,\n  2,\n  0,\n  3,\n  3,\n  6,\n  2,\n  3,\n  3,\n  4,\n  2,\n  2,\n  0,\n  0,\n  3,\n  3,\n  3,\n  3,\n  4,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  2,\n  6,\n  2,\n  1,\n  3,\n  2,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  1,\n  2,\n  1,\n  3,\n  3,\n  4,\n  1,\n  3,\n  3,\n  4,\n  0,\n  3,\n  2,\n  1,\n  3,\n  3,\n  3,\n  4,\n  3,\n  3,\n  1,\n  3,\n  6,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  2,\n  3,\n  4,\n  5,\n  4,\n  2,\n  4,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  0,\n  3,\n  0,\n  0,\n  2,\n  4,\n  2,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  0,\n  2,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  2,\n  3,\n  2,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  2,\n  0,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  4,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  4,\n  3,\n  3],\n 'KNN': [1,\n  0,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  1,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  1,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  2,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  5,\n  6,\n  1,\n  2,\n  3,\n  3,\n  3,\n  1,\n  1,\n  1,\n  3,\n  5,\n  1,\n  2,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  1,\n  3,\n  3,\n  1,\n  3,\n  1,\n  2,\n  6,\n  3,\n  6,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  6,\n  3,\n  2,\n  1,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  5,\n  6,\n  6,\n  3,\n  3,\n  1,\n  2,\n  3,\n  1,\n  3,\n  3,\n  5,\n  3,\n  3,\n  3,\n  1,\n  2,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  2,\n  1,\n  3,\n  1,\n  3,\n  2,\n  2,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  6,\n  3,\n  3,\n  3,\n  1,\n  2,\n  6,\n  3,\n  3,\n  3,\n  3,\n  1,\n  0,\n  5,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  2,\n  6,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  2,\n  6,\n  3,\n  2,\n  1,\n  3,\n  3,\n  3,\n  0,\n  3,\n  3,\n  3,\n  3,\n  4,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  1,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  5,\n  1,\n  1,\n  5,\n  3,\n  0,\n  6,\n  2,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  3,\n  1,\n  3,\n  1,\n  1,\n  5,\n  3,\n  3,\n  2,\n  3,\n  4,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  0,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  6,\n  0,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  1,\n  5,\n  1,\n  2,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  5,\n  3,\n  3,\n  3,\n  0,\n  3,\n  3,\n  5,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  2,\n  3,\n  1],\n 'gnb': [1,\n  1,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  3,\n  2,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  2,\n  1,\n  1,\n  3,\n  2,\n  1,\n  2,\n  1,\n  5,\n  1,\n  1,\n  3,\n  2,\n  1,\n  1,\n  5,\n  5,\n  3,\n  1,\n  6,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  2,\n  3,\n  3,\n  1,\n  5,\n  3,\n  3,\n  1,\n  3,\n  5,\n  1,\n  6,\n  3,\n  1,\n  2,\n  1,\n  2,\n  5,\n  6,\n  2,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  1,\n  0,\n  4,\n  2,\n  1,\n  5,\n  2,\n  3,\n  2,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  4,\n  6,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  5,\n  3,\n  3,\n  3,\n  4,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  2,\n  3,\n  5,\n  2,\n  3,\n  3,\n  5,\n  3,\n  5,\n  6,\n  2,\n  2,\n  1,\n  3,\n  3,\n  1,\n  3,\n  6,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  6,\n  3,\n  6,\n  3,\n  1,\n  1,\n  5,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  6,\n  2,\n  3,\n  6,\n  6,\n  3,\n  1,\n  3,\n  3,\n  3,\n  4,\n  3,\n  2,\n  6,\n  1,\n  1,\n  3,\n  4,\n  3,\n  1,\n  3,\n  6,\n  2,\n  6,\n  3,\n  4,\n  4,\n  6,\n  0,\n  3,\n  4,\n  2,\n  3,\n  3,\n  4,\n  3,\n  1,\n  3,\n  2,\n  3,\n  6,\n  6,\n  6,\n  4,\n  1,\n  6,\n  3,\n  3,\n  3,\n  3,\n  0,\n  2,\n  1,\n  4,\n  2,\n  6,\n  2,\n  3,\n  5,\n  1,\n  3,\n  3,\n  2,\n  0,\n  6,\n  2,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  5,\n  3,\n  1,\n  3,\n  3,\n  3,\n  6,\n  3,\n  2,\n  6,\n  3,\n  4,\n  6,\n  6,\n  4,\n  4,\n  3,\n  6,\n  3,\n  2,\n  3,\n  3,\n  1,\n  3,\n  0,\n  1,\n  2,\n  3,\n  5,\n  3,\n  3,\n  2,\n  3,\n  1,\n  3,\n  2,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  2,\n  3,\n  1,\n  5,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  2,\n  1,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  2,\n  6,\n  6,\n  3],\n 'logistic regression': [1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  5,\n  3,\n  3,\n  3,\n  5,\n  4,\n  3,\n  3,\n  2,\n  1,\n  4,\n  1,\n  1,\n  1,\n  3,\n  3,\n  1,\n  1,\n  3,\n  2,\n  1,\n  2,\n  4,\n  0,\n  1,\n  1,\n  3,\n  3,\n  1,\n  6,\n  1,\n  5,\n  6,\n  3,\n  2,\n  3,\n  3,\n  3,\n  1,\n  1,\n  1,\n  3,\n  0,\n  1,\n  4,\n  3,\n  3,\n  1,\n  5,\n  3,\n  3,\n  1,\n  3,\n  0,\n  1,\n  6,\n  3,\n  1,\n  3,\n  1,\n  2,\n  3,\n  4,\n  6,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  1,\n  0,\n  4,\n  2,\n  1,\n  5,\n  3,\n  3,\n  2,\n  6,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  5,\n  3,\n  6,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  4,\n  3,\n  1,\n  3,\n  3,\n  0,\n  1,\n  1,\n  3,\n  2,\n  2,\n  3,\n  3,\n  3,\n  3,\n  5,\n  6,\n  2,\n  2,\n  1,\n  3,\n  3,\n  4,\n  3,\n  0,\n  1,\n  3,\n  3,\n  3,\n  1,\n  2,\n  6,\n  3,\n  6,\n  3,\n  1,\n  1,\n  3,\n  2,\n  3,\n  3,\n  4,\n  3,\n  6,\n  3,\n  3,\n  6,\n  4,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  1,\n  1,\n  3,\n  3,\n  0,\n  1,\n  3,\n  6,\n  2,\n  6,\n  4,\n  4,\n  4,\n  6,\n  0,\n  3,\n  2,\n  2,\n  3,\n  3,\n  4,\n  4,\n  1,\n  3,\n  2,\n  3,\n  6,\n  3,\n  4,\n  4,\n  1,\n  2,\n  3,\n  3,\n  4,\n  3,\n  0,\n  4,\n  4,\n  4,\n  3,\n  6,\n  3,\n  3,\n  5,\n  1,\n  3,\n  3,\n  3,\n  0,\n  6,\n  2,\n  1,\n  3,\n  3,\n  3,\n  5,\n  3,\n  3,\n  1,\n  3,\n  0,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  6,\n  4,\n  6,\n  1,\n  3,\n  4,\n  4,\n  3,\n  6,\n  3,\n  2,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  0,\n  5,\n  3,\n  3,\n  2,\n  3,\n  6,\n  3,\n  6,\n  1,\n  3,\n  6,\n  3,\n  3,\n  3,\n  6,\n  3,\n  1,\n  1,\n  1,\n  3,\n  3,\n  2,\n  3,\n  3,\n  1,\n  0,\n  3,\n  1,\n  5,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  6,\n  6,\n  2,\n  3,\n  1,\n  0,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  2,\n  4,\n  6,\n  6],\n 'random forest': [3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  0,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  1,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  6,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  2,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  2,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  6,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  1,\n  3,\n  3,\n  3,\n  3,\n  3]}"},"metadata":{}}]}]}