{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hnaw257/facerecognition-task3-tunning-pca?scriptVersionId=164415115\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.datasets import fetch_lfw_people \nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report, confusion_matrix \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-02-26T13:51:34.913909Z","iopub.execute_input":"2024-02-26T13:51:34.915139Z","iopub.status.idle":"2024-02-26T13:51:36.385451Z","shell.execute_reply.started":"2024-02-26T13:51:34.915094Z","shell.execute_reply":"2024-02-26T13:51:36.384015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lfw_people = fetch_lfw_people(min_faces_per_person = 70, funneled=False) \n  \nn_samples, h, w = lfw_people.images.shape \n  \nX = lfw_people.data \nn_features = X.shape[1] \n  \ny = lfw_people.target \ntarget_names = lfw_people.target_names \nn_classes = target_names.shape[0] \n  \n# Print Details about dataset \nprint(\"Number of Data Samples: % d\" % n_samples) \nprint(\"Size of a data sample: % d\" % n_features) \nprint(\"Number of Class Labels: % d\" % n_classes)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:36.38749Z","iopub.execute_input":"2024-02-26T13:51:36.388034Z","iopub.status.idle":"2024-02-26T13:51:49.897744Z","shell.execute_reply.started":"2024-02-26T13:51:36.387986Z","shell.execute_reply":"2024-02-26T13:51:49.896544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify=y) ","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:49.899582Z","iopub.execute_input":"2024-02-26T13:51:49.900275Z","iopub.status.idle":"2024-02-26T13:51:49.923497Z","shell.execute_reply.started":"2024-02-26T13:51:49.900209Z","shell.execute_reply":"2024-02-26T13:51:49.922047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_components = 150\n  \npca = PCA(n_components=n_components)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced = pca.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:49.929371Z","iopub.execute_input":"2024-02-26T13:51:49.929925Z","iopub.status.idle":"2024-02-26T13:51:50.341856Z","shell.execute_reply.started":"2024-02-26T13:51:49.929886Z","shell.execute_reply":"2024-02-26T13:51:50.339996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Euclidean","metadata":{}},{"cell_type":"code","source":"y_predict = []\nfor i in range(len(X_test_reduced)):\n    min_ = np.argmin(np.sqrt(np.sum((X_train_reduced - X_test_reduced[i])**2,axis=1)))\n    y_predict.append(y_train[min_])","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:50.34371Z","iopub.execute_input":"2024-02-26T13:51:50.348941Z","iopub.status.idle":"2024-02-26T13:51:50.509804Z","shell.execute_reply.started":"2024-02-26T13:51:50.348865Z","shell.execute_reply":"2024-02-26T13:51:50.508769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_predict, target_names = target_names)) ","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:50.511427Z","iopub.execute_input":"2024-02-26T13:51:50.511816Z","iopub.status.idle":"2024-02-26T13:51:50.530145Z","shell.execute_reply.started":"2024-02-26T13:51:50.511782Z","shell.execute_reply":"2024-02-26T13:51:50.528889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"**Set up dataframe for model results storage**","metadata":{}},{"cell_type":"code","source":"model_scores = {}\nprediction_results = {}","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-26T13:51:50.53375Z","iopub.execute_input":"2024-02-26T13:51:50.534137Z","iopub.status.idle":"2024-02-26T13:51:50.541246Z","shell.execute_reply.started":"2024-02-26T13:51:50.534105Z","shell.execute_reply":"2024-02-26T13:51:50.540099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*****","metadata":{}},{"cell_type":"markdown","source":"# PCA - TUNNING PROCESS","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:14:34.583441Z","iopub.execute_input":"2024-02-26T11:14:34.583816Z","iopub.status.idle":"2024-02-26T11:14:34.588812Z","shell.execute_reply.started":"2024-02-26T11:14:34.583789Z","shell.execute_reply":"2024-02-26T11:14:34.587532Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nn_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:51.258723Z","iopub.execute_input":"2024-02-26T13:51:51.259653Z","iopub.status.idle":"2024-02-26T13:51:51.269459Z","shell.execute_reply.started":"2024-02-26T13:51:51.259587Z","shell.execute_reply":"2024-02-26T13:51:51.266722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine ","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:51.270837Z","iopub.execute_input":"2024-02-26T13:51:51.271322Z","iopub.status.idle":"2024-02-26T13:51:51.484346Z","shell.execute_reply.started":"2024-02-26T13:51:51.271275Z","shell.execute_reply":"2024-02-26T13:51:51.482164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        # 'degree': trial.suggest_int('degree', 2, 5),  # for polynomial kernel\n        'tol': trial.suggest_loguniform('tol', 1e-4, 1e-2),\n        'shrinking': trial.suggest_categorical('shrinking', [True, False]),\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = SVC(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:51.485698Z","iopub.execute_input":"2024-02-26T13:51:51.486072Z","iopub.status.idle":"2024-02-26T13:51:53.149108Z","shell.execute_reply.started":"2024-02-26T13:51:51.486039Z","shell.execute_reply":"2024-02-26T13:51:53.147858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = SVC(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['svc'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'SVM'\nmodel_scores[model_name] = [accuracy,recall,f1,precision,roc_auc_macro]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:51:53.150735Z","iopub.execute_input":"2024-02-26T13:51:53.151071Z","iopub.status.idle":"2024-02-26T13:52:43.10402Z","shell.execute_reply.started":"2024-02-26T13:51:53.151043Z","shell.execute_reply":"2024-02-26T13:52:43.102779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:52:43.105425Z","iopub.execute_input":"2024-02-26T13:52:43.106442Z","iopub.status.idle":"2024-02-26T13:52:43.121203Z","shell.execute_reply.started":"2024-02-26T13:52:43.106407Z","shell.execute_reply":"2024-02-26T13:52:43.119893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train_reduced, y_train)\ny_pred = dt.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\nsvm = SVC(kernel='linear')\nsvm.fit(X_train_reduced, y_train)\ny_pred = svm.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\n# Assuming 'label_' prefix for clarity\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot,\n                              average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:52:43.122838Z","iopub.execute_input":"2024-02-26T13:52:43.123383Z","iopub.status.idle":"2024-02-26T13:52:43.506436Z","shell.execute_reply.started":"2024-02-26T13:52:43.123334Z","shell.execute_reply":"2024-02-26T13:52:43.50519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 10),\n        \"min_samples_split\" : trial.suggest_int(\"min_samples_split\", 2, 20),\n        \"min_samples_leaf\" : trial.suggest_int(\"min_samples_leaf\", 1, 10),\n        \"criterion\" : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n        'random_state': trial.suggest_categorical('random_state', [42])\n\n    }\n\n    # Create KNN model with tuned hyperparameters\n    model = DecisionTreeClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:52:43.508146Z","iopub.execute_input":"2024-02-26T13:52:43.508567Z","iopub.status.idle":"2024-02-26T13:52:43.516855Z","shell.execute_reply.started":"2024-02-26T13:52:43.508535Z","shell.execute_reply":"2024-02-26T13:52:43.5157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = DecisionTreeClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['decison tree'] = list(y_pred)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Decision Tree'\nmodel_scores[model_name] = [accuracy, recall,f1,precision,roc_auc_macro]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:52:43.51847Z","iopub.execute_input":"2024-02-26T13:52:43.518826Z","iopub.status.idle":"2024-02-26T13:53:27.685979Z","shell.execute_reply.started":"2024-02-26T13:52:43.518796Z","shell.execute_reply":"2024-02-26T13:53:27.685041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-26T13:53:27.687335Z","iopub.execute_input":"2024-02-26T13:53:27.688162Z","iopub.status.idle":"2024-02-26T13:53:27.702318Z","shell.execute_reply.started":"2024-02-26T13:53:27.688132Z","shell.execute_reply":"2024-02-26T13:53:27.7011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN Classifier","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_reduced, y_train)\ny_pred = knn.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:25:35.347446Z","iopub.execute_input":"2024-02-26T14:25:35.347898Z","iopub.status.idle":"2024-02-26T14:25:35.442939Z","shell.execute_reply.started":"2024-02-26T14:25:35.347866Z","shell.execute_reply":"2024-02-26T14:25:35.441479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef objective(trial):\n    hyperparams = {\n        'n_neighbors': trial.suggest_int(\"n_neighbors\", 5, 100),\n        'weights' : trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n        'metric' : trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"]),\n        'algorithm':trial.suggest_categorical('algorithm',['auto', 'ball_tree', 'kd_tree', 'brute']),\n        'n_jobs': -1\n    }\n    \n    # Create KNN model with tuned hyperparameters\n    model = KNeighborsClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:25:37.518202Z","iopub.execute_input":"2024-02-26T14:25:37.518701Z","iopub.status.idle":"2024-02-26T14:25:37.529196Z","shell.execute_reply.started":"2024-02-26T14:25:37.518665Z","shell.execute_reply":"2024-02-26T14:25:37.52733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 200)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model =KNeighborsClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['KNN'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'K-Nearest Neighbors'\nmodel_scores[model_name] = [accuracy, recall, f1,precision, roc_auc_macro]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:25:43.879682Z","iopub.execute_input":"2024-02-26T14:25:43.880116Z","iopub.status.idle":"2024-02-26T14:26:22.462329Z","shell.execute_reply.started":"2024-02-26T14:25:43.880085Z","shell.execute_reply":"2024-02-26T14:26:22.461174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:53:41.737843Z","iopub.execute_input":"2024-02-26T13:53:41.739191Z","iopub.status.idle":"2024-02-26T13:53:41.753656Z","shell.execute_reply.started":"2024-02-26T13:53:41.739145Z","shell.execute_reply":"2024-02-26T13:53:41.752771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Gaussian NB","metadata":{}},{"cell_type":"markdown","source":"**Pre-tunning**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train_reduced, y_train)\n\ny_pred = gnb.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovr')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:53:41.75481Z","iopub.execute_input":"2024-02-26T13:53:41.755859Z","iopub.status.idle":"2024-02-26T13:53:41.784768Z","shell.execute_reply.started":"2024-02-26T13:53:41.755827Z","shell.execute_reply":"2024-02-26T13:53:41.783715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    hyperparams = {\n        'var_smoothing': trial.suggest_float('var_smoothing', 1e-9, 1e-4, log = True)\n    }\n    \n    model = GaussianNB(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced, y_train, cv = kf,scoring = 'accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:53:41.786211Z","iopub.execute_input":"2024-02-26T13:53:41.786561Z","iopub.status.idle":"2024-02-26T13:53:41.792242Z","shell.execute_reply.started":"2024-02-26T13:53:41.786532Z","shell.execute_reply":"2024-02-26T13:53:41.791138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = GaussianNB(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['gnb'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Gaussian Naives Bayes'\nmodel_scores[model_name] = [accuracy, recall,f1,precision,roc_auc_macro]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:53:41.7938Z","iopub.execute_input":"2024-02-26T13:53:41.794201Z","iopub.status.idle":"2024-02-26T13:53:45.116815Z","shell.execute_reply.started":"2024-02-26T13:53:41.794173Z","shell.execute_reply":"2024-02-26T13:53:45.1156Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:53:45.118742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train_reduced, y_train)\ny_pred = lr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# # One-hot encoding for probability calculation (adapt if necessary)\n# y_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\n# y_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# # ROC AUC score with multiclass handling\n# roc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\n# print('roc_auc: ', roc_auc_macro)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef objective(trial):\n    hyperparams = {\n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'saga']),\n        'penalty': trial.suggest_categorical('penalty', ['l2']),\n        'multi_class': trial.suggest_categorical('multi_class', ['ovr']),\n        'C': trial.suggest_loguniform(\"C\", 1e-3, 1e3),\n        'n_jobs': -1\n    }\n\n    model = LogisticRegression(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = LogisticRegression(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['logistic regression'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Logistic Regression'\nmodel_scores[model_name] = [accuracy, recall,f1,precision,roc_auc_macro]","metadata":{"execution":{"iopub.status.idle":"2024-02-26T13:57:41.664585Z","shell.execute_reply.started":"2024-02-26T13:53:45.353453Z","shell.execute_reply":"2024-02-26T13:57:41.66325Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:57:41.666686Z","iopub.execute_input":"2024-02-26T13:57:41.667941Z","iopub.status.idle":"2024-02-26T13:57:41.692258Z","shell.execute_reply.started":"2024-02-26T13:57:41.667894Z","shell.execute_reply":"2024-02-26T13:57:41.691022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:57:41.694553Z","iopub.execute_input":"2024-02-26T13:57:41.695399Z","iopub.status.idle":"2024-02-26T13:57:41.793785Z","shell.execute_reply.started":"2024-02-26T13:57:41.695358Z","shell.execute_reply":"2024-02-26T13:57:41.792541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normal**","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestClassifier(random_state=42)\nrfr.fit(X_train_reduced,y_train)\ny_pred = rfr.predict(X_test_reduced)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n# One-hot encoding for probability calculation (adapt if necessary)\ny_test_onehot = pd.get_dummies(y_test, prefix='label_')  # Assuming 'label_' prefix for clarity\ny_pred_onehot = pd.get_dummies(y_pred, prefix='label_')\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')  # Specify 'ovo' or 'ovr'\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:57:41.795189Z","iopub.execute_input":"2024-02-26T13:57:41.795562Z","iopub.status.idle":"2024-02-26T13:57:42.983515Z","shell.execute_reply.started":"2024-02-26T13:57:41.795527Z","shell.execute_reply":"2024-02-26T13:57:42.982264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tunning**","metadata":{}},{"cell_type":"code","source":"import optuna\n\n\ndef objective(trial):\n    hyperparams = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'max_depth': trial.suggest_int('max_depth', 10, 50),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 32),\n        'random_state': trial.suggest_categorical('random_state', [42]),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 32),\n        'n_jobs': -1\n    }\n\n    model = RandomForestClassifier(**hyperparams)\n    scores = cross_val_score(model, X_train_reduced,\n                             y_train, cv=kf, scoring='accuracy')\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:57:42.984932Z","iopub.execute_input":"2024-02-26T13:57:42.985328Z","iopub.status.idle":"2024-02-26T13:57:42.993393Z","shell.execute_reply.started":"2024-02-26T13:57:42.985293Z","shell.execute_reply":"2024-02-26T13:57:42.992081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 100)\nbest_params = study.best_params\nprint(\"Best params found :\", best_params)\n\nfinal_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T13:57:42.995429Z","iopub.execute_input":"2024-02-26T13:57:42.995852Z","iopub.status.idle":"2024-02-26T14:11:36.557692Z","shell.execute_reply.started":"2024-02-26T13:57:42.995814Z","shell.execute_reply":"2024-02-26T14:11:36.556316Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_reduced, y_train)\ny_pred = final_model.predict(X_test_reduced)\nprediction_results['random forest'] = y_pred \n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\n\n# Fit a label binarizer to get all possible classes\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_test)\n\n# Transform y_test and y_pred to one-hot encoding with the same set of columns\ny_test_onehot = pd.DataFrame(label_binarizer.transform(\n    y_test), columns=label_binarizer.classes_)\ny_pred_onehot = pd.DataFrame(label_binarizer.transform(\n    y_pred), columns=label_binarizer.classes_)\n\n# Ensure both sets have the same columns\nall_columns = set(y_test_onehot.columns).union(set(y_pred_onehot.columns))\ny_test_onehot = y_test_onehot.reindex(columns=all_columns, fill_value=0)\ny_pred_onehot = y_pred_onehot.reindex(columns=all_columns, fill_value=0)\n\n# ROC AUC score with multiclass handling\nroc_auc_macro = roc_auc_score(\n    y_test_onehot, y_pred_onehot, average='macro', multi_class='ovo')\n\n\nprint(\"accuracy:\", accuracy)\nprint(\"recall:\", recall)\nprint(\"precision:\", precision)\nprint(\"f1-score:\", f1)\nprint('roc_auc: ', roc_auc_macro)\n\n# Save model result\nmodel_name = 'Random Forest'\nmodel_scores[model_name] = [accuracy, recall,f1,precision,roc_auc_macro]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:11:36.559589Z","iopub.execute_input":"2024-02-26T14:11:36.560025Z","iopub.status.idle":"2024-02-26T14:11:37.756142Z","shell.execute_reply.started":"2024-02-26T14:11:36.559988Z","shell.execute_reply":"2024-02-26T14:11:37.75487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{model_name}\\n')\nprint('=' * 50)\nprint(classification_report(y_test, y_predict, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:11:37.757605Z","iopub.execute_input":"2024-02-26T14:11:37.757965Z","iopub.status.idle":"2024-02-26T14:11:37.77348Z","shell.execute_reply.started":"2024-02-26T14:11:37.757935Z","shell.execute_reply":"2024-02-26T14:11:37.772554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# SUMMARY","metadata":{}},{"cell_type":"markdown","source":"**Classification over all models**","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame(model_scores, index=['Accuracy', 'Recall','F1 Score','Precision','ROC AUC']).T\nresults_df","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-26T14:26:46.417578Z","iopub.execute_input":"2024-02-26T14:26:46.418029Z","iopub.status.idle":"2024-02-26T14:26:46.434721Z","shell.execute_reply.started":"2024-02-26T14:26:46.417994Z","shell.execute_reply":"2024-02-26T14:26:46.433315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dump prediction results\n# import json\n# with open(\"/kaggle/working/predict.json\", \"w\") as json_file:\n#     json.dump(prediction_results, json_file)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2024-02-26T14:17:11.343186Z","iopub.execute_input":"2024-02-26T14:17:11.343691Z","iopub.status.idle":"2024-02-26T14:17:11.350067Z","shell.execute_reply.started":"2024-02-26T14:17:11.343658Z","shell.execute_reply":"2024-02-26T14:17:11.348735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n# Visualization","metadata":{}},{"cell_type":"code","source":"plt.style.use('ggplot')\n# Data\nlabels = [(' '*10 +'Accuracy'), 'Recall', ('F1-score'+ ' ' * 10) , ('Precision'+ ' ' * 10), 'ROC AUC']\nsvm = results_df.loc['SVM'].tolist()\ndt = results_df.loc['Decision Tree'].tolist()\nknn = results_df.loc['K-Nearest Neighbors'].tolist()\ngnb = results_df.loc['Gaussian Naives Bayes'].tolist()\nlr = results_df.loc['Logistic Regression'].tolist()\nrf = results_df.loc['Random Forest'].tolist()\n\n# Number of variables we're plotting.\ncategories = labels\nN = len(categories)\n\n# What will be the angle of each axis in the plot?\nangles = np.linspace(0, 2*np.pi, len(labels), endpoint = False)\nangles = np.concatenate((angles, [angles[0]]))\n\n\n# Initialise the spider plot\nplt.figure(figsize=(8, 8))  # Increase the size of the radar\n\n# Draw one axe per variable + add labels yet\nplt.xticks(angles[:-1], categories, color='white')  # White labels\nplt.yticks([i/10 for i in range(11)], [\"{:.2f}\".format(i/10) for i in range(11)], color=\"white\", size=7)\nplt.ylim(0, 1)\n\n# Set gray background\nax = plt.subplot(111, polar=True, facecolor='#E6ECF5', alpha = 0.7)  \n\n# Plot each classifier's data\nfor data, label, color in zip([svm, dt, knn, gnb, lr, rf],\n                              [\"SVM (linear)\", \"Decision Trees\", \"K-Nearest Neighbor\",\n                               \"Gaussian Naive Bayes\", \"Logistic Regression\", \"Random Forest\"],\n                              ['#292AF4', '#A3B763', '#818181', 'orange', 'maroon', 'teal']):\n \n    ax.plot(angles, data + data[:1], 'o-', linewidth=1.5, label=label, color=color, alpha = 0.9)\n    ax.fill(angles, data + data[:1], alpha=0)  # Fill only the edges\n    \n# Modify grids\nlabels.append(labels[0])\nax.set_thetagrids(angles * 180/np.pi, labels, color = 'black')\nplt.grid(True)\n\n# Add labels for each coordinate system\n# for angle, lab in zip(angles, labels):\n# plt.annotate(labels[0], xy=(angles[0], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[1], xy=(angles[1], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[2], xy=(angles[2], 1.1), color='white', fontsize=10, ha='center')\n# plt.annotate(labels[3], xy=(angles[3], 1.1), color='white', fontsize=10, ha='center')\n\nplt.legend(loc='upper right', bbox_to_anchor=(1.3, 1))\nplt.title(\"PCA - Models Evaluation\\n\", size = 24,color='navy', weight = 'bold')\nplt.grid(color='white', linestyle='-', alpha = 0.8)  # White grid lines\nplt.yticks([0,0.2, 0.4, 0.6, 0.8, 1.0], [\"0\",\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"],color=\"black\", size=10)  # Custom y-ticks\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:29:38.755523Z","iopub.execute_input":"2024-02-26T14:29:38.755973Z","iopub.status.idle":"2024-02-26T14:29:39.302718Z","shell.execute_reply.started":"2024-02-26T14:29:38.755938Z","shell.execute_reply":"2024-02-26T14:29:39.301395Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dump prediction results\nimport json\npredictions = {}\nfor k in prediction_results.keys():\n    predictions[k] = list(prediction_results[k])\n\n# with open(\"/kaggle/working/prediction_results.json\", \"w\") as json_file:\n#     json.dump(predictions, json_file)\n\npredictions","metadata":{"execution":{"iopub.status.busy":"2024-02-26T14:28:15.572698Z","iopub.execute_input":"2024-02-26T14:28:15.573187Z","iopub.status.idle":"2024-02-26T14:28:15.629931Z","shell.execute_reply.started":"2024-02-26T14:28:15.573156Z","shell.execute_reply":"2024-02-26T14:28:15.628714Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]}]}